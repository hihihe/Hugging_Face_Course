{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "br-n-gdgeWxa"
   },
   "source": [
    "**训练分词器是一个统计过程，它试图确定哪些子词是给定语料库的最佳选择，而用于选择子词的确切规则取决于分词算法。它是确定性的，这意味着在相同的语料库上使用相同的算法进行训练时，您总是会得到相同的结果。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://chushi123.oss-cn-beijing.aliyuncs.com/img/202203021730442.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 更改缓存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:39.567381Z",
     "iopub.status.busy": "2022-03-02T09:10:39.567381Z",
     "iopub.status.idle": "2022-03-02T09:10:39.595620Z",
     "shell.execute_reply": "2022-03-02T09:10:39.594625Z",
     "shell.execute_reply.started": "2022-03-02T09:10:39.567381Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 更改缓存路径\n",
    "os.environ[\"HF_HOME\"] = \"D:/huggingface\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"D:/huggingface/datasets\"\n",
    "\n",
    "# 设置离线模式\n",
    "# 模型离线\n",
    "# os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "# 数据离线\n",
    "# os.environ['HF_DATASETS_OFFLINE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:40.689804Z",
     "iopub.status.busy": "2022-03-02T09:10:40.689804Z",
     "iopub.status.idle": "2022-03-02T09:10:46.923501Z",
     "shell.execute_reply": "2022-03-02T09:10:46.922970Z",
     "shell.execute_reply.started": "2022-03-02T09:10:40.689804Z"
    },
    "id": "oTSahAQIeWxi",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset code_search_net (D:\\huggingface\\datasets\\code_search_net\\python\\1.0.0\\80a244ab541c6b2125350b764dc5c2b715f65f00de7a56107a28915fac173a27)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d940e386fbf44c486425ce4362f1f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# This can take a few minutes to load, so grab a coffee or tea while you wait!\n",
    "raw_datasets = load_dataset(\"code_search_net\", \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:47.784376Z",
     "iopub.status.busy": "2022-03-02T09:10:47.784376Z",
     "iopub.status.idle": "2022-03-02T09:10:47.808372Z",
     "shell.execute_reply": "2022-03-02T09:10:47.807374Z",
     "shell.execute_reply.started": "2022-03-02T09:10:47.784376Z"
    },
    "id": "DqjDPWVUeWxi",
    "outputId": "d946baff-4663-462c-dcb6-07af920f21aa",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 412178\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:48.396977Z",
     "iopub.status.busy": "2022-03-02T09:10:48.395977Z",
     "iopub.status.idle": "2022-03-02T09:10:48.426031Z",
     "shell.execute_reply": "2022-03-02T09:10:48.425032Z",
     "shell.execute_reply.started": "2022-03-02T09:10:48.396977Z"
    },
    "id": "xca1lfYIeWxj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def last_rate_limit(self):\n",
      "        \"\"\"\n",
      "        A `dict` of the rate limit information returned in the most recent\n",
      "        response, or `None` if no requests have been made yet.  The `dict`\n",
      "        consists of all headers whose names begin with ``\"RateLimit\"`` (case\n",
      "        insensitive).\n",
      "\n",
      "        The DigitalOcean API specifies the following rate limit headers:\n",
      "\n",
      "        :var string RateLimit-Limit: the number of requests that can be made\n",
      "            per hour\n",
      "        :var string RateLimit-Remaining: the number of requests remaining until\n",
      "            the limit is reached\n",
      "        :var string RateLimit-Reset: the Unix timestamp for the time when the\n",
      "            oldest request will expire from rate limit consideration\n",
      "        \"\"\"\n",
      "        if self.last_response is None:\n",
      "            return None\n",
      "        else:\n",
      "            return {k:v for k,v in iteritems(self.last_response.headers)\n",
      "                        if k.lower().startswith('ratelimit')}\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][123456][\"whole_func_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:48.908459Z",
     "iopub.status.busy": "2022-03-02T09:10:48.908459Z",
     "iopub.status.idle": "2022-03-02T09:10:48.927073Z",
     "shell.execute_reply": "2022-03-02T09:10:48.926069Z",
     "shell.execute_reply.started": "2022-03-02T09:10:48.908459Z"
    },
    "id": "9W6PQh0SeWxk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 执行以下操作将创建一个包含 1,000 个文本的列表，但会将所有内容加载到内存中：\n",
    "# training_corpus = [raw_datasets[\"train\"][i: i + 1000][\"whole_func_string\"] for i in range(0, len(raw_datasets[\"train\"]), 1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在Python中，一边循环一边计算的机制，称为生成器：generator。\n",
    "* **我又想要得到庞大的数据，又想让它占用空间少，那就用生成器！**\n",
    "* 方法一，只要把一个列表生成式的[]改成()，就创建了一个generator。\n",
    "* 方法二， 如果一个函数中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator。调用函数就是创建了一个生成器（generator）对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可迭代类型与迭代器\n",
    "* 凡是可作用于for循环的对象都是Iterable类型；\n",
    "* 凡是可作用于next()函数的对象都是Iterator类型，它们表示一个惰性计算的序列；\n",
    "* 集合数据类型如list、dict、str等是Iterable但不是Iterator，不过可以通过iter()函数获得一个Iterator对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://chushi123.oss-cn-beijing.aliyuncs.com/img/202203021557765.png)\n",
    "* 迭代器实现了两个方法，一个是__next__，一个是__iter__，__iter__用来返回迭代器本身，__next__用来取出下一个元素。\n",
    "* 生成器也是迭代器的一种，迭代器只能记住自身的执行状态并等待下一次迭代，而生成器除了也会记住执行状态，还可以通过yield语句控制使多个生成器切换执行，例如手枪只能由一个枪口打出子弹，而加特林机枪可以通过旋转控制（yield切换）用多个枪口依次出子弹，威力也会更强，生成器是实现异步协程的重要基础。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:49.061075Z",
     "iopub.status.busy": "2022-03-02T09:10:49.061075Z",
     "iopub.status.idle": "2022-03-02T09:10:49.067074Z",
     "shell.execute_reply": "2022-03-02T09:10:49.066072Z",
     "shell.execute_reply.started": "2022-03-02T09:10:49.061075Z"
    },
    "id": "8SyZJY1aeWxk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_corpus = (\n",
    "    raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "    for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成器只能使用一次，所以我们需要一个返回生成器的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:49.129077Z",
     "iopub.status.busy": "2022-03-02T09:10:49.129077Z",
     "iopub.status.idle": "2022-03-02T09:10:49.146079Z",
     "shell.execute_reply": "2022-03-02T09:10:49.145078Z",
     "shell.execute_reply.started": "2022-03-02T09:10:49.129077Z"
    },
    "id": "ozI-kK5FeWxl",
    "outputId": "91488138-cd5c-43f9-8990-e65abe963bb5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "gen = (i for i in range(10))\n",
    "print(list(gen))\n",
    "print(list(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T08:22:56.571557Z",
     "iopub.status.busy": "2022-03-02T08:22:56.571557Z",
     "iopub.status.idle": "2022-03-02T08:22:56.585710Z",
     "shell.execute_reply": "2022-03-02T08:22:56.585710Z",
     "shell.execute_reply.started": "2022-03-02T08:22:56.571557Z"
    }
   },
   "source": [
    "## 为了节约内存，使用生成器加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:49.181072Z",
     "iopub.status.busy": "2022-03-02T09:10:49.181072Z",
     "iopub.status.idle": "2022-03-02T09:10:49.192076Z",
     "shell.execute_reply": "2022-03-02T09:10:49.191072Z",
     "shell.execute_reply.started": "2022-03-02T09:10:49.181072Z"
    },
    "id": "f__EqfR7eWxl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    return (\n",
    "        raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "        for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    "    )\n",
    "\n",
    "\n",
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:49.230077Z",
     "iopub.status.busy": "2022-03-02T09:10:49.230077Z",
     "iopub.status.idle": "2022-03-02T09:10:49.255075Z",
     "shell.execute_reply": "2022-03-02T09:10:49.254076Z",
     "shell.execute_reply.started": "2022-03-02T09:10:49.230077Z"
    },
    "id": "w5dPMd37eWxm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 该函数与上面的函数产生相同的生成器，在for循环中使用yield来产生生成器\n",
    "def get_training_corpus():\n",
    "    dataset = raw_datasets[\"train\"]\n",
    "    for start_idx in range(0, len(dataset), 1000):\n",
    "        samples = dataset[start_idx : start_idx + 1000]\n",
    "        yield samples[\"whole_func_string\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练新的分词器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新的分词器只有词汇表和原来的不一样，其他都和GPT-2的分词器一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:49.306074Z",
     "iopub.status.busy": "2022-03-02T09:10:49.306074Z",
     "iopub.status.idle": "2022-03-02T09:10:59.855620Z",
     "shell.execute_reply": "2022-03-02T09:10:59.854681Z",
     "shell.execute_reply.started": "2022-03-02T09:10:49.306074Z"
    },
    "id": "43hWfksUeWxm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:59.857647Z",
     "iopub.status.busy": "2022-03-02T09:10:59.857647Z",
     "iopub.status.idle": "2022-03-02T09:10:59.871616Z",
     "shell.execute_reply": "2022-03-02T09:10:59.870616Z",
     "shell.execute_reply.started": "2022-03-02T09:10:59.857647Z"
    },
    "id": "WQ9Xn089eWxm",
    "outputId": "4d478a0d-0bf8-456d-cee2-a2785e6e34a5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ġadd',\n",
       " '_',\n",
       " 'n',\n",
       " 'umbers',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " 'Ġb',\n",
       " '):',\n",
       " 'Ċ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ\"\"\"',\n",
       " 'Add',\n",
       " 'Ġthe',\n",
       " 'Ġtwo',\n",
       " 'Ġnumbers',\n",
       " 'Ġ`',\n",
       " 'a',\n",
       " '`',\n",
       " 'Ġand',\n",
       " 'Ġ`',\n",
       " 'b',\n",
       " '`',\n",
       " '.\"',\n",
       " '\"\"',\n",
       " 'Ċ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġreturn',\n",
       " 'Ġa',\n",
       " 'Ġ+',\n",
       " 'Ġb']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = '''def add_numbers(a, b):\n",
    "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
    "    return a + b'''\n",
    "\n",
    "tokens = old_tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**原始的GPT-2的分词器有一些特殊符号，如 Ċ 和 Ġ，分别表示空格和换行符。正如我们看到的，标记器为每个空格返回单独的标记，而实际上编程时，4个8个等空格组合在一起表示特殊的含义。GPT-2的分词器还拆分了函数名，单独标记了函数名中的_符号。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们训练一个新的分词器解决上述问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:10:59.873615Z",
     "iopub.status.busy": "2022-03-02T09:10:59.872616Z",
     "iopub.status.idle": "2022-03-02T09:16:47.359633Z",
     "shell.execute_reply": "2022-03-02T09:16:47.358675Z",
     "shell.execute_reply.started": "2022-03-02T09:10:59.873615Z"
    },
    "id": "XeSjmXcZeWxn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://chushi123.oss-cn-beijing.aliyuncs.com/img/202203021732824.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AutoTokenizer.train_new_from_iterator()仅当使用的分词器是“快速”分词器时才有效。\n",
    "* 🤗 Transformers 库包含两种类型的分词器：一些是纯粹用 Python 编写的，另一些（快速的）由 🤗 Tokenizers 库支持，它是用Rust编程语言编写的。\n",
    "* 大多数 Transformer 模型都有一个快速标记器可用（您下面的链接查看），并且AutoTokenizer API 始终为您选择快速标记器（如果可用）。\n",
    "* https://huggingface.co/docs/transformers/index#supported-frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:16:47.361632Z",
     "iopub.status.busy": "2022-03-02T09:16:47.361632Z",
     "iopub.status.idle": "2022-03-02T09:16:47.375636Z",
     "shell.execute_reply": "2022-03-02T09:16:47.374632Z",
     "shell.execute_reply.started": "2022-03-02T09:16:47.361632Z"
    },
    "id": "OmUTCiQKeWxn",
    "outputId": "f2fbd9ea-9d89-4cc6-adc7-a3c17977d806",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ġadd',\n",
       " '_',\n",
       " 'numbers',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " 'Ġb',\n",
       " '):',\n",
       " 'ĊĠĠĠ',\n",
       " 'Ġ\"\"\"',\n",
       " 'Add',\n",
       " 'Ġthe',\n",
       " 'Ġtwo',\n",
       " 'Ġnumbers',\n",
       " 'Ġ`',\n",
       " 'a',\n",
       " '`',\n",
       " 'Ġand',\n",
       " 'Ġ`',\n",
       " 'b',\n",
       " '`.\"\"\"',\n",
       " 'ĊĠĠĠ',\n",
       " 'Ġreturn',\n",
       " 'Ġa',\n",
       " 'Ġ+',\n",
       " 'Ġb']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我们再次看到了表示空格和换行符的特殊符号Ċ，Ġ但我们也可以看到，我们的分词器学习了一些高度特定于 Python 函数语料库的分词：例如，有一个ĊĠĠĠ表示缩进的分词，以及一个表示缩进的分词。Ġ\"\"\"表示开始文档字符串的三个引号的标记。标记器还正确地将函数名称拆分为_. 这是一个非常紧凑的表示；相比之下，在同一个例子中使用简单的英语分词器会给我们一个更长的句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:16:47.377637Z",
     "iopub.status.busy": "2022-03-02T09:16:47.376638Z",
     "iopub.status.idle": "2022-03-02T09:16:47.390638Z",
     "shell.execute_reply": "2022-03-02T09:16:47.389645Z",
     "shell.execute_reply.started": "2022-03-02T09:16:47.377637Z"
    },
    "id": "8oVpdpwCeWxn",
    "outputId": "32f6293a-2e71-42e5-97c7-76b41096b9d0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(old_tokenizer.tokenize(example)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:16:47.394638Z",
     "iopub.status.busy": "2022-03-02T09:16:47.393650Z",
     "iopub.status.idle": "2022-03-02T09:16:47.421631Z",
     "shell.execute_reply": "2022-03-02T09:16:47.420677Z",
     "shell.execute_reply.started": "2022-03-02T09:16:47.394638Z"
    },
    "id": "q_T_p7oeeWxn",
    "outputId": "52099050-a32f-4bab-af5d-2d554ffbaa0d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'ĠLinear',\n",
       " 'Layer',\n",
       " '():',\n",
       " 'ĊĠĠĠ',\n",
       " 'Ġdef',\n",
       " 'Ġ__',\n",
       " 'init',\n",
       " '__(',\n",
       " 'self',\n",
       " ',',\n",
       " 'Ġinput',\n",
       " '_',\n",
       " 'size',\n",
       " ',',\n",
       " 'Ġoutput',\n",
       " '_',\n",
       " 'size',\n",
       " '):',\n",
       " 'ĊĠĠĠĠĠĠĠ',\n",
       " 'Ġself',\n",
       " '.',\n",
       " 'weight',\n",
       " 'Ġ=',\n",
       " 'Ġtorch',\n",
       " '.',\n",
       " 'randn',\n",
       " '(',\n",
       " 'input',\n",
       " '_',\n",
       " 'size',\n",
       " ',',\n",
       " 'Ġoutput',\n",
       " '_',\n",
       " 'size',\n",
       " ')',\n",
       " 'ĊĠĠĠĠĠĠĠ',\n",
       " 'Ġself',\n",
       " '.',\n",
       " 'bias',\n",
       " 'Ġ=',\n",
       " 'Ġtorch',\n",
       " '.',\n",
       " 'zeros',\n",
       " '(',\n",
       " 'output',\n",
       " '_',\n",
       " 'size',\n",
       " ')',\n",
       " 'ĊĊĠĠĠ',\n",
       " 'Ġdef',\n",
       " 'Ġ__',\n",
       " 'call',\n",
       " '__(',\n",
       " 'self',\n",
       " ',',\n",
       " 'Ġx',\n",
       " '):',\n",
       " 'ĊĠĠĠĠĠĠĠ',\n",
       " 'Ġreturn',\n",
       " 'Ġx',\n",
       " 'Ġ@',\n",
       " 'Ġself',\n",
       " '.',\n",
       " 'weights',\n",
       " 'Ġ+',\n",
       " 'Ġself',\n",
       " '.',\n",
       " 'bias',\n",
       " 'ĊĠĠĠĠ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"\"\"class LinearLayer():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weight = torch.randn(input_size, output_size)\n",
    "        self.bias = torch.zeros(output_size)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.weights + self.bias\n",
    "    \"\"\"\n",
    "tokenizer.tokenize(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的例子除了缩进对应的记号，这里我们还可以看到双缩进的记号ĊĠĠĠĠĠĠĠ：特殊的 Python 单词，如class, init, call, self, 和return每个都被标记为一个标记，我们可以看到，除了分割开_和.标记器正确分割甚至骆驼大小写的名称：LinearLayer被标记为[\"ĠLinear\", \"Layer\"]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存自己训练的分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:16:47.424637Z",
     "iopub.status.busy": "2022-03-02T09:16:47.423632Z",
     "iopub.status.idle": "2022-03-02T09:16:47.658326Z",
     "shell.execute_reply": "2022-03-02T09:16:47.656668Z",
     "shell.execute_reply.started": "2022-03-02T09:16:47.424637Z"
    },
    "id": "9DkcW5cSeWxo",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('code-search-net-tokenizer\\\\tokenizer_config.json',\n",
       " 'code-search-net-tokenizer\\\\special_tokens_map.json',\n",
       " 'code-search-net-tokenizer\\\\vocab.json',\n",
       " 'code-search-net-tokenizer\\\\merges.txt',\n",
       " 'code-search-net-tokenizer\\\\added_tokens.json',\n",
       " 'code-search-net-tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"code-search-net-tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载自己训练的分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:16:47.659884Z",
     "iopub.status.busy": "2022-03-02T09:16:47.659884Z",
     "iopub.status.idle": "2022-03-02T09:16:47.968499Z",
     "shell.execute_reply": "2022-03-02T09:16:47.964100Z",
     "shell.execute_reply.started": "2022-03-02T09:16:47.659884Z"
    },
    "id": "_zfyVD65eWxo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./code-search-net-tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:34:43.782231Z",
     "iopub.status.busy": "2022-03-02T09:34:43.782231Z",
     "iopub.status.idle": "2022-03-02T09:34:43.787231Z",
     "shell.execute_reply": "2022-03-02T09:34:43.787231Z",
     "shell.execute_reply.started": "2022-03-02T09:34:43.782231Z"
    }
   },
   "source": [
    "# 完整代码示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:47:59.431197Z",
     "iopub.status.busy": "2022-03-02T09:47:59.431197Z",
     "iopub.status.idle": "2022-03-02T09:48:13.379190Z",
     "shell.execute_reply": "2022-03-02T09:48:13.379190Z",
     "shell.execute_reply.started": "2022-03-02T09:47:59.431197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset code_search_net (C:\\Users\\ls\\.cache\\huggingface\\datasets\\code_search_net\\python\\1.0.0\\80a244ab541c6b2125350b764dc5c2b715f65f00de7a56107a28915fac173a27)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48f19bf0fc64933a92b8e50f373f77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"code_search_net\", \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:49:53.085400Z",
     "iopub.status.busy": "2022-03-02T09:49:53.084400Z",
     "iopub.status.idle": "2022-03-02T09:49:53.093462Z",
     "shell.execute_reply": "2022-03-02T09:49:53.093462Z",
     "shell.execute_reply.started": "2022-03-02T09:49:53.085400Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    dataset = raw_datasets[\"train\"]\n",
    "    for start_idx in range(0, len(dataset), 1000):\n",
    "        samples = dataset[start_idx : start_idx + 1000]\n",
    "        yield samples[\"whole_func_string\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:49:53.892854Z",
     "iopub.status.busy": "2022-03-02T09:49:53.892854Z",
     "iopub.status.idle": "2022-03-02T09:55:25.264867Z",
     "shell.execute_reply": "2022-03-02T09:55:25.263972Z",
     "shell.execute_reply.started": "2022-03-02T09:49:53.892854Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "training_corpus = get_training_corpus()\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "new_tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T09:55:53.325431Z",
     "iopub.status.busy": "2022-03-02T09:55:53.324432Z",
     "iopub.status.idle": "2022-03-02T09:55:53.353403Z",
     "shell.execute_reply": "2022-03-02T09:55:53.352411Z",
     "shell.execute_reply.started": "2022-03-02T09:55:53.325431Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ġadd',\n",
       " '_',\n",
       " 'numbers',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " 'Ġb',\n",
       " '):',\n",
       " 'ĊĠĠĠ',\n",
       " 'Ġ\"\"\"',\n",
       " 'Add',\n",
       " 'Ġthe',\n",
       " 'Ġtwo',\n",
       " 'Ġnumbers',\n",
       " 'Ġ`',\n",
       " 'a',\n",
       " '`',\n",
       " 'Ġand',\n",
       " 'Ġ`',\n",
       " 'b',\n",
       " '`.\"\"\"',\n",
       " 'ĊĠĠĠ',\n",
       " 'Ġreturn',\n",
       " 'Ġa',\n",
       " 'Ġ+',\n",
       " 'Ġb']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = '''def add_numbers(a, b):\n",
    "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
    "    return a + b'''\n",
    "\n",
    "new_tokenizer.tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Training a new tokenizer from an old one",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
