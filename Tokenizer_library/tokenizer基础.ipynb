{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3adb73f1-2c14-4a56-8730-18663171445a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-chinese', vocab_size=21128, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-chinese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d0c4c-1d3a-4ee0-a7c0-a10c278e3008",
   "metadata": {},
   "source": [
    "![](https://chushi123.oss-cn-beijing.aliyuncs.com/img/202202262158097.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be9c2c9-5559-4a84-9e45-a24a2e851142",
   "metadata": {},
   "source": [
    "**Tokenizer：将文本转换为模型可以处理的数据。模型只能处理数字，因此Tokenizer需要将我们的文本输入转换为数字数据。**\n",
    "1. 第一步是将文本拆分为单词（或单词的一部分、标点符号等），通常称为标记。有多个规则可以管理该过程，这就是为什么我们需要使用模型名称来实例化分词器，以确保我们使用模型预训练时使用的相同规则。\n",
    "2. 第二步是将这些标记转换为数字，这样我们就可以用它们构建一个张量并将它们提供给模型。为此，分词器有一个词汇表，这是我们在使用from_pretrained方法实例化它时下载的部分。同样，**我们需要使用模型预训练时使用的相同词汇**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfff150-8635-4250-9660-8e0ca6e6d1ca",
   "metadata": {},
   "source": [
    "![](https://chushi123.oss-cn-beijing.aliyuncs.com/img/202202262159317.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4a34d-75a1-4b41-8013-8ce7aab0851e",
   "metadata": {},
   "source": [
    "tokenizer方法实现了tokenization，处理special tokens和转化为input ids三个过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b251a3-ae00-4f88-97a4-12ee698437d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 编码一个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e5e9a05-be49-4a2a-a0d0-de667a8fe35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 6848, 2885, 4403, 3736, 5709, 1736, 4638, 1333, 1728, 2218, 3221, 3175, 912, 511, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = \"选择珠江花园的原因就是方便。\"\n",
    "inputs = tokenizer(sents)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac89e0-06e9-4561-bfad-95d570c24a3b",
   "metadata": {},
   "source": [
    "1. input_ids：句子中每个标记的唯一标识符。\n",
    "2. token_type_ids：告诉模型输出的哪一部分是第一句，哪一部分是第二句。\n",
    "3. attention_mask：具有与input_ids张量完全相同形状的张量，填充0和1：1表示应注意的相应位置的标记，0表示不应注意的相应位置的标记(即，模型的 attention layers 应忽略它们)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342269ff-b074-44fa-b20b-ac2b1c5c76c9",
   "metadata": {},
   "source": [
    "## 将索引ID转换回标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d538ce-1190-461f-af0e-c298ae6bba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 选 择 珠 江 花 园 的 原 因 就 是 方 便 。 [SEP]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b9bb2-a9f5-4dc6-9932-c1c62a96bee4",
   "metadata": {},
   "source": [
    "请注意，该decode方法不仅将索引转换回标记，还将属于相同单词的标记组合在一起以生成可读的句子。当我们使用预测新文本的模型（从提示生成的文本，或序列到序列问题（如翻译或摘要））时，这种行为将非常有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c88849-f6f4-4efc-9357-60fd29d97f2a",
   "metadata": {},
   "source": [
    "# 编码一批单个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d8ff50-2ce3-4b2d-bbe8-72b40658e860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 6848, 2885, 4403, 3736, 5709, 1736, 4638, 1333, 1728, 2218, 3221, 3175, 912, 511, 102], [101, 5011, 6381, 3315, 4638, 7241, 4669, 4802, 2141, 4272, 511, 102], [101, 2791, 7313, 1922, 2207, 511, 1071, 800, 4638, 6963, 671, 5663, 511, 102], [101, 791, 1921, 2798, 4761, 6887, 6821, 741, 6820, 3300, 5018, 127, 1318, 117, 4696, 3300, 4157, 6944, 7315, 119, 102], [101, 3322, 1690, 5520, 7481, 849, 725, 6158, 3056, 749, 2476, 784, 720, 3403, 5041, 8024, 3655, 5540, 6820, 1762, 511, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 选 择 珠 江 花 园 的 原 因 就 是 方 便 。 [SEP]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 笔 记 本 的 键 盘 确 实 爽 。 [SEP]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 机 器 背 面 似 乎 被 撕 了 张 什 么 标 签 ， 残 胶 还 在 。 [SEP]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [\n",
    "    \"选择珠江花园的原因就是方便。\",\n",
    "    \"笔记本的键盘确实爽。\",\n",
    "    \"房间太小。其他的都一般。\",\n",
    "    \"今天才知道这书还有第6卷,真有点郁闷.\",\n",
    "    \"机器背面似乎被撕了张什么标签，残胶还在。\",\n",
    "]\n",
    "inputs = tokenizer(sents)\n",
    "inputs\n",
    "tokenizer.decode(inputs[\"input_ids\"][0])\n",
    "tokenizer.decode(inputs[\"input_ids\"][1])\n",
    "tokenizer.decode(inputs[\"input_ids\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d5a12-ec4e-48c8-a56d-02453498d51a",
   "metadata": {},
   "source": [
    "# 编码一对句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d49b382-96e3-4d92-829f-f25fcfa57dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 6848, 2885, 4403, 3736, 5709, 1736, 4638, 1333, 1728, 2218, 3221, 3175, 912, 511, 102, 5011, 6381, 3315, 4638, 7241, 4669, 4802, 2141, 4272, 511, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 选 择 珠 江 花 园 的 原 因 就 是 方 便 。 [SEP] 笔 记 本 的 键 盘 确 实 爽 。 [SEP]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [[\"选择珠江花园的原因就是方便。\", \"笔记本的键盘确实爽。\"]]\n",
    "inputs = tokenizer(sents)\n",
    "inputs\n",
    "tokenizer.decode(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d18e0d-9f12-49af-8d2d-4ac61abba374",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 编码多对句子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35da89-19fa-41d1-94b0-af2a0d9c352f",
   "metadata": {},
   "source": [
    "## 编码多对句子，输入方式1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5fd566c-6ad7-4d81-8666-9ed8fb57c02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 6848, 2885, 4403, 3736, 5709, 1736, 4638, 1333, 1728, 2218, 3221, 3175, 912, 511, 102, 5011, 6381, 3315, 4638, 7241, 4669, 4802, 2141, 4272, 511, 102, 0, 0, 0, 0, 0, 0, 0], [101, 2791, 7313, 1922, 2207, 511, 1071, 800, 4638, 6963, 671, 5663, 511, 102, 791, 1921, 2798, 4761, 6887, 6821, 741, 6820, 3300, 5018, 127, 1318, 117, 4696, 3300, 4157, 6944, 7315, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 选 择 珠 江 花 园 的 原 因 就 是 方 便 。 [SEP] 笔 记 本 的 键 盘 确 实 爽 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 房 间 太 小 。 其 他 的 都 一 般 。 [SEP] 今 天 才 知 道 这 书 还 有 第 6 卷, 真 有 点 郁 闷. [SEP]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [[\"选择珠江花园的原因就是方便。\", \"笔记本的键盘确实爽。\"], [\"房间太小。其他的都一般。\", \"今天才知道这书还有第6卷,真有点郁闷.\"]]\n",
    "inputs = tokenizer(sents, padding=True)\n",
    "inputs\n",
    "tokenizer.decode(inputs[\"input_ids\"][0])\n",
    "tokenizer.decode(inputs[\"input_ids\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d888f3-790c-4019-8c34-8d20552ef28d",
   "metadata": {},
   "source": [
    "## 编码多对句子，输入方式2\n",
    "**注意和上一种方式的句子对应关系区别**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2cfd707-02eb-4ce5-b161-a586e6eb93da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 6848, 2885, 4403, 3736, 5709, 1736, 4638, 1333, 1728, 2218, 3221, 3175, 912, 511, 102, 2791, 7313, 1922, 2207, 511, 1071, 800, 4638, 6963, 671, 5663, 511, 102, 0, 0, 0], [101, 5011, 6381, 3315, 4638, 7241, 4669, 4802, 2141, 4272, 511, 102, 791, 1921, 2798, 4761, 6887, 6821, 741, 6820, 3300, 5018, 127, 1318, 117, 4696, 3300, 4157, 6944, 7315, 119, 102], [101, 2769, 4263, 872, 704, 1744, 102, 2769, 779, 4263, 4638, 4862, 1744, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 选 择 珠 江 花 园 的 原 因 就 是 方 便 。 [SEP] 房 间 太 小 。 其 他 的 都 一 般 。 [SEP] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 我 爱 你 中 国 [SEP] 我 亲 爱 的 祖 国 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [\"选择珠江花园的原因就是方便。\", \"笔记本的键盘确实爽。\", \"我爱你中国\"],\n",
    "    [\"房间太小。其他的都一般。\", \"今天才知道这书还有第6卷,真有点郁闷.\", \"我亲爱的祖国\"],\n",
    "    padding=True,\n",
    ")\n",
    "inputs\n",
    "tokenizer.decode(inputs[\"input_ids\"][0])\n",
    "tokenizer.decode(inputs[\"input_ids\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80fee2-89de-45d2-a56b-9916ef115ba5",
   "metadata": {},
   "source": [
    "# 获取字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df859a4-bef8-4bf3-a6e8-f06d3dd82c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zidian = tokenizer.get_vocab()\n",
    "\n",
    "type(zidian)\n",
    "len(zidian)\n",
    "\"月光\" in zidian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f9b2e-12ce-4d54-8f04-abb17cf8d3c3",
   "metadata": {},
   "source": [
    "# 添加新词、新符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e310e298-8e44-48ea-915b-eba85c777c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(dict, 21131, 21128, 21130)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加新词\n",
    "tokenizer.add_tokens(new_tokens=[\"月光\", \"希望\"])\n",
    "\n",
    "# 添加新符号\n",
    "tokenizer.add_special_tokens({\"eos_token\": \"[EOS]\"})\n",
    "\n",
    "zidian = tokenizer.get_vocab()\n",
    "\n",
    "type(zidian), len(zidian), zidian[\"月光\"], zidian[\"[EOS]\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403590fa-e922-44b5-be4b-3177f25011bb",
   "metadata": {},
   "source": [
    "## 编码新添加的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201ba98c-0bd2-459b-9077-b12ce80b8dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 21128, 4638, 3173, 21129, 511, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 月光 的 新 希望 。 [SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = \"月光的新希望。\"\n",
    "inputs = tokenizer(sents)\n",
    "inputs\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87eaab5-03fb-409d-b08b-828e6f4c7b40",
   "metadata": {},
   "source": [
    "# tokenizer返回能输入模型的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a72e32b-ef7c-4cc6-ab20-46fda4cc208a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6848, 2885, 4403, 3736, 5709, 1736, 4638, 1333, 1728, 2218, 3221,\n",
       "         3175,  912,  511,  102, 2791, 7313, 1922, 2207,  511, 1071,  800, 4638,\n",
       "         6963,  671, 5663,  511,  102,    0,    0,    0],\n",
       "        [ 101, 5011, 6381, 3315, 4638, 7241, 4669, 4802, 2141, 4272,  511,  102,\n",
       "          791, 1921, 2798, 4761, 6887, 6821,  741, 6820, 3300, 5018,  127, 1318,\n",
       "          117, 4696, 3300, 4157, 6944, 7315,  119,  102],\n",
       "        [ 101, 2769, 4263,  872,  704, 1744,  102, 2769,  779, 4263, 4638, 4862,\n",
       "         1744,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要指定我们想要返回的张量类型（PyTorch、TensorFlow 或普通 NumPy），我们使用return_tensors参数：\n",
    "inputs = tokenizer(\n",
    "    [\"选择珠江花园的原因就是方便。\", \"笔记本的键盘确实爽。\", \"我爱你中国\"],\n",
    "    [\"房间太小。其他的都一般。\", \"今天才知道这书还有第6卷,真有点郁闷.\", \"我亲爱的祖国\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a2fc3-5607-415f-92ae-dd594ee5801d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df84d7c-e314-4a2b-acf1-2dd34f1740dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
