{"cells":[{"cell_type":"markdown","metadata":{"id":"478A039B9CBB430EB8FC6454B3CB4A82","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"## è‡ªåŠ¨é—®ç­”\nè‡ªåŠ¨é—®ç­”(question answering, QA)æœ€åˆçš„å®šä¹‰å¾ˆç®€å•, æ˜¯æŒ‡å¯¹äºäººä»¬ç”¨è‡ªç„¶è¯­è¨€æå‡ºçš„é—®é¢˜, è®¡ç®—æœºèƒ½å¤Ÿè‡ªåŠ¨åœ°ç»™å‡ºç­”æ¡ˆæˆ–è€…ç­”æ¡ˆåˆ—è¡¨ã€‚è‡ªåŠ¨é—®ç­”æ˜¯è®¡ç®—æœºç§‘å­¦å­¦ç§‘ä¸­ä¿¡æ¯æ£€ç´¢ä¸è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„ä¸€ä¸ªé‡è¦ç ”ç©¶æ–¹å‘, ä¸»è¦ä»»åŠ¡æ˜¯ç†è§£å¹¶è‡ªåŠ¨å›ç­”ç”¨æˆ·æå‡ºçš„é—®é¢˜, æ„å»ºæ»¡è¶³ç”¨æˆ·æå‡ºçš„æ£€ç´¢ã€æ¨ç†ç­‰éœ€æ±‚çš„è‡ªåŠ¨é—®ç­”ç³»ç»Ÿã€‚\n\nè‡ªåŠ¨é—®ç­”ä¸ä»…è¦æ»¡è¶³ç”¨æˆ·å¯¹è‡ªç„¶çš„ä¿¡æ¯äº¤äº’çš„éœ€æ±‚, ä¹Ÿè¦æ»¡è¶³ç”¨æˆ·é€šè¿‡è‡ªåŠ¨é—®ç­”è·å–ç²¾ç¡®é«˜æ•ˆçš„ä¿¡æ¯çš„éœ€æ±‚ã€‚è‡ªä»æ·±åº¦å­¦ä¹ å¾—åˆ°å¹¿æ³›åº”ç”¨ä»¥æ¥, è‡ªåŠ¨é—®ç­”ä¹Ÿéšä¹‹å¾—åˆ°äº†è“¬å‹ƒçš„å‘å±•, åœ¨å„ç§æ™ºèƒ½äº§å“ä¸Šçš„åº”ç”¨ä¹Ÿè¶Šæ¥è¶Šå¹¿æ³›ã€‚\n\nä¸æœç´¢å¼•æ“ç›¸æ¯”, è‡ªåŠ¨é—®ç­”ç³»ç»Ÿä¸ºç”¨æˆ·æä¾›çš„ç­”æ¡ˆå¹¶éæ˜¯ç®€å•æ£€ç´¢æ’åºçš„æ–‡æ¡£, è€Œæ˜¯æ›´å…·æœ‰è¯­ä¹‰å†…æ¶µçš„è‡ªç„¶è¯­è¨€è¡¨è¿°ã€‚è¿‘å¹´æ¥, éšç€äººå·¥æ™ºèƒ½çš„é£é€Ÿå‘å±•, è‡ªåŠ¨é—®ç­”å·²ç»æˆä¸ºå€å—å…³æ³¨ä¸”å‘å±•å‰æ™¯å¹¿é˜”çš„ç ”ç©¶æ–¹å‘ã€‚è¯¥ç ”ç©¶æ¶‰åŠåˆ°ä¿¡æ¯æ£€ç´¢ã€çŸ¥è¯†åº“ã€æ·±åº¦å­¦ä¹ ç­‰é¢†åŸŸ, å¯¹åŠ æ·±è‡ªç„¶è¯­è¨€å¤„ç†çš„ç†è®ºä¸åº”ç”¨ç ”ç©¶æœ‰ç€ç°å®æ„ä¹‰ã€‚"},{"cell_type":"markdown","metadata":{"id":"6238260C09214B54A8BE1269ACE32018","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"## è‡ªåŠ¨é—®ç­”çš„ç±»åˆ«"},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"5F3D39B851B341279AA4CDDCF4910561","jupyter":{},"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"è‡ªåŠ¨é—®ç­”æŠ€æœ¯ä¾æ®ä¸åŒçš„ç‰¹å¾, å¯ä»¥åˆ’åˆ†ä¸ºä¸åŒçš„ç±»åˆ«ã€‚ç°æœ‰çš„ä¸€èˆ¬åˆ†ç±»ä¾æ®åŒ…æ‹¬æ•°æ®æ¥æºã€é—®ç­”èŒƒå›´ã€ä¼šè¯ç®¡ç†æ–¹å¼ç­‰ã€‚\n\n### ä¾æ®æ•°æ®æ¥æºåŒºåˆ†\n\næ ¹æ®ç›®æ ‡æ•°æ®æºçš„ä¸åŒ, å·²æœ‰è‡ªåŠ¨é—®ç­”æŠ€æœ¯å¤§è‡´å¯ä»¥åˆ†ä¸ºä¸‰ç±»:1)æ£€ç´¢å¼é—®ç­”; 2)ç¤¾åŒºé—®ç­”; 3)çŸ¥è¯†åº“é—®ç­”ã€‚\n\n- æ£€ç´¢å¼é—®ç­”æŒ‡åˆ©ç”¨ä¿¡æ¯æ£€ç´¢é¢†åŸŸçš„æŠ€æœ¯å¯¹é—®é¢˜è¿›è¡Œåˆ†æã€æå–ç‰¹å¾è¿›è¡Œæ£€ç´¢å¾—åˆ°é—®é¢˜çš„ç­”æ¡ˆã€‚ä»ç‰¹å¾æŠ½å–æ–¹å¼æ¥åˆ’åˆ†, å¯ä»¥å°†æ£€ç´¢å¼é—®ç­”ç³»ç»Ÿå¤§è‡´åˆ’åˆ†ä¸ºåŸºäºæ¨¡å¼åŒ¹é…çš„æ–¹æ³•ä¸åŸºäºç»Ÿè®¡æ–‡æœ¬æŠ½å–çš„æ–¹æ³•ã€‚æ·±åº¦å­¦ä¹ å¯¹æ£€ç´¢å¼é—®ç­”ç³»ç»Ÿçš„å‘å±•æœ‰ç€ä¸€å®šå¸®åŠ©, å¹¶ä¸»è¦åº”ç”¨äºä»æ–‡æœ¬ä¸­æå–ç­”æ¡ˆã€‚\n\n- ç¤¾åŒºé—®ç­”æŒ‡ç”¨æˆ·åˆ©ç”¨é—®ç­”ç¤¾åŒºè¿›è¡Œäº’åŠ¨, æå‡ºé—®é¢˜æˆ–å›ç­”é—®é¢˜çš„é—®ç­”å½¢å¼ã€‚é—®ç­”ç¤¾åŒºæ˜¯ç¤¾åŒºé—®ç­”ç”¨æˆ·æ´»è·ƒçš„äº’è”ç½‘ç¤¾åŒºã€‚é—®ç­”ç¤¾åŒºç”¨æˆ·é‡å·¨å¤§, å¯æä¾›è®¸å¤šé—®ç­”æ•°æ®, è¿™äº›é—®ç­”æ•°æ®è¦†ç›–äº†ç”¨æˆ·çš„å„ç§ä¿¡æ¯éœ€æ±‚ã€‚æ­¤å¤–, ç”¨æˆ·çš„å†å²è¡Œä¸ºä¿¡æ¯å¯¹ç¤¾åŒºä¸­çš„é—®ç­”åˆ†æä¹Ÿæœ‰é‡è¦å¸®åŠ©ã€‚ç¤¾åŒºé—®ç­”å¯¹ç”¨æˆ·çš„è¡Œä¸ºè¿›è¡Œåˆ†æ, ç†è§£ç”¨æˆ·çš„è¡Œä¸ºæ¨¡å¼, ä¸ºç”¨æˆ·çš„æŸ¥è¯¢æä¾›é«˜è´¨é‡çš„å›ç­”ã€‚ç¤¾åŒºé—®ç­”åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒä»»åŠ¡, åˆ†åˆ«æ˜¯ä¸“å®¶æ¨èã€ç›¸ä¼¼é—®é¢˜æ£€ç´¢ä¸ç­”æ¡ˆè´¨é‡è¯„ä¼°ã€‚\n\n\n- çŸ¥è¯†åº“é—®ç­”, æˆ–ç§°ä¸ºé¢å‘çŸ¥è¯†åº“çš„é—®ç­”, æ˜¯é€šè¿‡å¯¹è‡ªç„¶è¯­è¨€é—®é¢˜è¿›è¡Œè¯­ä¹‰ç†è§£ä¸è§£æ, åŸºäºçŸ¥è¯†åº“è¿›è¡ŒçŸ¥è¯†æå–è·å¾—ç­”æ¡ˆã€‚çŸ¥è¯†åº“æ˜¯ä¸€ç»„ç»“æ„åŒ–æ•°æ®, åŒ…å«å¤šä¸ªä¸‰å…ƒç»„ã€‚çŸ¥è¯†åº“é—®ç­”çš„ä¸­å¿ƒé—®é¢˜æ˜¯å¦‚ä½•ä»çŸ¥è¯†åº“ä¸­è·å–ä¸é—®é¢˜ç›¸å…³çš„ä¿¡æ¯è¿›è¡Œå›ç­”ã€‚ä¸»è¦åŒ…æ‹¬è¯­ä¹‰è§£æã€ä¿¡æ¯æŠ½å–ã€å‘é‡å»ºæ¨¡ç­‰æ–¹æ³•ã€‚\n\n### ä¾æ®é—®ç­”èŒƒå›´åŒºåˆ†\n\næ ¹æ®å›ç­”èŒƒå›´çš„ä¸åŒ, è‡ªåŠ¨é—®ç­”æŠ€æœ¯å¤§è‡´å¯ä»¥åˆ†ä¸ºä¸¤ç±»:1)å¼€æ”¾åŸŸé—®ç­”; 2)å‚ç›´åŸŸé—®ç­”ã€‚\n\n- å¼€æ”¾åŸŸé—®ç­”æŒ‡é—®ç­”ä¸é™å®šäºä¸€ä¸ªç‰¹å®šé¢†åŸŸ, å¯ä»¥åŸºäºä»»ä½•é¢†åŸŸè¿›è¡Œæé—®å›ç­”çš„é—®ç­”æ–¹å¼, å®ƒå¯ä»¥ä½¿ç”¨ä»»ä½•å½¢å¼çš„é—®ç­”ç³»ç»Ÿã€‚ç”±äºçŸ¥è¯†åº“ç›¸å…³æŠ€æœ¯çš„å¿«é€Ÿå‘å±•, å½“å‰çš„å¼€æ”¾åŸŸé—®ç­”ä»¥çŸ¥è¯†åº“é—®ç­”ä¸ºä¸»ã€‚\n\n- å‚ç›´åŸŸé—®ç­”, åˆå«åšé™å®šåŸŸé—®ç­”, è¡¨ç¤ºé—®ç­”çš„èƒŒæ™¯çŸ¥è¯†åœ¨æŸä¸ªé™å®šé¢†åŸŸä¸Šçš„é—®ç­”ã€‚\n\n### ä¾æ®ä¼šè¯ç®¡ç†æ–¹å¼åŒºåˆ†\n\næ ¹æ®é—®ç­”çš„ä¼šè¯ç®¡ç†æ–¹å¼æ¥åˆ’åˆ†, è‡ªåŠ¨é—®ç­”å¯ä»¥åˆ’åˆ†ä¸ºä¸¤ç±»:å•è½®é—®ç­”å’Œå¤šè½®é—®ç­”(å¤šè½®å¯¹è¯)ã€‚\n\n- ç”¨æˆ·çš„ä¸€æ¬¡æé—®ä¸é—®ç­”ç³»ç»Ÿçš„ä¸€æ¬¡é’ˆå¯¹æ€§çš„å›ç­”æ„æˆäº†ä¸€è½®é—®ç­”ã€‚å•è½®é—®ç­”çš„æ¯è½®é—®ç­”ä¹‹é—´ç›¸äº’ç‹¬ç«‹, ä¸å­˜åœ¨å…³è”, å¤šè½®é—®ç­”çš„æ¯è½®é—®ç­”ä¹‹é—´å­˜åœ¨ä¸€å®šçš„å…³è”æ€§ã€‚\n- å¤šè½®é—®ç­”å¯¹é—®ç­”ä¸Šä¸‹æ–‡è¿›è¡Œå»ºæ¨¡, å¢åŠ äº†é—®ç­”ä¸Šä¸‹æ–‡çš„ç®¡ç†æ¨¡å—, å› æ­¤å…·æœ‰æ›´é«˜çš„éš¾åº¦ä¸ç ”ç©¶ä»·å€¼ã€‚å¤šè½®é—®ç­”æ˜¯å•è½®é—®ç­”çš„åŠŸèƒ½æ€§æ‰©å±•, å› æ­¤å•è½®é—®ç­”çš„æ‰€æœ‰åŠŸèƒ½å‡åŒ…å«äºå¤šè½®é—®ç­”ä¸­ã€‚"},{"cell_type":"markdown","metadata":{"id":"9257A3E71C7F44FD9020A9BEDD033293","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"## åŸºäºæ·±åº¦å­¦ä¹ çš„é—®ç­”ç³»ç»Ÿ\n\nåŸºäºç›¸ä¼¼æ€§åŒ¹é…çš„æ·±åº¦å­¦ä¹ æ–¹æ³•æ˜¯æ·±åº¦å­¦ä¹ é—®ç­”ç³»ç»Ÿçš„ä¸€ä¸ªé‡è¦æ–¹æ³•ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ä»è§‚æµ‹æ•°æ®ä¸­å­¦ä¹ é—®é¢˜ä¸çŸ¥è¯†çš„è¯­ä¹‰è¡¨ç¤º, ä½¿å¾—æ­£ç¡®çš„å›ç­”ä¾æ®åœ¨å­¦åˆ°çš„å‘é‡ç©ºé—´ä¸­æ˜¯å’Œé—®é¢˜çš„æœ€æ¥è¿‘çš„å‘é‡ã€‚\n\næ— è®ºæ˜¯æ£€ç´¢å¼é—®ç­”ã€ç¤¾åŒºé—®ç­”è¿˜æ˜¯çŸ¥è¯†åº“é—®ç­”, æ·±åº¦å­¦ä¹ éƒ½éš¾ä»¥åº”ç”¨åˆ°å¯¹æ•°æ®æ¥æºçš„æ£€ç´¢ä¸­, å› æ­¤æ·±åº¦å­¦ä¹ é—®ç­”ç³»ç»Ÿä¸»è¦ç ”ç©¶çš„æ–¹å‘æ˜¯, åœ¨æä¾›äº†æ•°æ®æ¥æºçš„åŸºç¡€ä¸Š, ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¥å¯¹ç”¨æˆ·çš„æé—®è¿›è¡Œå›ç­”ã€‚è‡ªåŠ¨é—®ç­”çš„è¿™ä¸ªå­ä»»åŠ¡è¢«ç§°ä¸ºé˜…è¯»ç†è§£ã€‚é˜…è¯»ç†è§£å¯¹é—®ç­”çš„æ•°æ®æ¥æºè¦æ±‚ä¸é«˜, æ—¢å¯ä»¥ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ•°æ®è¿›è¡Œå›ç­”, ä¹Ÿå¯ä»¥ä¸å¤–éƒ¨çŸ¥è¯†ç›¸ç»“åˆå…±åŒè¿›è¡Œå›ç­”ã€‚ç„¶è€Œé˜…è¯»ç†è§£å¯¹æ•°æ®åˆ†æä¸æ¨ç†åŠŸèƒ½çš„è¦æ±‚è¾ƒé«˜, å› æ­¤ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•éš¾ä»¥å–å¾—ä¼˜è‰¯çš„ç»“æœ, ä¸šç•Œæ™®éé‡‡ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•è¿›è¡Œé˜…è¯»ç†è§£ã€‚\n\né˜…è¯»ç†è§£çš„ä¸€èˆ¬ä»»åŠ¡å½¢å¼ä¸º:ç»™å®šä¸€æ®µæˆ–å¤šæ®µæ–‡æœ¬ä½œä¸ºæ•°æ®æ¥æº, è¾“å…¥é—®é¢˜, ç»è¿‡å¤„ç†åè¾“å‡ºä¸€æ®µæ–‡æœ¬ä½œä¸ºé—®é¢˜çš„ç­”æ¡ˆã€‚ä¾æ®ç­”æ¡ˆæ˜¯å¦ç›´æ¥æ¥è‡ªæ–‡æœ¬, å¯å°†é˜…è¯»ç†è§£åˆ’åˆ†ä¸ºæŠ½å–å¼é˜…è¯»ç†è§£ä¸ç”Ÿæˆå¼é˜…è¯»ç†è§£ã€‚\n    \n    \nè‡ªåŠ¨é—®ç­” (Question Answering, QA) æ˜¯ç»å…¸çš„ NLP ä»»åŠ¡ï¼Œéœ€è¦æ¨¡å‹åŸºäºç»™å®šçš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œæ ¹æ®äº§ç”Ÿå›ç­”æ–¹å¼çš„ä¸åŒå¯ä»¥åˆ†ä¸ºï¼š\n\n- æŠ½å–å¼ (extractive) é—®ç­”ï¼šä»ä¸Šä¸‹æ–‡ä¸­æˆªå–ç‰‡æ®µä½œä¸ºå›ç­”ï¼Œç±»ä¼¼äºå‰é¢ä»‹ç»çš„åºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼›\n- ç”Ÿæˆå¼ (generative) é—®ç­”ï¼šç”Ÿæˆä¸€ä¸ªæ–‡æœ¬ç‰‡æ®µä½œä¸ºå›ç­”ï¼Œç±»ä¼¼äºç¿»è¯‘å’Œæ‘˜è¦ä»»åŠ¡ã€‚\n\næŠ½å–å¼é—®ç­”æ¨¡å‹é€šå¸¸é‡‡ç”¨çº¯ Encoder æ¡†æ¶ï¼ˆä¾‹å¦‚ BERTï¼‰ï¼Œå®ƒæ›´é€‚ç”¨äºå¤„ç†äº‹å®æ€§é—®é¢˜ï¼Œä¾‹å¦‚â€œè°å‘æ˜äº† Transformer æ¶æ„ï¼Ÿâ€ï¼›è€Œç”Ÿæˆå¼é—®ç­”æ¨¡å‹åˆ™é€šå¸¸é‡‡ç”¨ Encoder-Decoder æ¡†æ¶ï¼ˆä¾‹å¦‚ T5ã€BARTï¼‰ï¼Œå®ƒæ›´é€‚ç”¨äºå¤„ç†å¼€æ”¾å¼é—®é¢˜ï¼Œä¾‹å¦‚â€œå¤©ç©ºä¸ºä»€ä¹ˆæ˜¯è“è‰²çš„ï¼Ÿâ€ã€‚\n\næœ¬æ–‡æˆ‘ä»¬å°†å¾®è°ƒä¸€ä¸ª BERT æ¨¡å‹æ¥å®ŒæˆæŠ½å–å¼é—®ç­”ä»»åŠ¡ï¼šå¯¹äºæ¯ä¸€ä¸ªé—®é¢˜ï¼Œä»ç»™å®šçš„ä¸Šä¸‹æ–‡ä¸­æŠ½å–å‡ºæ¦‚ç‡æœ€å¤§çš„æ–‡æœ¬ç‰‡æ®µä½œä¸ºç­”æ¡ˆã€‚"},{"cell_type":"markdown","metadata":{"id":"CD0CC8671FAE44AB9A1BF8DD4D127B4A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"## åŸºäºtransformerså®ç°æŠ½å–å¼é—®ç­”\n\næˆ‘ä»¬å¯ä»¥å‚ç…§Huggingfaceè¯¾ç¨‹çš„ä¾‹å­[Question answering](https://huggingface.co/course/chapter7/7?fw=pt)å®ç°ä¸€ä¸ªä¸­æ–‡æŠ½å–å¼é—®ç­”æ¨¡å‹ï¼Œå…·ä½“æ­¥éª¤å¦‚ä¸‹"},{"cell_type":"markdown","metadata":{"id":"52B65DFF71734468A43153E3EA0027D0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"### æ•°æ®é›† CMRC2018ä»‹ç»\n\næœ¬ç›®å½•åŒ…å«[ç¬¬äºŒå±Šâ€œè®¯é£æ¯â€ä¸­æ–‡æœºå™¨é˜…è¯»ç†è§£è¯„æµ‹ï¼ˆCMRC 2018ï¼‰](https://hfl-rc.github.io/cmrc2018/)æ‰€ä½¿ç”¨çš„æ•°æ®ã€‚æœ¬æ•°æ®é›†å·²è¢«è®¡ç®—è¯­è¨€å­¦é¡¶çº§å›½é™…ä¼šè®®[EMNLP 2019](http://emnlp-ijcnlp2019.org)å½•ç”¨ã€‚\n\n**Title: A Span-Extraction Dataset for Chinese Machine Reading Comprehension**    \nAuthors: Yiming Cui, Ting Liu, Wanxiang Che, Li Xiao, Zhipeng Chen, Wentao Ma, Shijin Wang, Guoping Hu   \nLink: [https://www.aclweb.org/anthology/D19-1600/](https://www.aclweb.org/anthology/D19-1600/)  \nVenue: EMNLP-IJCNLP 2019\n\n- å¼€æ”¾å¼æŒ‘æˆ˜æ’è¡Œæ¦œ (new!)\n\næƒ³äº†è§£åœ¨CMRC 2018æ•°æ®ä¸Šè¡¨ç°æœ€å¥½çš„æ¨¡å‹å—ï¼Ÿè¯·æŸ¥é˜…æ’è¡Œæ¦œã€‚\n[https://ymcui.github.io/cmrc2018/](https://ymcui.github.io/cmrc2018/)\n\n-  CMRC 2018 å…¬å¼€æ•°æ®é›†\n\nè¯·é€šè¿‡CodaLab Worksheetä¸‹è½½CMRC 2018å…¬å¼€æ•°æ®é›†ï¼ˆè®­ç»ƒé›†ï¼Œå¼€å‘é›†ï¼‰ã€‚\n[https://worksheets.codalab.org/worksheets/0x92a80d2fab4b4f79a2b4064f7ddca9ce](https://worksheets.codalab.org/worksheets/0x92a80d2fab4b4f79a2b4064f7ddca9ce)\n\n- æäº¤æ–¹æ³•\n\nå¦‚æœä½ æƒ³è¦åœ¨**éšè—çš„æµ‹è¯•é›†ã€æŒ‘æˆ˜é›†ä¸Šæµ‹è¯•ä½ çš„æ¨¡å‹**ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ­¥éª¤æäº¤ä½ çš„æ¨¡å‹ã€‚\n[https://worksheets.codalab.org/worksheets/0x96f61ee5e9914aee8b54bd11e66ec647/](https://worksheets.codalab.org/worksheets/0x96f61ee5e9914aee8b54bd11e66ec647/)\n\n**éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ[CLUE](https://github.com/CLUEbenchmark/CLUE)ä¸Šæä¾›çš„æµ‹è¯•é›†ä»…æ˜¯CMRC 2018çš„éƒ¨åˆ†å­é›†ã€‚æ­£å¼è¯„æµ‹ä»éœ€é€šè¿‡ä¸Šè¿°æ–¹æ³•å¾—åˆ°å®Œæ•´æµ‹è¯•é›†ã€æŒ‘æˆ˜é›†ä¸Šçš„ç»“æœã€‚**\n\n\n- é€šè¿‡ğŸ¤—datasetså¿«é€ŸåŠ è½½\n\nä½ å¯ä»¥é€šè¿‡[HuggingFace `datasets` library](https://github.com/huggingface/datasets)å·¥å…·åŒ…å¿«é€ŸåŠ è½½æ•°æ®é›†ï¼š\n\n```python\n!pip install datasets\nfrom datasets import load_dataset\ndataset = load_dataset('cmrc2018')\n```\nå…³äº`datasets`å·¥å…·åŒ…çš„æ›´å¤šé€‰é¡¹å’Œä½¿ç”¨ç»†èŠ‚å¯ä»¥é€šè¿‡è¿™é‡Œè®¿é—®äº†è§£ï¼šhttps://github.com/huggingface/datasets\n\n\næ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚"},{"cell_type":"markdown","metadata":{"id":"19CACC298FB248148F0453B9093AC2FF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"æ ·æœ¬å…·ä½“å†…å®¹å¦‚ä¸‹ï¼š\n```\n{\n      \"paragraphs\": [\n        {\n          \"id\": \"DEV_1096\", \n          \"context\": \"ç‹å¤©æˆï¼Œä¸­å›½æ¹–å—çœåŒç‰Œå¿äººï¼Œè‘—åå¼‚è®®äººå£«ã€æ”¿æ²»å­¦è€…ã€‚1989å¹´æ¯•ä¸šäºåŒ—äº¬å¤§å­¦æ³•å¾‹ç³»ï¼ˆç°åŒ—äº¬å¤§å­¦æ³•å­¦é™¢ï¼‰ï¼Œè·ç¡•å£«å­¦ä½ï¼ŒåŒå¹´ç•™æ ¡ä»»åŠ©æ•™ï¼Œå…¼ä»»åŒ—å¤§ã€Šä¸­å¤–æ³•å­¦ã€‹æ‚å¿—ç¼–è¾‘ï¼Œæ—‹å³æ™‹å‡ä¸ºè®²å¸ˆã€‚å› å‚ä¸åˆ›å»ºâ€œä¸­å›½è‡ªç”±æ°‘ä¸»å…šâ€ï¼Œæ‹…ä»»è¯¥å…šå®£ä¼ éƒ¨é•¿ï¼Œç‹å¤©æˆ1992å¹´10æœˆè¢«æ•ï¼Œ1994å¹´è¢«åŒ—äº¬å¸‚ä¸­çº§äººæ°‘æ³•é™¢åˆ¤å¤„æœ‰æœŸå¾’åˆ‘5å¹´ï¼Œå‰¥å¤ºæ”¿æ²»æƒåˆ©2å¹´ï¼Œ1997å¹´10æœˆåˆ‘æ»¡é‡Šæ”¾ã€‚ç‹å¤©æˆ1999å¹´æ‰€è‘—æ–‡ç« ã€Šè®ºå…±å’Œå›½ã€‹ã€ã€Šå†è®ºå…±å’Œå›½ã€‹ï¼Œæ˜¯ä¸­å›½å­¦è€…è¾ƒæ—©ç³»ç»Ÿé˜è¿°å…±å’Œä¸»ä¹‰çš„ä½œå“ï¼Œæµä¼ ç”šå¹¿ï¼Œå·²æˆä¸ºæ±‰è¯­ç•Œåœ¨è¯¥é¢†åŸŸçš„ç»å…¸ä¹‹ä½œã€‚ç‹å¦ä¸äººåˆè¯‘æœ‰åŸƒå¾·è’™Â·æŸå…‹ã€Šè‡ªç”±ä¸ä¼ ç»Ÿã€‹ã€é˜¿å…‹é¡¿å‹‹çˆµã€Šè‡ªç”±çš„å†å²ã€‹ã€è·¯æ˜“æ–¯Â·åšæ´›å°”ã€Šæ”¿æ²»çš„ç½ªæ¶ã€‹ç­‰è¥¿æ–¹å­¦æœ¯åè‘—ã€‚2005å¹´11æœˆï¼Œç‹å¤©æˆå‘è¡¨æ–‡ç« æŒ‡æ§æ­¦æ±‰å¤§å­¦æ•™æˆã€åšå£«ç”Ÿå¯¼å¸ˆå‘¨å¶ä¸­æ‰€è‘—ã€Šå…±å’Œä¸»ä¹‰ä¹‹å®ªæ”¿è§£è¯»ã€‹ä¸€ä¹¦ï¼ˆ2005å¹´11æœˆäººæ°‘å‡ºç‰ˆç¤¾å‡ºç‰ˆï¼‰ï¼Œä¸¥é‡æŠ„è¢­äº†å…¶ã€Šè®ºå…±å’Œå›½ã€‹ã€ã€Šå†è®ºå…±å’Œå›½ã€‹ã€‚å‘¨å¶ä¸­æ˜¯ä¸­å›½å®ªæ³•å­¦ç ”ç©¶ä¼šå‰¯ä¼šé•¿ï¼Œ2002å¹´æ›¾åˆ°ä¸­å—æµ·ç»™èƒ¡é”¦æ¶›æ¸©å®¶å®ç­‰ä¸­å…±é¢†å¯¼äººè®²è¯¾ã€‚è¯¥äº‹ä»¶è½°åŠ¨ä¸€æ—¶ï¼Œä½†æ³•é™¢åˆ¤å†³å‘¨å¶ä¸­æ²¡æœ‰æŠ„è¢­ï¼Œåˆ¤å†³å…¬å¸ƒåå¤‡å—éè®®ï¼Œæˆä¸ºå­¦ç•Œä¸€å¤§å…¬æ¡ˆã€‚ç‹å¤©æˆ2008å¹´èµ´ç¾ï¼Œå…ˆååœ¨å“¥ä¼¦æ¯”äºšå¤§å­¦ã€è¥¿åŒ—å¤§å­¦ã€çº½çº¦å¤§å­¦ä»äº‹æ°‘ä¸»è½¬å‹ã€åˆ¶åº¦è®¾è®¡ç ”ç©¶ã€‚æœŸé—´æ‰€å®Œæˆçš„è‘—ä½œã€Šå¤§è½¬å‹ï¼šä¸­å›½æ°‘ä¸»åŒ–æˆ˜ç•¥ç ”ç©¶æ¡†æ¶ã€‹ï¼ˆè¿è½½äºã€Šä¸­å›½äººæƒåŒå‘¨åˆŠã€‹ï¼Œå®Œæ•´ç‰ˆ2012å¹´åœ¨é¦™æ¸¯å‡ºç‰ˆï¼‰ï¼Œåœ¨å¤§é‡æ°‘ä¸»è½¬å‹æ¡ˆä¾‹ç ”ç©¶çš„åŸºç¡€ä¹‹ä¸Šï¼Œç³»ç»Ÿæ¢è®¨äº†ä¸­å›½æ°‘ä¸»è½¬å‹è·¯å¾„ä¸åˆ¶åº¦é€‰æ‹©å…³é”®é—®é¢˜ï¼Œè¢«ä¸€äº›è¯„è®ºå®¶è®¤ä¸ºæ˜¯90å¹´ä»£åˆè‡³ä»Š20ä½™å¹´ä¸­å›½æ”¿æ²»å­¦é¢†åŸŸæœ€é‡è¦çš„è‘—ä½œã€‚2010å¹´3æœˆä»£è¡¨ä¸­å›½è‡ªç”±æ°‘ä¸»å…šä¸ç‹æœ‰æ‰å‘è¡¨è”åˆå…¬å‘Šï¼Œå®£å¸ƒä¸­å›½è‡ªç”±æ°‘ä¸»å…šä¸ä¸­å›½æ°‘ä¸»å…šå…±åŒç»„å»ºä¸­å›½æ°‘ä¸»å…šå…¨å›½å§”å‘˜ä¼šï¼Œ4æœˆå½“é€‰ä¸­å›½æ°‘ä¸»å…šå…¨å›½å§”å‘˜ä¼šæ‰§è¡Œé•¿ã€‚2013å¹´1æœˆè¾èŒï¼Œå›å½’å­¦æœ¯ç ”ç©¶ã€‚2013å¹´6æœˆå¤©å®‰é—¨æ°‘ä¸»å¤§å­¦å¼€å­¦ï¼Œç‹å¤©æˆä»»æ•™åŠ¡é•¿ã€‚\", \n          \"qas\": [\n            {\n              \"question\": \"ç‹å¤©æˆçš„ç±è´¯æ˜¯å“ªé‡Œï¼Ÿ\", \n              \"id\": \"DEV_1096_QUERY_0\", \n              \"answers\": [\n                {\n                  \"text\": \"ä¸­å›½æ¹–å—çœåŒç‰Œå¿\", \n                  \"answer_start\": 4\n                }, \n                {\n                  \"text\": \"ä¸­å›½æ¹–å—çœåŒç‰Œå¿\", \n                  \"answer_start\": 4\n                }, \n                {\n                  \"text\": \"æ¹–å—çœåŒç‰Œå¿\", \n                  \"answer_start\": 6\n                }\n              ]\n            }, \n            {\n              \"question\": \"ç‹å¤©æˆå“ªä¸€å¹´ä»åŒ—äº¬å¤§å­¦æ³•å¾‹ç³»æ¯•ä¸šï¼Ÿ\", \n              \"id\": \"DEV_1096_QUERY_1\", \n              \"answers\": [\n                {\n                  \"text\": \"1989å¹´\", \n                  \"answer_start\": 26\n                }, \n                {\n                  \"text\": \"1989å¹´\", \n                  \"answer_start\": 26\n                }, \n                {\n                  \"text\": \"1989å¹´\", \n                  \"answer_start\": 26\n                }\n              ]\n            }, \n            {\n              \"question\": \"ç‹å¤©æˆå…¼ä»»äº†å“ªä¸ªæ‚å¿—çš„ç¼–è¾‘ï¼Ÿ\", \n              \"id\": \"DEV_1096_QUERY_2\", \n              \"answers\": [\n                {\n                  \"text\": \"ã€Šä¸­å¤–æ³•å­¦ã€‹\", \n                  \"answer_start\": 70\n                }, \n                {\n                  \"text\": \"ã€Šä¸­å¤–æ³•å­¦ã€‹\", \n                  \"answer_start\": 70\n                }, \n                {\n                  \"text\": \"ã€Šä¸­å¤–æ³•å­¦ã€‹\", \n                  \"answer_start\": 70\n                }\n              ]\n            },\n            ...\n          ]\n        }\n      ], \n      \"id\": \"DEV_1096\", \n      \"title\": \"ç‹å¤©æˆ\"\n    }, \n```"},{"cell_type":"markdown","metadata":{"id":"24CD697300824C09965A563EBE4C2ED0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"å…¶ä¸­ä¸€ä¸ªé—®é¢˜å¯èƒ½å¯¹åº”å¤šä¸ªç­”æ¡ˆï¼Œä¹Ÿå°±æ˜¯ç­”æ¡ˆä¼šåå¤çš„å‡ºç°åœ¨åŸæ–‡ä¸­ï¼Œåœ¨è®­ç»ƒçš„æ—¶å€™æ¯ä¸ªé—®é¢˜åªæœ‰ä¸€ä¸ªç­”æ¡ˆï¼ŒéªŒè¯ä¸æµ‹è¯•çš„æ—¶å€™ï¼Œåªéœ€è¦åˆ¤æ–­é¢„æµ‹ç­”æ¡ˆä¸æ‰€æœ‰å‚è€ƒç­”æ¡ˆä¸€èµ·è¯„ä¼°"},{"cell_type":"markdown","metadata":{"id":"FE29FB18000E407DB9C3877603452BD5","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"### åˆ›å»ºDataset"},{"cell_type":"markdown","metadata":{"id":"71E384F9CFE048BFBB2C4673E28C2211","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"å’Œä¹‹å‰ä»»åŠ¡ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦ç¼–ä¸€ä¸ªè‡ªå®šä¹‰æ•°æ®é›†CMRC2018ï¼Œç„¶åç”¨æ¥åŠ è½½æ•°æ®å¹¶è¿›è¡Œå¤„ç†ã€‚ä¸»è¦æ˜¯éœ€è¦questionå’Œanswerï¼Œä»¥åŠç­”æ¡ˆçš„å¼€å§‹ä½ç½®ç­‰ï¼š"},{"cell_type":"code","execution_count":1,"metadata":{"id":"E2F9C7FE748B4D4EAF4E6B9F138F7A19","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"from torch.utils.data import Dataset\nimport json"},{"cell_type":"code","execution_count":4,"metadata":{"id":"096DE56677ED47D7AA3E38B29D5BDEFD","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"class CMRCDataset(Dataset):\n    def __init__(self, data_file):\n        self.data = self.load_data(data_file)\n    \n    def load_data(self, data_file):\n        Data = {}\n        with open(data_file, 'r', encoding='utf-8') as f:\n            json_data = json.load(f)\n            idx = 0\n            for article in json_data['data']:\n                title = article['title']\n                context = article['paragraphs'][0]['context']\n                for question in article['paragraphs'][0]['qas']:\n                    q_id = question['id']\n                    ques = question['question']\n                    text = [ans['text'] for ans in question['answers']]\n                    answer_start = [ans['answer_start'] for ans in question['answers']]\n                    Data[idx] = {\n                        'id': q_id,\n                        'title': title,\n                        'context': context, \n                        'question': ques,\n                        'answers': {\n                            'text': text,\n                            'answer_start': answer_start\n                        }\n                    }\n                    idx += 1\n        return Data\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n# train_data = CMRCDataset('data/10/cmrc2018_train.json')\n# valid_data = CMRCDataset('data/10/cmrc2018_dev.json')\n# test_data = CMRCDataset('data/10/cmrc2018_trial.json')\n\ntrain_data = CMRCDataset('/home/mw/input/task109875/cmrc2018_train.json')\nvalid_data = CMRCDataset('/home/mw/input/task109875/cmrc2018_dev.json')\ntest_data = CMRCDataset('/home/mw/input/task109875/cmrc2018_trial.json')"},{"cell_type":"code","execution_count":5,"metadata":{"id":"645474D58EE2465A9831B27ACF3C7F11","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"{'id': 'TRAIN_186_QUERY_0',\n 'title': 'èŒƒå»·é¢‚',\n 'context': 'èŒƒå»·é¢‚æ¢æœºï¼ˆï¼Œï¼‰ï¼Œåœ£åä¿ç¦„Â·è‹¥ç‘Ÿï¼ˆï¼‰ï¼Œæ˜¯è¶Šå—ç½—é©¬å¤©ä¸»æ•™æ¢æœºã€‚1963å¹´è¢«ä»»ä¸ºä¸»æ•™ï¼›1990å¹´è¢«æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºå®—åº§ç½²ç†ï¼›1994å¹´è¢«æ“¢å‡ä¸ºæ€»ä¸»æ•™ï¼ŒåŒå¹´å¹´åº•è¢«æ“¢å‡ä¸ºæ¢æœºï¼›2009å¹´2æœˆç¦»ä¸–ã€‚èŒƒå»·é¢‚äº1919å¹´6æœˆ15æ—¥åœ¨è¶Šå—å®å¹³çœå¤©ä¸»æ•™å‘è‰³æ•™åŒºå‡ºç”Ÿï¼›ç«¥å¹´æ—¶æ¥å—è‰¯å¥½æ•™è‚²åï¼Œè¢«ä¸€ä½è¶Šå—ç¥çˆ¶å¸¦åˆ°æ²³å†…ç»§ç»­å…¶å­¦ä¸šã€‚èŒƒå»·é¢‚äº1940å¹´åœ¨æ²³å†…å¤§ä¿®é“é™¢å®Œæˆç¥å­¦å­¦ä¸šã€‚èŒƒå»·é¢‚äº1949å¹´6æœˆ6æ—¥åœ¨æ²³å†…çš„ä¸»æ•™åº§å ‚æ™‹é“ï¼›åŠåè¢«æ´¾åˆ°åœ£å¥³å°å¾·å…°å­¤å„¿é™¢æœåŠ¡ã€‚1950å¹´ä»£ï¼ŒèŒƒå»·é¢‚åœ¨æ²³å†…å ‚åŒºåˆ›å»ºç§»æ°‘æ¥å¾…ä¸­å¿ƒä»¥æ”¶å®¹åˆ°æ²³å†…é¿æˆ˜çš„éš¾æ°‘ã€‚1954å¹´ï¼Œæ³•è¶Šæˆ˜äº‰ç»“æŸï¼Œè¶Šå—æ°‘ä¸»å…±å’Œå›½å»ºéƒ½æ²³å†…ï¼Œå½“æ—¶å¾ˆå¤šå¤©ä¸»æ•™ç¥èŒäººå‘˜é€ƒè‡³è¶Šå—çš„å—æ–¹ï¼Œä½†èŒƒå»·é¢‚ä»ç„¶ç•™åœ¨æ²³å†…ã€‚ç¿Œå¹´ç®¡ç†åœ£è‹¥æœ›å°ä¿®é™¢ï¼›æƒŸåœ¨1960å¹´å› æå«ä¿®é™¢çš„è‡ªç”±ã€è‡ªæ²»åŠæ‹’ç»æ”¿åºœåœ¨ä¿®é™¢è®¾æ”¿æ²»è¯¾çš„è¦æ±‚è€Œè¢«æ•ã€‚1963å¹´4æœˆ5æ—¥ï¼Œæ•™å®—ä»»å‘½èŒƒå»·é¢‚ä¸ºå¤©ä¸»æ•™åŒ—å®æ•™åŒºä¸»æ•™ï¼ŒåŒå¹´8æœˆ15æ—¥å°±ä»»ï¼›å…¶ç‰§é“­ä¸ºã€Œæˆ‘ä¿¡å¤©ä¸»çš„çˆ±ã€ã€‚ç”±äºèŒƒå»·é¢‚è¢«è¶Šå—æ”¿åºœè½¯ç¦å·®ä¸å¤š30å¹´ï¼Œå› æ­¤ä»–æ— æ³•åˆ°æ‰€å±å ‚åŒºè¿›è¡Œç‰§çµå·¥ä½œè€Œä¸“æ³¨ç ”è¯»ç­‰å·¥ä½œã€‚èŒƒå»·é¢‚é™¤äº†é¢å¯¹æˆ˜äº‰ã€è´«å›°ã€è¢«å½“å±€è¿«å®³å¤©ä¸»æ•™ä¼šç­‰é—®é¢˜å¤–ï¼Œä¹Ÿç§˜å¯†æ¢å¤ä¿®é™¢ã€åˆ›å»ºå¥³ä¿®ä¼šå›¢ä½“ç­‰ã€‚1990å¹´ï¼Œæ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–åœ¨åŒå¹´6æœˆ18æ—¥æ“¢å‡èŒƒå»·é¢‚ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºå®—åº§ç½²ç†ä»¥å¡«è¡¥è¯¥æ•™åŒºæ€»ä¸»æ•™çš„ç©ºç¼ºã€‚1994å¹´3æœˆ23æ—¥ï¼ŒèŒƒå»·é¢‚è¢«æ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™å¹¶å…¼å¤©ä¸»æ•™è°…å±±æ•™åŒºå®—åº§ç½²ç†ï¼›åŒå¹´11æœˆ26æ—¥ï¼Œè‹¥æœ›ä¿ç¦„äºŒä¸–æ“¢å‡èŒƒå»·é¢‚ä¸ºæ¢æœºã€‚èŒƒå»·é¢‚åœ¨1995å¹´è‡³2001å¹´æœŸé—´å‡ºä»»å¤©ä¸»æ•™è¶Šå—ä¸»æ•™å›¢ä¸»å¸­ã€‚2003å¹´4æœˆ26æ—¥ï¼Œæ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–ä»»å‘½å¤©ä¸»æ•™è°…å±±æ•™åŒºå…¼å¤©ä¸»æ•™é«˜å¹³æ•™åŒºå´å…‰æ°ä¸»æ•™ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºç½²ç†ä¸»æ•™ï¼›åŠè‡³2005å¹´2æœˆ19æ—¥ï¼ŒèŒƒå»·é¢‚å› è·æ‰¹è¾å»æ€»ä¸»æ•™èŒåŠ¡è€Œè£ä¼‘ï¼›å´å…‰æ°åŒæ—¥çœŸé™¤å¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™èŒåŠ¡ã€‚èŒƒå»·é¢‚äº2009å¹´2æœˆ22æ—¥æ¸…æ™¨åœ¨æ²³å†…ç¦»ä¸–ï¼Œäº«å¹´89å²ï¼›å…¶è‘¬ç¤¼äºåŒæœˆ26æ—¥ä¸Šåˆåœ¨å¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™åº§å ‚ä¸¾è¡Œã€‚',\n 'question': 'èŒƒå»·é¢‚æ˜¯ä»€ä¹ˆæ—¶å€™è¢«ä»»ä¸ºä¸»æ•™çš„ï¼Ÿ',\n 'answers': {'text': ['1963å¹´'], 'answer_start': [30]}}"},"transient":{}}],"source":"train_data[0]"},{"cell_type":"markdown","metadata":{"id":"2613635AB9064EEF8D4294E886952FBF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"æˆ‘ä»¬å¯ä»¥çœ‹ä¸‹æ•°æ®é›†çš„å¤§å°ï¼š"},{"cell_type":"code","execution_count":6,"metadata":{"id":"8794D7BD9DF04FB2B7799ACA9D3665E9","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"train_data lengths 10142\nvalid_data lengths 3219\ntest_data lengths 1002\n","name":"stdout"}],"source":"print(\"train_data lengths\",len(train_data))\nprint(\"valid_data lengths\",len(valid_data))\nprint(\"test_data lengths\",len(test_data))"},{"metadata":{"id":"695F8ACBC9AD4468B6581EABE586D62D","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\nCollecting transformers\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8f/e9/c2b4c823b3959d475a570c1bd2df4125478e2e37b96fb967a87933ae7134/transformers-4.18.0-py3-none-any.whl (4.0 MB)\n\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.0 MB 1.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.26.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.49.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (1.7.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2019.6.8)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.3.1)\nCollecting huggingface-hub<1.0,>=0.1.0\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c8/df/1b454741459f6ce75f86534bdad42ca17291b14a83066695f7d2c676e16c/huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 1.6 MB/s eta 0:00:011\n\u001b[?25hCollecting numpy>=1.17\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/14/32/d3fa649ad7ec0b82737b92fefd3c4dd376b0bb23730715124569f38f3a08/numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.8 MB 1.7 MB/s eta 0:00:01\n\u001b[?25hCollecting packaging>=20.0\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/05/8e/8de486cbd03baba4deef4142bd643a3e7bbe954a784dc1bb17142572d127/packaging-21.3-py3-none-any.whl (40 kB)\n\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40 kB 1.0 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.1.10)\nCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/db/07/5125318be83d03c311125412da13988e422b0c0255c08621637614c40b86/tokenizers-0.12.0-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.6 MB 1.3 MB/s eta 0:00:01\n\u001b[?25hCollecting typing-extensions>=3.7.4.3\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/45/6b/44f7f8f1e110027cf88956b59f2fad776cca7e1704396d043f89effd3a0e/typing_extensions-4.1.1-py3-none-any.whl (26 kB)\nCollecting dataclasses\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl (19 kB)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.26.6)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.2)\nCollecting sacremoses\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/db/8b/37b90a3848ff71c0d05ebac5ee6d83f1f81e5f57f26b99a83ebff033303b/sacremoses-0.0.49-py3-none-any.whl (895 kB)\n\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 1.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (0.13.2)\nInstalling collected packages: typing-extensions, packaging, tokenizers, sacremoses, numpy, huggingface-hub, dataclasses, transformers\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.7.4\n    Uninstalling typing-extensions-3.7.4:\n      Successfully uninstalled typing-extensions-3.7.4\n  Attempting uninstall: packaging\n    Found existing installation: packaging 19.0\n    Uninstalling packaging-19.0:\n      Successfully uninstalled packaging-19.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.16.3\n    Uninstalling numpy-1.16.3:\n      Successfully uninstalled numpy-1.16.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspacy 2.1.4 requires jsonschema<3.1.0,>=2.6.0, but you have jsonschema 3.2.0 which is incompatible.\npaddlepaddle 1.5.0 requires matplotlib<=2.2.4, but you have matplotlib 3.1.1 which is incompatible.\npaddlepaddle 1.5.0 requires nltk<=3.4,>=3.2.2, but you have nltk 3.4.1 which is incompatible.\nmxnet 1.4.1 requires numpy<1.15.0,>=1.8.2, but you have numpy 1.19.5 which is incompatible.\nauto-sklearn 0.5.2 requires scikit-learn<0.20,>=0.19, but you have scikit-learn 0.21.1 which is incompatible.\u001b[0m\nSuccessfully installed dataclasses-0.8 huggingface-hub-0.4.0 numpy-1.19.5 packaging-21.3 sacremoses-0.0.49 tokenizers-0.12.0 transformers-4.18.0 typing-extensions-4.1.1\n\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}],"source":"!pip install transformers -i https://pypi.tuna.tsinghua.edu.cn/simple","execution_count":9},{"cell_type":"markdown","metadata":{"id":"1EFEA05E46DC48ADB661DA9E1CEA2942","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"### æ•°æ®é¢„å¤„ç†"},{"cell_type":"code","execution_count":10,"metadata":{"id":"DC9EB8233A5E4E588F8FA1A9E31E96A3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=19.0, style=ProgressStyle(description_wâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"597658cb337b4f059ad15b707a00b8bc"}},"transient":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","metadata":{},"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=647.0, style=ProgressStyle(description_â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44ea502de5b24722a272c4d9125fc70e"}},"transient":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","metadata":{},"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descriptiâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"437a4911351d42cdab7d5a7c1b87d6f7"}},"transient":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","metadata":{},"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=268961.0, style=ProgressStyle(descriptiâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcbb8d601eb74cf6bde85762ff9eee51"}},"transient":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","metadata":{},"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wiâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ed0f7d00a924318907449dfea7dd379"}},"transient":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","metadata":{},"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1b6525ad3394c9ebd00d8799f31bfd1"}},"transient":{}},{"output_type":"stream","text":"\n","name":"stdout"}],"source":"from transformers import AutoTokenizer\n\n# model_checkpoint = '../pretrained_models/chinese-roberta-wwm-ext'\nmodel_checkpoint = 'hfl/chinese-bert-wwm-ext'\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"},{"cell_type":"code","execution_count":11,"metadata":{"id":"A7404840F91B4DC29EA99A1A28AFAC5E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"PreTrainedTokenizerFast(name_or_path='hfl/chinese-bert-wwm-ext', vocab_size=21128, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"},"transient":{}}],"source":"tokenizer"},{"metadata":{"id":"4412B53EFF3345E8BEA5D4249A6B632B","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"'èŒƒå»·é¢‚æ˜¯ä»€ä¹ˆæ—¶å€™è¢«ä»»ä¸ºä¸»æ•™çš„ï¼Ÿ'"},"transient":{}}],"source":"text=train_data[0][\"question\"]\ntext","execution_count":19},{"metadata":{"id":"C87B792CB551480193CFFD359932633A","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"{'input_ids': [101, 5745, 2455, 7563, 3221, 784, 720, 3198, 952, 6158, 818, 711, 712, 3136, 4638, 8043, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (0, 0)]}\n","name":"stdout"}],"source":"inputs = tokenizer(\n    text,\n    return_offsets_mapping=True\n)\nprint(inputs)","execution_count":22},{"metadata":{"id":"30E34C48A8DF456186F2040A0909E3F4","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"'[CLS] èŒƒ å»· é¢‚ æ˜¯ ä»€ ä¹ˆ æ—¶ å€™ è¢« ä»» ä¸º ä¸» æ•™ çš„ ï¼Ÿ [SEP]'"},"transient":{}}],"source":"tokenizer.decode(inputs['input_ids'])","execution_count":23},{"metadata":{"id":"D9DAF02AC1C241418FD789D099EC1A4D","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"['[CLS]',\n 'èŒƒ',\n 'å»·',\n 'é¢‚',\n 'æ˜¯',\n 'ä»€',\n 'ä¹ˆ',\n 'æ—¶',\n 'å€™',\n 'è¢«',\n 'ä»»',\n 'ä¸º',\n 'ä¸»',\n 'æ•™',\n 'çš„',\n 'ï¼Ÿ',\n '[SEP]']"},"transient":{}}],"source":"decode_words=[tokenizer.decode(input_id) for input_id in inputs['input_ids']]\ndecode_words","execution_count":27},{"metadata":{"id":"9B891064214444AE83DD13907C14EA5A","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"['[CLS]']"},"transient":{}}],"source":"start_index=inputs['offset_mapping'][0][0]\nend_index=inputs['offset_mapping'][0][1]+1\ndecode_words[start_index:end_index]","execution_count":33},{"metadata":{"id":"B4DEC3F645FA473E88629789BAA039F9","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"['å»·']"},"transient":{}}],"source":"start_index=inputs['offset_mapping'][2][0]+1\nend_index=inputs['offset_mapping'][2][1]+1\ndecode_words[start_index:end_index]","execution_count":36},{"cell_type":"markdown","metadata":{"id":"1F5A306345D74CD89778C4B44E1E3C2B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"é€‰å–ç¬¬ä¸€ä¸ªè®­ç»ƒé›†æ ·æœ¬ï¼Œå¯¹ä¸Šä¸‹æ–‡contextå’Œquestionè¿›è¡Œåˆ†è¯ï¼Œ"},{"cell_type":"code","execution_count":12,"metadata":{"id":"C7A482C6F30B41D990205E1A2698800B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"{'input_ids': [[101, 5745, 2455, 7563, 3221, 784, 720, 3198, 952, 6158, 818, 711, 712, 3136, 4638, 8043, 102, 5745, 2455, 7563, 3364, 3322, 8020, 8024, 8021, 8024, 1760, 1399, 924, 4882, 185, 5735, 4449, 8020, 8021, 8024, 3221, 6632, 1298, 5384, 7716, 1921, 712, 3136, 3364, 3322, 511, 9155, 2399, 6158, 818, 711, 712, 3136, 8039, 8431, 2399, 6158, 3091, 1285, 711, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2134, 2429, 5392, 4415, 8039, 8447, 2399, 6158, 3091, 1285, 711, 2600, 712, 3136, 8024, 1398, 2399, 2399, 2419, 6158, 3091, 1285, 711, 3364, 3322, 8039, 8170, 2399, 123, 3299, 4895, 686, 511, 5745, 2455, 7563, 754, 9915, 2399, 127, 3299, 8115, 3189, 1762, 6632, 1298, 2123, 2398, 4689, 1921, 712, 3136, 1355, 5683, 3136, 1277, 1139, 4495, 8039, 4997, 2399, 3198, 2970, 1358, 5679, 1962, 3136, 5509, 1400, 8024, 6158, 671, 855, 6632, 1298, 4868, 4266, 2372, 1168, 3777, 1079, 5326, 5330, 1071, 2110, 689, 511, 5745, 2455, 7563, 754, 9211, 2399, 1762, 3777, 1079, 1920, 934, 6887, 7368, 2130, 2768, 4868, 2110, 2110, 689, 511, 5745, 2455, 7563, 754, 8594, 2399, 127, 3299, 127, 3189, 1762, 3777, 1079, 4638, 712, 3136, 2429, 1828, 3232, 7195, 8039, 1350, 1400, 6158, 3836, 1168, 1760, 1957, 2207, 2548, 1065, 2109, 1036, 7368, 3302, 1218, 511, 8707, 2399, 807, 8024, 5745, 2455, 7563, 1762, 3777, 1079, 1828, 1277, 1158, 2456, 4919, 3696, 2970, 2521, 704, 2552, 809, 3119, 2159, 1168, 3777, 1079, 6912, 2773, 4638, 7410, 3696, 511, 9258, 2399, 8024, 3791, 6632, 2773, 751, 5310, 3338, 8024, 6632, 1298, 3696, 712, 1066, 1469, 1744, 2456, 6963, 3777, 1079, 8024, 2496, 3198, 2523, 1914, 1921, 712, 3136, 4868, 5466, 782, 1447, 6845, 5635, 6632, 1298, 4638, 1298, 3175, 8024, 852, 5745, 2455, 7563, 793, 4197, 4522, 1762, 3777, 1079, 511, 5422, 2399, 102], [101, 5745, 2455, 7563, 3221, 784, 720, 3198, 952, 6158, 818, 711, 712, 3136, 4638, 8043, 102, 6632, 2773, 751, 5310, 3338, 8024, 6632, 1298, 3696, 712, 1066, 1469, 1744, 2456, 6963, 3777, 1079, 8024, 2496, 3198, 2523, 1914, 1921, 712, 3136, 4868, 5466, 782, 1447, 6845, 5635, 6632, 1298, 4638, 1298, 3175, 8024, 852, 5745, 2455, 7563, 793, 4197, 4522, 1762, 3777, 1079, 511, 5422, 2399, 5052, 4415, 1760, 5735, 3307, 2207, 934, 7368, 8039, 2668, 1762, 8779, 2399, 1728, 2932, 1310, 934, 7368, 4638, 5632, 4507, 510, 5632, 3780, 1350, 2867, 5318, 3124, 2424, 1762, 934, 7368, 6392, 3124, 3780, 6440, 4638, 6206, 3724, 5445, 6158, 2936, 511, 9155, 2399, 125, 3299, 126, 3189, 8024, 3136, 2134, 818, 1462, 5745, 2455, 7563, 711, 1921, 712, 3136, 1266, 2123, 3136, 1277, 712, 3136, 8024, 1398, 2399, 129, 3299, 8115, 3189, 2218, 818, 8039, 1071, 4288, 7208, 711, 519, 2769, 928, 1921, 712, 4638, 4263, 520, 511, 4507, 754, 5745, 2455, 7563, 6158, 6632, 1298, 3124, 2424, 6763, 4881, 2345, 679, 1914, 8114, 2399, 8024, 1728, 3634, 800, 3187, 3791, 1168, 2792, 2247, 1828, 1277, 6822, 6121, 4288, 4130, 2339, 868, 5445, 683, 3800, 4777, 6438, 5023, 2339, 868, 511, 5745, 2455, 7563, 7370, 749, 7481, 2190, 2773, 751, 510, 6577, 1737, 510, 6158, 2496, 2229, 6833, 2154, 1921, 712, 3136, 833, 5023, 7309, 7579, 1912, 8024, 738, 4908, 2166, 2612, 1908, 934, 7368, 510, 1158, 2456, 1957, 934, 833, 1730, 860, 5023, 511, 8431, 2399, 8024, 3136, 2134, 5735, 3307, 924, 4882, 753, 686, 1762, 1398, 2399, 127, 3299, 8123, 3189, 3091, 1285, 5745, 2455, 7563, 711, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2134, 2429, 5392, 4415, 809, 1856, 6133, 6421, 3136, 1277, 2600, 712, 3136, 4638, 4958, 5375, 511, 8447, 2399, 124, 3299, 8133, 3189, 102], [101, 5745, 2455, 7563, 3221, 784, 720, 3198, 952, 6158, 818, 711, 712, 3136, 4638, 8043, 102, 5735, 3307, 924, 4882, 753, 686, 1762, 1398, 2399, 127, 3299, 8123, 3189, 3091, 1285, 5745, 2455, 7563, 711, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2134, 2429, 5392, 4415, 809, 1856, 6133, 6421, 3136, 1277, 2600, 712, 3136, 4638, 4958, 5375, 511, 8447, 2399, 124, 3299, 8133, 3189, 8024, 5745, 2455, 7563, 6158, 3136, 2134, 5735, 3307, 924, 4882, 753, 686, 3091, 1285, 711, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2600, 712, 3136, 2400, 1076, 1921, 712, 3136, 6446, 2255, 3136, 1277, 2134, 2429, 5392, 4415, 8039, 1398, 2399, 8111, 3299, 8153, 3189, 8024, 5735, 3307, 924, 4882, 753, 686, 3091, 1285, 5745, 2455, 7563, 711, 3364, 3322, 511, 5745, 2455, 7563, 1762, 8396, 2399, 5635, 8285, 2399, 3309, 7313, 1139, 818, 1921, 712, 3136, 6632, 1298, 712, 3136, 1730, 712, 2375, 511, 8263, 2399, 125, 3299, 8153, 3189, 8024, 3136, 2134, 5735, 3307, 924, 4882, 753, 686, 818, 1462, 1921, 712, 3136, 6446, 2255, 3136, 1277, 1076, 1921, 712, 3136, 7770, 2398, 3136, 1277, 1426, 1045, 3345, 712, 3136, 711, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 5392, 4415, 712, 3136, 8039, 1350, 5635, 8232, 2399, 123, 3299, 8131, 3189, 8024, 5745, 2455, 7563, 1728, 5815, 2821, 6791, 1343, 2600, 712, 3136, 5466, 1218, 5445, 5783, 828, 8039, 1426, 1045, 3345, 1398, 3189, 4696, 7370, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2600, 712, 3136, 5466, 1218, 511, 5745, 2455, 7563, 754, 8170, 2399, 123, 3299, 8130, 3189, 3926, 3247, 1762, 3777, 1079, 4895, 686, 8024, 775, 2399, 8426, 2259, 8039, 1071, 5873, 4851, 754, 1398, 3299, 8153, 3189, 677, 1286, 1762, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2600, 712, 3136, 2429, 1828, 102], [101, 5745, 2455, 7563, 3221, 784, 720, 3198, 952, 6158, 818, 711, 712, 3136, 4638, 8043, 102, 5466, 1218, 511, 5745, 2455, 7563, 754, 8170, 2399, 123, 3299, 8130, 3189, 3926, 3247, 1762, 3777, 1079, 4895, 686, 8024, 775, 2399, 8426, 2259, 8039, 1071, 5873, 4851, 754, 1398, 3299, 8153, 3189, 677, 1286, 1762, 1921, 712, 3136, 3777, 1079, 2600, 3136, 1277, 2600, 712, 3136, 2429, 1828, 715, 6121, 511, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'overflow_to_sample_mapping': [0, 0, 0, 0]}\n","name":"stdout"}],"source":"context = train_data[0][\"context\"] # \nquestion = train_data[0][\"question\"]\n\ninputs = tokenizer(\n    question,\n    context,\n    max_length=300,# æœ€å¤§é•¿åº¦\n    truncation=\"only_second\",# ä»…å¯¹ç¬¬äºŒä¸ªè¾“å…¥è¿›è¡Œæˆªæ–­\n    stride=50,# æ»‘åŠ¨çª—å£å¤§å°ä¸º50\n    return_overflowing_tokens=True,#è®¾å®šåˆ†è¯å™¨æ”¯æŒè¿”å›é‡å  tokenã€‚\n)\nprint(inputs)"},{"metadata":{"id":"2F83F136CFF84C53851E15DABB3D020B","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"'èŒƒå»·é¢‚æ¢æœºï¼ˆï¼Œï¼‰ï¼Œåœ£åä¿ç¦„Â·è‹¥ç‘Ÿï¼ˆï¼‰ï¼Œæ˜¯è¶Šå—ç½—é©¬å¤©ä¸»æ•™æ¢æœºã€‚1963å¹´è¢«ä»»ä¸ºä¸»æ•™ï¼›1990å¹´è¢«æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºå®—åº§ç½²ç†ï¼›1994å¹´è¢«æ“¢å‡ä¸ºæ€»ä¸»æ•™ï¼ŒåŒå¹´å¹´åº•è¢«æ“¢å‡ä¸ºæ¢æœºï¼›2009å¹´2æœˆç¦»ä¸–ã€‚èŒƒå»·é¢‚äº1919å¹´6æœˆ15æ—¥åœ¨è¶Šå—å®å¹³çœå¤©ä¸»æ•™å‘è‰³æ•™åŒºå‡ºç”Ÿï¼›ç«¥å¹´æ—¶æ¥å—è‰¯å¥½æ•™è‚²åï¼Œè¢«ä¸€ä½è¶Šå—ç¥çˆ¶å¸¦åˆ°æ²³å†…ç»§ç»­å…¶å­¦ä¸šã€‚èŒƒå»·é¢‚äº1940å¹´åœ¨æ²³å†…å¤§ä¿®é“é™¢å®Œæˆç¥å­¦å­¦ä¸šã€‚èŒƒå»·é¢‚äº1949å¹´6æœˆ6æ—¥åœ¨æ²³å†…çš„ä¸»æ•™åº§å ‚æ™‹é“ï¼›åŠåè¢«æ´¾åˆ°åœ£å¥³å°å¾·å…°å­¤å„¿é™¢æœåŠ¡ã€‚1950å¹´ä»£ï¼ŒèŒƒå»·é¢‚åœ¨æ²³å†…å ‚åŒºåˆ›å»ºç§»æ°‘æ¥å¾…ä¸­å¿ƒä»¥æ”¶å®¹åˆ°æ²³å†…é¿æˆ˜çš„éš¾æ°‘ã€‚1954å¹´ï¼Œæ³•è¶Šæˆ˜äº‰ç»“æŸï¼Œè¶Šå—æ°‘ä¸»å…±å’Œå›½å»ºéƒ½æ²³å†…ï¼Œå½“æ—¶å¾ˆå¤šå¤©ä¸»æ•™ç¥èŒäººå‘˜é€ƒè‡³è¶Šå—çš„å—æ–¹ï¼Œä½†èŒƒå»·é¢‚ä»ç„¶ç•™åœ¨æ²³å†…ã€‚ç¿Œå¹´ç®¡ç†åœ£è‹¥æœ›å°ä¿®é™¢ï¼›æƒŸåœ¨1960å¹´å› æå«ä¿®é™¢çš„è‡ªç”±ã€è‡ªæ²»åŠæ‹’ç»æ”¿åºœåœ¨ä¿®é™¢è®¾æ”¿æ²»è¯¾çš„è¦æ±‚è€Œè¢«æ•ã€‚1963å¹´4æœˆ5æ—¥ï¼Œæ•™å®—ä»»å‘½èŒƒå»·é¢‚ä¸ºå¤©ä¸»æ•™åŒ—å®æ•™åŒºä¸»æ•™ï¼ŒåŒå¹´8æœˆ15æ—¥å°±ä»»ï¼›å…¶ç‰§é“­ä¸ºã€Œæˆ‘ä¿¡å¤©ä¸»çš„çˆ±ã€ã€‚ç”±äºèŒƒå»·é¢‚è¢«è¶Šå—æ”¿åºœè½¯ç¦å·®ä¸å¤š30å¹´ï¼Œå› æ­¤ä»–æ— æ³•åˆ°æ‰€å±å ‚åŒºè¿›è¡Œç‰§çµå·¥ä½œè€Œä¸“æ³¨ç ”è¯»ç­‰å·¥ä½œã€‚èŒƒå»·é¢‚é™¤äº†é¢å¯¹æˆ˜äº‰ã€è´«å›°ã€è¢«å½“å±€è¿«å®³å¤©ä¸»æ•™ä¼šç­‰é—®é¢˜å¤–ï¼Œä¹Ÿç§˜å¯†æ¢å¤ä¿®é™¢ã€åˆ›å»ºå¥³ä¿®ä¼šå›¢ä½“ç­‰ã€‚1990å¹´ï¼Œæ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–åœ¨åŒå¹´6æœˆ18æ—¥æ“¢å‡èŒƒå»·é¢‚ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºå®—åº§ç½²ç†ä»¥å¡«è¡¥è¯¥æ•™åŒºæ€»ä¸»æ•™çš„ç©ºç¼ºã€‚1994å¹´3æœˆ23æ—¥ï¼ŒèŒƒå»·é¢‚è¢«æ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™å¹¶å…¼å¤©ä¸»æ•™è°…å±±æ•™åŒºå®—åº§ç½²ç†ï¼›åŒå¹´11æœˆ26æ—¥ï¼Œè‹¥æœ›ä¿ç¦„äºŒä¸–æ“¢å‡èŒƒå»·é¢‚ä¸ºæ¢æœºã€‚èŒƒå»·é¢‚åœ¨1995å¹´è‡³2001å¹´æœŸé—´å‡ºä»»å¤©ä¸»æ•™è¶Šå—ä¸»æ•™å›¢ä¸»å¸­ã€‚2003å¹´4æœˆ26æ—¥ï¼Œæ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–ä»»å‘½å¤©ä¸»æ•™è°…å±±æ•™åŒºå…¼å¤©ä¸»æ•™é«˜å¹³æ•™åŒºå´å…‰æ°ä¸»æ•™ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºç½²ç†ä¸»æ•™ï¼›åŠè‡³2005å¹´2æœˆ19æ—¥ï¼ŒèŒƒå»·é¢‚å› è·æ‰¹è¾å»æ€»ä¸»æ•™èŒåŠ¡è€Œè£ä¼‘ï¼›å´å…‰æ°åŒæ—¥çœŸé™¤å¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™èŒåŠ¡ã€‚èŒƒå»·é¢‚äº2009å¹´2æœˆ22æ—¥æ¸…æ™¨åœ¨æ²³å†…ç¦»ä¸–ï¼Œäº«å¹´89å²ï¼›å…¶è‘¬ç¤¼äºåŒæœˆ26æ—¥ä¸Šåˆåœ¨å¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™åº§å ‚ä¸¾è¡Œã€‚'"},"transient":{}}],"source":"context","execution_count":37},{"metadata":{"id":"B873778CB43840E58C131154F7A37799","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"4"},"transient":{}}],"source":"len(inputs['input_ids'])","execution_count":14},{"cell_type":"code","execution_count":13,"metadata":{"id":"AC631AEE902D416DBF80E6218B7C7004","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"815"},"transient":{}}],"source":"len(context)"},{"cell_type":"markdown","metadata":{"id":"28DD15785E954C03BB2968A8282316B0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"å¯¹åˆ†è¯ä¹‹åçš„idè¿›è¡Œè¿˜åŸä¸ºå­—ç¬¦ä¸²å­—ç¬¦,è¿™ä¸ªæ˜¯é¢„è®­ç»ƒæ¨¡å‹ä¸­çš„vocab.txtå¯¹åº”çš„"},{"cell_type":"code","execution_count":9,"metadata":{"id":"90E64E3E6DAA49688986F3375D51C3BE","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS] èŒƒ å»· é¢‚ æ˜¯ ä»€ ä¹ˆ æ—¶ å€™ è¢« ä»» ä¸º ä¸» æ•™ çš„ ï¼Ÿ [SEP] èŒƒ å»· é¢‚ æ¢ æœº ï¼ˆ ï¼Œ ï¼‰ ï¼Œ åœ£ å ä¿ ç¦„ Â· è‹¥ ç‘Ÿ ï¼ˆ ï¼‰ ï¼Œ æ˜¯ è¶Š å— ç½— é©¬ å¤© ä¸» æ•™ æ¢ æœº ã€‚ 1963 å¹´ è¢« ä»» ä¸º ä¸» æ•™ ï¼› 1990 å¹´ è¢« æ“¢ å‡ ä¸º å¤© ä¸» æ•™ æ²³ å†… æ€» æ•™ åŒº å®— åº§ ç½² ç† ï¼› 1994 å¹´ è¢« æ“¢ å‡ ä¸º æ€» ä¸» æ•™ ï¼Œ åŒ å¹´ å¹´ åº• è¢« æ“¢ å‡ ä¸º æ¢ æœº ï¼› 2009 å¹´ 2 æœˆ ç¦» ä¸– ã€‚ èŒƒ å»· é¢‚ äº 1919 å¹´ 6 æœˆ 15 æ—¥ åœ¨ è¶Š å— å® å¹³ çœ å¤© ä¸» æ•™ å‘ è‰³ æ•™ åŒº å‡º ç”Ÿ ï¼› ç«¥ å¹´ æ—¶ æ¥ å— è‰¯ å¥½ æ•™ è‚² å ï¼Œ è¢« ä¸€ ä½ è¶Š å— ç¥ çˆ¶ å¸¦ åˆ° æ²³ å†… ç»§ ç»­ å…¶ å­¦ ä¸š ã€‚ èŒƒ å»· é¢‚ äº 1940 å¹´ åœ¨ æ²³ å†… å¤§ ä¿® é“ é™¢ å®Œ æˆ ç¥ å­¦ å­¦ ä¸š ã€‚ èŒƒ å»· é¢‚ äº 1949 å¹´ 6 æœˆ 6 æ—¥ åœ¨ æ²³ å†… çš„ ä¸» æ•™ åº§ å ‚ æ™‹ é“ ï¼› åŠ å è¢« æ´¾ åˆ° åœ£ å¥³ å° å¾· å…° å­¤ å„¿ é™¢ æœ åŠ¡ ã€‚ 1950 å¹´ ä»£ ï¼Œ èŒƒ å»· é¢‚ åœ¨ æ²³ å†… å ‚ åŒº åˆ› å»º ç§» æ°‘ æ¥ å¾… ä¸­ å¿ƒ ä»¥ æ”¶ å®¹ åˆ° æ²³ å†… é¿ æˆ˜ çš„ éš¾ æ°‘ ã€‚ 1954 å¹´ ï¼Œ æ³• è¶Š æˆ˜ äº‰ ç»“ æŸ ï¼Œ è¶Š å— æ°‘ ä¸» å…± å’Œ å›½ å»º éƒ½ æ²³ å†… ï¼Œ å½“ æ—¶ å¾ˆ å¤š å¤© ä¸» æ•™ ç¥ èŒ äºº å‘˜ é€ƒ è‡³ è¶Š å— çš„ å— æ–¹ ï¼Œ ä½† èŒƒ å»· é¢‚ ä» ç„¶ ç•™ åœ¨ æ²³ å†… ã€‚ ç¿Œ å¹´ [SEP]\n","[CLS] èŒƒ å»· é¢‚ æ˜¯ ä»€ ä¹ˆ æ—¶ å€™ è¢« ä»» ä¸º ä¸» æ•™ çš„ ï¼Ÿ [SEP] è¶Š æˆ˜ äº‰ ç»“ æŸ ï¼Œ è¶Š å— æ°‘ ä¸» å…± å’Œ å›½ å»º éƒ½ æ²³ å†… ï¼Œ å½“ æ—¶ å¾ˆ å¤š å¤© ä¸» æ•™ ç¥ èŒ äºº å‘˜ é€ƒ è‡³ è¶Š å— çš„ å— æ–¹ ï¼Œ ä½† èŒƒ å»· é¢‚ ä» ç„¶ ç•™ åœ¨ æ²³ å†… ã€‚ ç¿Œ å¹´ ç®¡ ç† åœ£ è‹¥ æœ› å° ä¿® é™¢ ï¼› æƒŸ åœ¨ 1960 å¹´ å›  æ å« ä¿® é™¢ çš„ è‡ª ç”± ã€ è‡ª æ²» åŠ æ‹’ ç» æ”¿ åºœ åœ¨ ä¿® é™¢ è®¾ æ”¿ æ²» è¯¾ çš„ è¦ æ±‚ è€Œ è¢« æ• ã€‚ 1963 å¹´ 4 æœˆ 5 æ—¥ ï¼Œ æ•™ å®— ä»» å‘½ èŒƒ å»· é¢‚ ä¸º å¤© ä¸» æ•™ åŒ— å® æ•™ åŒº ä¸» æ•™ ï¼Œ åŒ å¹´ 8 æœˆ 15 æ—¥ å°± ä»» ï¼› å…¶ ç‰§ é“­ ä¸º ã€Œ æˆ‘ ä¿¡ å¤© ä¸» çš„ çˆ± ã€ ã€‚ ç”± äº èŒƒ å»· é¢‚ è¢« è¶Š å— æ”¿ åºœ è½¯ ç¦ å·® ä¸ å¤š 30 å¹´ ï¼Œ å›  æ­¤ ä»– æ—  æ³• åˆ° æ‰€ å± å ‚ åŒº è¿› è¡Œ ç‰§ çµ å·¥ ä½œ è€Œ ä¸“ æ³¨ ç ” è¯» ç­‰ å·¥ ä½œ ã€‚ èŒƒ å»· é¢‚ é™¤ äº† é¢ å¯¹ æˆ˜ äº‰ ã€ è´« å›° ã€ è¢« å½“ å±€ è¿« å®³ å¤© ä¸» æ•™ ä¼š ç­‰ é—® é¢˜ å¤– ï¼Œ ä¹Ÿ ç§˜ å¯† æ¢ å¤ ä¿® é™¢ ã€ åˆ› å»º å¥³ ä¿® ä¼š å›¢ ä½“ ç­‰ ã€‚ 1990 å¹´ ï¼Œ æ•™ å®— è‹¥ æœ› ä¿ ç¦„ äºŒ ä¸– åœ¨ åŒ å¹´ 6 æœˆ 18 æ—¥ æ“¢ å‡ èŒƒ å»· é¢‚ ä¸º å¤© ä¸» æ•™ æ²³ å†… æ€» æ•™ åŒº å®— åº§ ç½² ç† ä»¥ å¡« è¡¥ è¯¥ æ•™ åŒº æ€» ä¸» æ•™ çš„ ç©º ç¼º ã€‚ 1994 å¹´ 3 æœˆ 23 æ—¥ [SEP]\n","[CLS] èŒƒ å»· é¢‚ æ˜¯ ä»€ ä¹ˆ æ—¶ å€™ è¢« ä»» ä¸º ä¸» æ•™ çš„ ï¼Ÿ [SEP] è‹¥ æœ› ä¿ ç¦„ äºŒ ä¸– åœ¨ åŒ å¹´ 6 æœˆ 18 æ—¥ æ“¢ å‡ èŒƒ å»· é¢‚ ä¸º å¤© ä¸» æ•™ æ²³ å†… æ€» æ•™ åŒº å®— åº§ ç½² ç† ä»¥ å¡« è¡¥ è¯¥ æ•™ åŒº æ€» ä¸» æ•™ çš„ ç©º ç¼º ã€‚ 1994 å¹´ 3 æœˆ 23 æ—¥ ï¼Œ èŒƒ å»· é¢‚ è¢« æ•™ å®— è‹¥ æœ› ä¿ ç¦„ äºŒ ä¸– æ“¢ å‡ ä¸º å¤© ä¸» æ•™ æ²³ å†… æ€» æ•™ åŒº æ€» ä¸» æ•™ å¹¶ å…¼ å¤© ä¸» æ•™ è°… å±± æ•™ åŒº å®— åº§ ç½² ç† ï¼› åŒ å¹´ 11 æœˆ 26 æ—¥ ï¼Œ è‹¥ æœ› ä¿ ç¦„ äºŒ ä¸– æ“¢ å‡ èŒƒ å»· é¢‚ ä¸º æ¢ æœº ã€‚ èŒƒ å»· é¢‚ åœ¨ 1995 å¹´ è‡³ 2001 å¹´ æœŸ é—´ å‡º ä»» å¤© ä¸» æ•™ è¶Š å— ä¸» æ•™ å›¢ ä¸» å¸­ ã€‚ 2003 å¹´ 4 æœˆ 26 æ—¥ ï¼Œ æ•™ å®— è‹¥ æœ› ä¿ ç¦„ äºŒ ä¸– ä»» å‘½ å¤© ä¸» æ•™ è°… å±± æ•™ åŒº å…¼ å¤© ä¸» æ•™ é«˜ å¹³ æ•™ åŒº å´ å…‰ æ° ä¸» æ•™ ä¸º å¤© ä¸» æ•™ æ²³ å†… æ€» æ•™ åŒº ç½² ç† ä¸» æ•™ ï¼› åŠ è‡³ 2005 å¹´ 2 æœˆ 19 æ—¥ ï¼Œ èŒƒ å»· é¢‚ å›  è· æ‰¹ è¾ å» æ€» ä¸» æ•™ èŒ åŠ¡ è€Œ è£ ä¼‘ ï¼› å´ å…‰ æ° åŒ æ—¥ çœŸ é™¤ å¤© ä¸» æ•™ æ²³ å†… æ€» æ•™ åŒº æ€» ä¸» æ•™ èŒ åŠ¡ ã€‚ èŒƒ å»· é¢‚ äº 2009 å¹´ 2 æœˆ 22 æ—¥ æ¸… æ™¨ åœ¨ æ²³ å†… ç¦» ä¸– ï¼Œ äº« å¹´ 89 å² ï¼› å…¶ è‘¬ ç¤¼ äº åŒ æœˆ 26 æ—¥ ä¸Š åˆ åœ¨ å¤© ä¸» æ•™ æ²³ å†… æ€» æ•™ åŒº æ€» ä¸» æ•™ åº§ å ‚ [SEP]\n","[CLS] èŒƒ å»· é¢‚ æ˜¯ ä»€ ä¹ˆ æ—¶ å€™ è¢« ä»» ä¸º ä¸» æ•™ çš„ ï¼Ÿ [SEP] èŒ åŠ¡ ã€‚ èŒƒ å»· é¢‚ äº 2009 å¹´ 2 æœˆ 22 æ—¥ æ¸… æ™¨ åœ¨ æ²³ å†… ç¦» ä¸– ï¼Œ äº« å¹´ 89 å² ï¼› å…¶ è‘¬ ç¤¼ äº åŒ æœˆ 26 æ—¥ ä¸Š åˆ åœ¨ å¤© ä¸» æ•™ æ²³ å†… æ€» æ•™ åŒº æ€» ä¸» æ•™ åº§ å ‚ ä¸¾ è¡Œ ã€‚ [SEP]\n"]}],"source":"for ids in inputs[\"input_ids\"]:\n    print(tokenizer.decode(ids))"},{"cell_type":"markdown","metadata":{"id":"89C532CF165B48949EA337BB992E18DB","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"ä¸‹é¢æ˜¯ tokenizerå¯ä»¥æ¥å—å¤šä¸ªæ ·æœ¬ï¼Œä¹Ÿå°±æ˜¯å¤šæ¡é—®é¢˜å’Œä¸Šä¸‹æ–‡å¯ä»¥ä¸€èµ·è¾“å…¥è¿›å»ï¼š"},{"cell_type":"code","execution_count":15,"metadata":{"id":"771170E2FE2B485486B1366A2334B68B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])\nThe 4 examples gave 14 features.\nHere is where each comes from: [0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3].\n","name":"stdout"}],"source":"contexts = [train_data[idx][\"context\"] for idx in range(4)]\nquestions = [train_data[idx][\"question\"] for idx in range(4)]\n\ninputs = tokenizer(\n    questions,\n    contexts,\n    max_length=300,\n    truncation=\"only_second\",\n    stride=50,\n    return_overflowing_tokens=True,\n    return_offsets_mapping=True\n)\n\nprint(inputs.keys())\nprint(f\"The 4 examples gave {len(inputs['input_ids'])} features.\")\nprint(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")"},{"metadata":{"id":"58140DAE834A452EBB5C6770E6BC25FB","notebookId":"62556e9030fa900018de3878","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"14"},"transient":{}}],"source":"len(inputs['offset_mapping'])","execution_count":18},{"cell_type":"code","execution_count":11,"metadata":{"id":"4309745858F144159887D25DF04AAAAF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":"# inputs"},{"cell_type":"markdown","metadata":{"id":"EB6DAC74B4564DE9918C316F58AEE0CE","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"å¯ä»¥çœ‹åˆ°ï¼Œé€šè¿‡è®¾ç½® return_overflowing_tokens å’Œ return_offsets_mappingï¼Œç¼–ç ç»“æœä¸­é™¤äº† input_idsã€token_type_ids å’Œattention_mask ä»¥å¤–ï¼Œè¿˜è¿”å›äº†è®°å½• token åˆ°åŸæ–‡æ˜ å°„çš„ offset_mappingï¼Œä»¥åŠè®°å½•åˆ†å—æ ·æœ¬åˆ°åŸå§‹æ ·æœ¬æ˜ å°„çš„ overflow_to_sample_mappingã€‚\n\nä»â€œ[0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3].â€æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç¬¬1ä¸ªæ ·æœ¬å’Œå’Œç¬¬4ä¸ªæ ·æœ¬è¢«åˆ†æˆäº†4ä¸ªæ–°çš„æ ·æœ¬ï¼Œç¬¬2ä¸ªå’Œç¬¬3ä¸ªæ ·æœ¬è¢«åˆ†æˆäº†3ä¸ªæ ·æœ¬ã€‚\n"},{"cell_type":"markdown","metadata":{"id":"933CCD7591B142B0A9671394DA6B86CD","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"sequence_ids:https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.BatchEncoding.sequence_ids\n\nè¿”å›tokenæ¥è‡ªåŸå§‹å“ªä¸ªå¥å­ï¼š\n\n- None ä»£è¡¨æ˜¯ç‰¹æ®Štokenï¼Œæ¯”å¦‚CLSï¼ŒSEPç­‰\n- 0 ä»£è¡¨tokenæ¥è‡ªç¬¬ä¸€ä¸ªå¥å­\n- 1 ä»£è¡¨tokenæ¥è‡ªç¬¬äºŒä¸ªå¥å­"},{"cell_type":"code","execution_count":12,"metadata":{"id":"FCDEB849E3384F8AA9C6BB18808DF930","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["14"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":"len(inputs[\"offset_mapping\"])"},{"cell_type":"code","execution_count":13,"metadata":{"id":"9722EFDBA82A45B8807AA8E5EE44ECA2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["300"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":"len(inputs[\"offset_mapping\"][0])"},{"cell_type":"code","execution_count":14,"metadata":{"id":"FDEEADBFC96A465BA68995D37E8CD929","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[47, 0, 0, 0, 53, 0, 0, 100, 0, 0, 0, 0, 61, 0]\n","[48, 0, 0, 0, 70, 0, 0, 124, 0, 0, 0, 0, 106, 0]\n"]}],"source":"answers = [train_data[idx][\"answers\"] for idx in range(4)]\nstart_positions = []\nend_positions = []\n\nfor i, offset in enumerate(inputs[\"offset_mapping\"]):\n    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n    answer = answers[sample_idx]\n    start_char = answer[\"answer_start\"][0]# ç­”æ¡ˆçš„å¼€å§‹ä½ç½®\n    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])# ç­”æ¡ˆçš„ç»ˆæ­¢ä½ç½®\n    sequence_ids = inputs.sequence_ids(i) # token çš„å¥å­æ ‡è®°\n\n    # Find the start and end of the context\n    # æ‰¾åˆ°contextçš„å¼€å§‹å’Œç»ˆæ­¢ä½ç½®\n    idx = 0 # è®°å½•ç¬¬ä¸€ä¸ªå¥å­çš„ç´¢å¼•\n    while sequence_ids[idx] != 1:\n        idx += 1\n    context_start = idx # contextçš„å¼€å§‹\n    while sequence_ids[idx] == 1:\n        idx += 1\n    context_end = idx - 1\n\n    # If the answer is not fully inside the context, label is (0, 0)\n    # å¦‚æœç­”æ¡ˆansweræ²¡æœ‰å®Œå…¨åœ¨contextï¼Œlabelä¸ºï¼ˆ0,0ï¼‰\n    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n        start_positions.append(0)\n        end_positions.append(0)\n    else:\n        # Otherwise it's the start and end token positions\n        # ä¸‹é¢ä¸ºç­”æ¡ˆå®Œå…¨åœ¨contextä¸Šä¸‹æ–‡ä¸­\n        idx = context_start\n        while idx <= context_end and offset[idx][0] <= start_char:\n            idx += 1\n        start_positions.append(idx - 1)\n\n        idx = context_end\n        while idx >= context_start and offset[idx][1] >= end_char:\n            idx -= 1\n        end_positions.append(idx + 1)\n\nprint(start_positions)\nprint(end_positions)"},{"cell_type":"markdown","metadata":{"id":"81F13C87EF1347E988F06AB6DD9598FF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"ä¸‹é¢æˆ‘ä»¬åšä¸ªç®€å•çš„éªŒè¯ï¼Œä¾‹å¦‚å¯¹äºç¬¬ä¸€ä¸ªæ–°æ ·æœ¬ï¼Œå¯ä»¥çœ‹åˆ°å¤„ç†åçš„ç­”æ¡ˆæ ‡ç­¾ä¸º (47, 48)ï¼Œæˆ‘ä»¬å°†å¯¹åº”çš„ token è§£ç å¹¶ä¸æ ‡æ³¨ç­”æ¡ˆè¿›è¡Œå¯¹æ¯”ï¼š"},{"cell_type":"code","execution_count":15,"metadata":{"id":"920DD7678FB1448C87D7F883191816B1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["çœŸå® answer: 1963å¹´, æ„å»ºçš„labels ä¸º: 1963 å¹´\n"]}],"source":"idx = 0 # ç¬¬ä¸€ä¸ªæ ·æœ¬\nsample_idx = inputs[\"overflow_to_sample_mapping\"][idx]  # ç¬¬ä¸€ä¸ªæ ·æœ¬æ¥è‡ªçš„å“ªä¸ªåŸå§‹æ ·æœ¬\nanswer = answers[sample_idx][\"text\"][0]\n\nstart = start_positions[idx] # ç­”æ¡ˆå¼€å§‹ä½ç½®\nend = end_positions[idx] # ç­”æ¡ˆç»ˆæ­¢ä½ç½®\nlabeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1]) # ä¸Šä¸‹æ–‡åˆ†è¯idæ ¹æ®è½¬ä¸ºç­”æ¡ˆ\n\nprint(f\"çœŸå® answer: {answer}, æ„å»ºçš„labels ä¸º: {labeled_answer}\")"},{"cell_type":"markdown","metadata":{"id":"82F61828D2EA4968849DD159FAEC6746","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"### è®­ç»ƒæ‰¹å¤„ç†å‡½æ•°"},{"cell_type":"code","execution_count":16,"metadata":{"id":"EDAF2327648F4582B9B88EDF955CAC03","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":"from torch.utils.data import DataLoader\n\nmax_length = 384 # æ–‡æœ¬æœ€å¤§é•¿åº¦\nstride = 128 # æ»‘çª—å¤§å°\n\ndef train_collote_fn(batch_samples):\n    # batch_samplesä¸€æ‰¹æ ·æœ¬ï¼Œåœ¨DataLoaderæ‰§è¡Œæ“ä½œ\n    batch_question, batch_context, batch_answers = [], [], [] #\n    for sample in batch_samples:\n        batch_question.append(sample['question'])\n        batch_context.append(sample['context'])\n        batch_answers.append(sample['answers'])\n    \n    # å¯¹ä¸€æ•´æ‰¹é—®é¢˜ä¸ä¸Šä¸‹æ–‡è¿›è¡Œç¼–ç \n    batch_data = tokenizer(\n        batch_question,\n        batch_context,\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding='max_length'\n    )\n    \n    offset_mapping = batch_data.pop('offset_mapping')\n    sample_map = batch_data.pop('overflow_to_sample_mapping')\n\n    start_positions = []\n    end_positions = []\n    \n    # åœ¨contextå®šä½ç­”æ¡ˆå¼€å§‹å’Œç»“æŸçš„ä½ç½®ï¼ŒåŒä¸Šé¢æ¼”ç¤ºæ­¥éª¤ä¸€æ ·\n    for i, offset in enumerate(offset_mapping):\n        sample_idx = sample_map[i]\n        answer = batch_answers[sample_idx]\n        start_char = answer['answer_start'][0]\n        end_char = answer['answer_start'][0] + len(answer['text'][0])\n        sequence_ids = batch_data.sequence_ids(i)\n\n        # å¯»æ‰¾contextçš„å¼€å§‹å’Œç»“æŸä½ç½®\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label is (0, 0)\n        # å¦‚æœç­”æ¡ˆansweræ²¡æœ‰å®Œå…¨åœ¨contextï¼Œlabelä¸ºï¼ˆ0,0ï¼‰\n        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            # ä¸‹é¢ä¸ºç­”æ¡ˆå®Œå…¨åœ¨contextä¸Šä¸‹æ–‡ä¸­\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n    batch_data['start_positions'] = start_positions\n    batch_data['end_positions'] = end_positions\n    return batch_data\n \ntrain_dataloader = DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=train_collote_fn)# æ‰¹æ•°æ®å¤§å°ä¸º4"},{"cell_type":"code","execution_count":17,"metadata":{"id":"65EE52F3432446E3B7C9F2C60DFC80DC","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n","batch shape: {'input_ids': torch.Size([7, 384]), 'token_type_ids': torch.Size([7, 384]), 'attention_mask': torch.Size([7, 384]), 'start_positions': torch.Size([7]), 'end_positions': torch.Size([7])}\n","{'input_ids': tensor([[ 101, 7988, 7905,  ..., 4923, 2792,  102],\n","        [ 101, 7988, 7905,  ..., 7988, 7905,  102],\n","        [ 101, 7988, 7905,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 9213, 8354,  ...,    0,    0,    0],\n","        [ 101, 1762, 1525,  ..., 1398, 2399,  102],\n","        [ 101, 1762, 1525,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n","        [0, 0, 0,  ..., 1, 1, 1],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 1, 1, 1],\n","        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0]]), 'start_positions': tensor([ 71,   0,   0,  56, 113,   0, 158]), 'end_positions': tensor([161,   0,   0,  58, 151,   0, 172])}\n","train set size: \n","10142 -> 19189\n"]}],"source":"import torch\n\nbatch = next(iter(train_dataloader)) # é€‰å–ä¸€æ‰¹æ•°æ®\n\n# æ¯æ‰¹æ•°æ®åŒ…å«çš„å­—æ®µæœ‰ï¼šdict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\nbatch = {k: torch.tensor(v) for k, v in batch.items()}\nprint(batch.keys())\nprint('batch shape:', {k: v.shape for k, v in batch.items()})\nprint(batch)\n\nprint('train set size: ', )\nprint(len(train_data), '->', sum([len(batch_data['input_ids']) for batch_data in train_dataloader]))"},{"cell_type":"markdown","metadata":{"id":"2B32F1F2BBC94B7B9275CF49DC82D2ED","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"å¯ä»¥çœ‹åˆ°è¿”å›çš„æ•°æ®ä¸­é™¤äº†'input_ids', 'token_type_ids', 'attention_mask',è¿˜åŒ…æ‹¬ç­”æ¡ˆ'start_positions', 'end_positions'ï¼Œå¦å¤–å°±æ˜¯å› ä¸ºæˆ‘ä»¬å¯¹å¤§äºæœ€å¤§é•¿åº¦384è¿›è¡Œäº†åˆ’èˆ¹æ“ä½œï¼Œæœ€åæ‰€æœ‰åˆ†è¯ä¹‹åçš„idæ–‡æœ¬åºåˆ—ä¸ªæ•°æ€»å’Œä¸º19189ï¼ŒåŸå§‹æ–‡æœ¬ä¸ªæ•°ä¸º10142 "},{"cell_type":"markdown","metadata":{"id":"AEC99BBB6A6A48EEA285E678E88D7A58","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"```\nfrom transformers import default_data_collator\n\ntrain_dataloader = DataLoader(\n    new_train_dataset,\n    shuffle=True,\n    collate_fn=default_data_collator,\n    batch_size=8,\n)\n```"},{"cell_type":"markdown","metadata":{"id":"4BA5499B2ECF422B9FDEC0A1967B7662","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"### éªŒè¯/æµ‹è¯•æ‰¹å¤„ç†å‡½æ•°\n\n"},{"cell_type":"markdown","metadata":{"id":"7B83A06044F948598B3ECE9FB426655A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"å¯¹äºéªŒè¯/æµ‹è¯•é›†ï¼Œæˆ‘ä»¬å¹¶ä¸åœ¨æ„æ¨¡å‹é¢„æµ‹çš„æ ‡ç­¾ï¼Œè€Œæ˜¯å…³æ³¨é¢„æµ‹å‡ºçš„ç­”æ¡ˆæ–‡æœ¬ï¼Œè¿™å°±éœ€è¦ï¼šè®°å½•æ¯ä¸ªæ ·æœ¬è¢«åˆ†å—æˆäº†å“ªå‡ ä¸ªæ–°æ ·æœ¬ï¼Œä»è€Œåˆå¹¶å¯¹åº”çš„é¢„æµ‹ç»“æœï¼›åœ¨ offset mapping ä¸­æ ‡è®°é—®é¢˜çš„å¯¹åº” tokenï¼Œä»è€Œåœ¨åå¤„ç†é˜¶æ®µå¯ä»¥åŒºåˆ†å“ªäº›ä½ç½®çš„ token æ¥è‡ªäºä¸Šä¸‹æ–‡ã€‚\n\nå› æ­¤ï¼Œå¯¹åº”äºéªŒè¯é›†/æµ‹è¯•é›†çš„æ‰¹å¤„ç†å‡½æ•°ä¸ºï¼š"},{"cell_type":"code","execution_count":18,"metadata":{"id":"F72B316AB43D4B89A400E495157C13A7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":"def test_collote_fn(batch_samples):\n    batch_id, batch_question, batch_context = [], [], [] # é—®é¢˜æ ·æœ¬idã€é—®é¢˜æ–‡æœ¬ï¼Œä¸Šä¸‹æ–‡\n    for sample in batch_samples:\n        batch_id.append(sample['id'])\n        batch_question.append(sample['question'])\n        batch_context.append(sample['context'])\n    batch_data = tokenizer(\n        batch_question,\n        batch_context,\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n    \n    sample_map = batch_data.pop('overflow_to_sample_mapping')\n    example_ids = []\n\n    for i in range(len(batch_data['input_ids'])):\n        sample_idx = sample_map[i]\n        example_ids.append(batch_id[sample_idx])\n\n        sequence_ids = batch_data.sequence_ids(i)\n        offset = batch_data[\"offset_mapping\"][i]\n        batch_data[\"offset_mapping\"][i] = [\n            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n        ]# ä¸Šä¸‹æ–‡offset_mapping\n    batch_data[\"example_id\"] = example_ids\n    return batch_data\n\nvalid_dataloader = DataLoader(valid_data, batch_size=8, shuffle=False, collate_fn=test_collote_fn)"},{"cell_type":"markdown","metadata":{"id":"116D3EAF06E7402F9748F72258B20B3D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"åŒæ ·æˆ‘ä»¬æ‰“å°å‡ºä¸€ä¸ª batch ç¼–ç åçš„æ•°æ®ï¼Œå¹¶ä¸”è®¡ç®—åˆ†å—åæ–°æ•°æ®é›†çš„å¤§å°ï¼š"},{"cell_type":"code","execution_count":19,"metadata":{"id":"B0082535DCAE41588461772E3987949B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'])\n","['DEV_0_QUERY_0', 'DEV_0_QUERY_0', 'DEV_0_QUERY_1', 'DEV_0_QUERY_1', 'DEV_0_QUERY_2', 'DEV_0_QUERY_2', 'DEV_1_QUERY_0', 'DEV_1_QUERY_0', 'DEV_1_QUERY_1', 'DEV_1_QUERY_1', 'DEV_1_QUERY_2', 'DEV_1_QUERY_2', 'DEV_1_QUERY_3', 'DEV_1_QUERY_3', 'DEV_2_QUERY_0', 'DEV_2_QUERY_0']\n","valid set size: \n","3219 -> 6327\n"]}],"source":"batch = next(iter(valid_dataloader))\nprint(batch.keys())\nprint(batch['example_id'])\n\nprint('valid set size: ')\nprint(len(valid_data), '->', sum([len(batch_data['input_ids']) for batch_data in valid_dataloader]))"},{"cell_type":"markdown","metadata":{"id":"F5370A78C553470B82A3358FF92E325B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"å¯ä»¥çœ‹åˆ°ï¼Œç¼–ç ç»“æœä¸­é™¤äº† 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping',ä»¥åŠè®°å½•åˆ†å—æ ·æœ¬å¯¹åº” ID çš„ example_idã€‚ç»è¿‡åˆ†å—æ“ä½œåï¼Œæ•´ä¸ªæµ‹è¯•é›†çš„æ ·æœ¬æ•°é‡ä» 3219 å¢é•¿åˆ°äº† 6327ã€‚"},{"cell_type":"markdown","metadata":{"id":"5C009DFF7BC94CFF977A66A9689A5F09","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"## è®­ç»ƒæ¨¡å‹\næœ¬æ–‡æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ Transformers åº“è‡ªå¸¦çš„ AutoModelForQuestionAnswering å‡½æ•°æ¥æ„å»ºæ¨¡å‹ï¼Œå‰é¢å·²ç»é€šè¿‡æ‰¹å¤„ç†å‡½æ•°å°†è®­ç»ƒé›†å¤„ç†æˆäº†ç‰¹å®šæ ¼å¼ï¼Œå› æ­¤å¯ä»¥ç›´æ¥é€å…¥æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼š\n"},{"cell_type":"code","execution_count":20,"metadata":{"id":"D49A5EECF9844357B8D09C8B323D481A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":"from transformers import AutoModelForQuestionAnswering\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Using {device} device')\n"},{"cell_type":"code","execution_count":21,"metadata":{"id":"8177C122FD27423587E3E80E3D6E437F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at hfl/chinese-bert-wwm-ext were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at hfl/chinese-bert-wwm-ext and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\nmodel = model.to(device)"},{"cell_type":"code","execution_count":22,"metadata":{"id":"610980E1811B4376A9A185D2387DF3FE","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The hfl/chinese-bert-wwm-ext model has 199 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (21128, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layers ====\n","\n","bert.encoder.layer.11.attention.output.LayerNorm.weight       (768,)\n","bert.encoder.layer.11.attention.output.LayerNorm.bias         (768,)\n","bert.encoder.layer.11.intermediate.dense.weight          (3072, 768)\n","bert.encoder.layer.11.intermediate.dense.bias                (3072,)\n","bert.encoder.layer.11.output.dense.weight                (768, 3072)\n","bert.encoder.layer.11.output.dense.bias                       (768,)\n","bert.encoder.layer.11.output.LayerNorm.weight                 (768,)\n","bert.encoder.layer.11.output.LayerNorm.bias                   (768,)\n","qa_outputs.weight                                           (2, 768)\n","qa_outputs.bias                                                 (2,)\n"]}],"source":"# è·å–æ¨¡å‹æ‰€æœ‰çš„å‚æ•°\nparams = list(model.named_parameters())\n\nprint('The {} model has {:} different named parameters.\\n'.format(model_checkpoint,len(params)))\n\nprint('==== Embedding Layer ====\\n')\n\nfor p in params[0:5]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== First Transformer ====\\n')\n\nfor p in params[5:21]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== Output Layers ====\\n')\n\nfor p in params[-10:]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"},{"cell_type":"markdown","metadata":{"id":"6F26B2D18B36466D9F152D50FC61BB24","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"### è®­ç»ƒå‡½æ•°\nä½¿ç”¨ AutoModelForQuestionAnswering æ„é€ çš„æ¨¡å‹å·²ç»å°è£…å¥½äº†å¯¹åº”çš„æŸå¤±å‡½æ•°ï¼Œè®¡ç®—å‡ºçš„æŸå¤±ä¼šç›´æ¥åŒ…å«åœ¨æ¨¡å‹çš„è¾“å‡º outputs ä¸­ï¼ˆå¯ä»¥é€šè¿‡ outputs.loss è·å¾—ï¼‰ï¼Œå› æ­¤è®­ç»ƒå¾ªç¯ä¸ºï¼š"},{"cell_type":"code","execution_count":23,"metadata":{"id":"EBBCF73B5CFE44B69038166C16EFE5C9","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":"from tqdm.auto import tqdm\n\ndef train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n    progress_bar = tqdm(range(len(dataloader)))\n    progress_bar.set_description(f'loss: {0:>7f}')\n    finish_batch_num = (epoch-1) * len(dataloader)\n    \n    model.train()\n    for batch, batch_data in enumerate(dataloader, start=1):\n        batch_data = {k: torch.tensor(v).to(device) for k, v in batch_data.items()}\n        outputs = model(**batch_data)\n        loss = outputs.loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n\n        total_loss += loss.item()\n        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n        progress_bar.update(1)\n    return total_loss"},{"cell_type":"markdown","metadata":{"id":"12B206B92F9D422AA3683DBA7C69C3F0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"### åå¤„ç†\nå› ä¸ºæœ€ç»ˆæ˜¯æ ¹æ®é¢„æµ‹å‡ºçš„ç­”æ¡ˆæ–‡æœ¬æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œæ‰€ä»¥åœ¨ç¼–å†™éªŒè¯/æµ‹è¯•å¾ªç¯ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆè®¨è®ºä¸€ä¸‹é—®ç­”æ¨¡å‹çš„åå¤„ç†æ“ä½œï¼Œå³æ€ä¹ˆå°†æ¨¡å‹çš„é¢„æµ‹ç»“æœè½¬æ¢ä¸ºç­”æ¡ˆæ–‡æœ¬ã€‚\n\nä¹‹å‰åœ¨è‡ªåŠ¨é—®ç­”ä»»åŠ¡ä¸­å·²ç»ä»‹ç»è¿‡ï¼Œå¯¹æ¯ä¸ªæ ·æœ¬ï¼Œé—®ç­”æ¨¡å‹éƒ½ä¼šè¾“å‡ºä¸¤ä¸ªå¼ é‡ï¼Œåˆ†åˆ«å¯¹åº”ç­”æ¡ˆèµ·å§‹/ç»“æŸä½ç½®çš„ logits å€¼ï¼Œæˆ‘ä»¬å›é¡¾ä¸€ä¸‹ä¹‹å‰çš„åå¤„ç†è¿‡ç¨‹ï¼š\n\n- é®ç›–æ‰é™¤ä¸Šä¸‹æ–‡ä¹‹å¤–çš„å…¶ä»– token çš„èµ·å§‹/ç»“æŸ logits å€¼,å¦‚CLSæˆ–è€…SEPï¼›\n- é€šè¿‡ softmax å‡½æ•°å°†èµ·å§‹/ç»“æŸ logits å€¼è½¬æ¢ä¸ºæ¦‚ç‡å€¼ï¼Œå°†æ¨¡å‹çš„è¾“å‡ºè½¬ä¸ºç­”æ¡ˆå¼€å§‹ä½ç½®å’Œç»“æŸä½ç½®çš„æ¦‚ç‡ï¼›\n- é€šè¿‡è®¡ç®—æ¦‚ç‡å€¼çš„ä¹˜ç§¯ä¼°è®¡æ¯ä¸€å¯¹ (start_token, end_token) ä¸ºç­”æ¡ˆçš„åˆ†æ•°ï¼›\n- è¾“å‡ºåˆç†çš„ï¼ˆä¾‹å¦‚ start_token è¦å°äº end_tokenï¼‰åˆ†æ•°æœ€å¤§çš„å¯¹ä½œä¸ºç­”æ¡ˆã€‚\n\næœ¬æ–‡æˆ‘ä»¬ä¼šç¨å¾®åšä¸€äº›è°ƒæ•´ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬åªå…³å¿ƒæœ€åé¢„æµ‹å‡ºçš„ç­”æ¡ˆæ–‡æœ¬ï¼Œå› æ­¤å¯ä»¥è·³è¿‡ softmax å‡½æ•°ï¼Œç›´æ¥åŸºäº logits å€¼æ¥ä¼°è®¡ç­”æ¡ˆåˆ†æ•°ï¼Œä»åŸæ¥è®¡ç®—æ¦‚ç‡å€¼çš„ä¹˜ç§¯å˜æˆè®¡ç®— logits å€¼çš„å’Œï¼ˆå› ä¸º $\\log(ab) = \\log(a) + \\log(b)$ï¼‰ï¼›å…¶æ¬¡ï¼Œä¸ºäº†å‡å°‘è®¡ç®—é‡ï¼Œæˆ‘ä»¬ä¸å†ä¸ºæ‰€æœ‰å¯èƒ½çš„ (start_token, end_token) å¯¹æ‰“åˆ†ï¼Œè€Œæ˜¯åªè®¡ç®— logits å€¼æœ€é«˜çš„å‰ n_best ä¸ª token ç»„æˆçš„å¯¹ã€‚å› ä¸ºæ¯ä¸ªä½ç½®éƒ½æœ‰å¯èƒ½æ˜¯å¼€å§‹ä½ç½®æˆ–è€…ç»“æŸä½ç½®ï¼Œè®¡ç®—æ‰€æœ‰çš„å¯èƒ½è®¡ç®—é‡å¾ˆå¤§ã€‚\n\nç”±äºæˆ‘ä»¬çš„ BERT æ¨¡å‹è¿˜æ²¡æœ‰è¿›è¡Œå¾®è°ƒï¼Œå› æ­¤è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªå·²ç»é¢„è®­ç»ƒå¥½çš„é—®ç­”æ¨¡å‹ [Chinese RoBERTa-Base Model for QA](https://huggingface.co/uer/roberta-base-chinese-extractive-qa) è¿›è¡Œæ¼”ç¤ºï¼Œå¹¶ä¸”åªå¯¹éªŒè¯é›†ä¸Šçš„å‰ 10 ä¸ªæ ·æœ¬è¿›è¡Œå¤„ç†ï¼š"},{"cell_type":"code","execution_count":24,"metadata":{"id":"D68D8CE36C1E476295F222D5E02D5F65","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":"valid_data = CMRCDataset('data/10/cmrc2018_dev.json')\nsmall_eval_set = [valid_data[idx] for idx in range(10)]\n\ntrained_checkpoint = \"uer/roberta-base-chinese-extractive-qa\"\n# trained_checkpoint = \"roberta-base-chinese-extractive-qa\"\n\ntokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\neval_set = DataLoader(small_eval_set, batch_size=4, shuffle=False, collate_fn=test_collote_fn)\n\nimport torch\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nfrom transformers import AutoModelForQuestionAnswering\ntrained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(device)"},{"cell_type":"code","execution_count":51,"metadata":{"id":"2711F0596FF14A59A029B7FDC6BA0860","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'id': 'DEV_0_QUERY_0',\n","  'title': 'æˆ˜å›½æ— åŒ3',\n","  'context': 'ã€Šæˆ˜å›½æ— åŒ3ã€‹ï¼ˆï¼‰æ˜¯ç”±å…‰è£å’ŒÏ‰-forceå¼€å‘çš„æˆ˜å›½æ— åŒç³»åˆ—çš„æ­£ç»Ÿç¬¬ä¸‰ç»­ä½œã€‚æœ¬ä½œä»¥ä¸‰å¤§æ•…äº‹ä¸ºä¸»è½´ï¼Œåˆ†åˆ«æ˜¯ä»¥æ­¦ç”°ä¿¡ç„ç­‰äººä¸ºä¸»çš„ã€Šå…³ä¸œä¸‰å›½å¿—ã€‹ï¼Œç»‡ç”°ä¿¡é•¿ç­‰äººä¸ºä¸»çš„ã€Šæˆ˜å›½ä¸‰æ°ã€‹ï¼ŒçŸ³ç”°ä¸‰æˆç­‰äººä¸ºä¸»çš„ã€Šå…³åŸçš„å¹´è½»æ­¦è€…ã€‹ï¼Œä¸°å¯Œæ¸¸æˆå†…çš„å‰§æƒ…ã€‚æ­¤éƒ¨ä»½ä¸“é—¨ä»‹ç»è§’è‰²ï¼Œæ¬²çŸ¥æ­¦å™¨æƒ…æŠ¥ã€å¥¥ä¹‰å­—æˆ–æ“…é•¿æ”»å‡»ç±»å‹ç­‰ï¼Œè¯·è‡³æˆ˜å›½æ— åŒç³»åˆ—1.ç”±äºä¹¡é‡Œå¤§è¾…å…ˆç”Ÿå› æ•…å»ä¸–ï¼Œä¸å¾—ä¸å¯»æ‰¾å…¶ä»–å£°ä¼˜æ¥æ‰‹ã€‚ä»çŒ›å°†ä¼  and Zå¼€å§‹ã€‚2.æˆ˜å›½æ— åŒ ç¼–å¹´å²çš„åŸåˆ›ç”·å¥³ä¸»è§’äº¦æœ‰ä¸“å±å£°ä¼˜ã€‚æ­¤æ¨¡å¼æ˜¯ä»»å¤©å ‚æ¸¸æˆè°œä¹‹æ‘é›¨åŸæ”¹ç¼–çš„æ–°å¢æ¨¡å¼ã€‚æœ¬ä½œä¸­å…±æœ‰20å¼ æˆ˜åœºåœ°å›¾ï¼ˆä¸å«æ‘é›¨åŸï¼‰ï¼Œåæ¥å‘è¡Œçš„çŒ›å°†ä¼ å†æ–°å¢3å¼ æˆ˜åœºåœ°å›¾ã€‚ä½†æ¸¸æˆå†…æˆ˜å½¹æ•°é‡ç¹å¤šï¼Œéƒ¨åˆ†åœ°å›¾ä¼šæœ‰å…¼ç”¨çš„çŠ¶å†µï¼Œæˆ˜å½¹è™šå®åˆ™æ˜¯ä»¥å…‰è£å‘è¡Œçš„2æœ¬ã€Œæˆ˜å›½æ— åŒ3 äººç‰©çœŸä¹¦ã€å†…å®¹ä¸ºä¸»ï¼Œä»¥ä¸‹æ˜¯ç›¸å…³ä»‹ç»ã€‚ï¼ˆæ³¨ï¼šå‰æ–¹åŠ â˜†è€…ä¸ºçŒ›å°†ä¼ æ–°å¢å…³å¡åŠåœ°å›¾ã€‚ï¼‰åˆå¹¶æœ¬ç¯‡å’ŒçŒ›å°†ä¼ çš„å†…å®¹ï¼Œæ‘é›¨åŸæ¨¡å¼å‰”é™¤ï¼Œæˆ˜å›½å²æ¨¡å¼å¯ç›´æ¥æ¸¸ç©ã€‚ä¸»æ‰“ä¸¤å¤§æ¨¡å¼ã€Œæˆ˜å²æ¼”æ­¦ã€&ã€Œäº‰éœ¸æ¼”æ­¦ã€ã€‚ç³»åˆ—ä½œå“å¤–ä¼ ä½œå“',\n","  'question': 'ã€Šæˆ˜å›½æ— åŒ3ã€‹æ˜¯ç”±å“ªä¸¤ä¸ªå…¬å¸åˆä½œå¼€å‘çš„ï¼Ÿ',\n","  'answers': {'text': ['å…‰è£å’ŒÏ‰-force', 'å…‰è£å’ŒÏ‰-force', 'å…‰è£å’ŒÏ‰-force'],\n","   'answer_start': [11, 11, 11]}},\n"," {'id': 'DEV_0_QUERY_1',\n","  'title': 'æˆ˜å›½æ— åŒ3',\n","  'context': 'ã€Šæˆ˜å›½æ— åŒ3ã€‹ï¼ˆï¼‰æ˜¯ç”±å…‰è£å’ŒÏ‰-forceå¼€å‘çš„æˆ˜å›½æ— åŒç³»åˆ—çš„æ­£ç»Ÿç¬¬ä¸‰ç»­ä½œã€‚æœ¬ä½œä»¥ä¸‰å¤§æ•…äº‹ä¸ºä¸»è½´ï¼Œåˆ†åˆ«æ˜¯ä»¥æ­¦ç”°ä¿¡ç„ç­‰äººä¸ºä¸»çš„ã€Šå…³ä¸œä¸‰å›½å¿—ã€‹ï¼Œç»‡ç”°ä¿¡é•¿ç­‰äººä¸ºä¸»çš„ã€Šæˆ˜å›½ä¸‰æ°ã€‹ï¼ŒçŸ³ç”°ä¸‰æˆç­‰äººä¸ºä¸»çš„ã€Šå…³åŸçš„å¹´è½»æ­¦è€…ã€‹ï¼Œä¸°å¯Œæ¸¸æˆå†…çš„å‰§æƒ…ã€‚æ­¤éƒ¨ä»½ä¸“é—¨ä»‹ç»è§’è‰²ï¼Œæ¬²çŸ¥æ­¦å™¨æƒ…æŠ¥ã€å¥¥ä¹‰å­—æˆ–æ“…é•¿æ”»å‡»ç±»å‹ç­‰ï¼Œè¯·è‡³æˆ˜å›½æ— åŒç³»åˆ—1.ç”±äºä¹¡é‡Œå¤§è¾…å…ˆç”Ÿå› æ•…å»ä¸–ï¼Œä¸å¾—ä¸å¯»æ‰¾å…¶ä»–å£°ä¼˜æ¥æ‰‹ã€‚ä»çŒ›å°†ä¼  and Zå¼€å§‹ã€‚2.æˆ˜å›½æ— åŒ ç¼–å¹´å²çš„åŸåˆ›ç”·å¥³ä¸»è§’äº¦æœ‰ä¸“å±å£°ä¼˜ã€‚æ­¤æ¨¡å¼æ˜¯ä»»å¤©å ‚æ¸¸æˆè°œä¹‹æ‘é›¨åŸæ”¹ç¼–çš„æ–°å¢æ¨¡å¼ã€‚æœ¬ä½œä¸­å…±æœ‰20å¼ æˆ˜åœºåœ°å›¾ï¼ˆä¸å«æ‘é›¨åŸï¼‰ï¼Œåæ¥å‘è¡Œçš„çŒ›å°†ä¼ å†æ–°å¢3å¼ æˆ˜åœºåœ°å›¾ã€‚ä½†æ¸¸æˆå†…æˆ˜å½¹æ•°é‡ç¹å¤šï¼Œéƒ¨åˆ†åœ°å›¾ä¼šæœ‰å…¼ç”¨çš„çŠ¶å†µï¼Œæˆ˜å½¹è™šå®åˆ™æ˜¯ä»¥å…‰è£å‘è¡Œçš„2æœ¬ã€Œæˆ˜å›½æ— åŒ3 äººç‰©çœŸä¹¦ã€å†…å®¹ä¸ºä¸»ï¼Œä»¥ä¸‹æ˜¯ç›¸å…³ä»‹ç»ã€‚ï¼ˆæ³¨ï¼šå‰æ–¹åŠ â˜†è€…ä¸ºçŒ›å°†ä¼ æ–°å¢å…³å¡åŠåœ°å›¾ã€‚ï¼‰åˆå¹¶æœ¬ç¯‡å’ŒçŒ›å°†ä¼ çš„å†…å®¹ï¼Œæ‘é›¨åŸæ¨¡å¼å‰”é™¤ï¼Œæˆ˜å›½å²æ¨¡å¼å¯ç›´æ¥æ¸¸ç©ã€‚ä¸»æ‰“ä¸¤å¤§æ¨¡å¼ã€Œæˆ˜å²æ¼”æ­¦ã€&ã€Œäº‰éœ¸æ¼”æ­¦ã€ã€‚ç³»åˆ—ä½œå“å¤–ä¼ ä½œå“',\n","  'question': 'ç”·å¥³ä¸»è§’äº¦æœ‰ä¸“å±å£°ä¼˜è¿™ä¸€æ¨¡å¼æ˜¯ç”±è°æ”¹ç¼–çš„ï¼Ÿ',\n","  'answers': {'text': ['æ‘é›¨åŸ', 'æ‘é›¨åŸ', 'ä»»å¤©å ‚æ¸¸æˆè°œä¹‹æ‘é›¨åŸ'],\n","   'answer_start': [226, 226, 219]}}]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":"small_eval_set[:2]"},{"cell_type":"code","execution_count":54,"metadata":{"id":"88747ABEE8AA43B38305E467AC65B0EF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["3"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":"len(eval_set)"},{"cell_type":"code","execution_count":55,"metadata":{"id":"4244B7E043F34C2DB1BC400A6A88C339","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["10 -> 20\n"]}],"source":"print(len(small_eval_set), '->', sum([len(batch_data['input_ids']) for batch_data in eval_set]))"},{"cell_type":"markdown","metadata":{"id":"D2858E98053B43C5827CE5D138C7AA0E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"æ¥ä¸‹æ¥ï¼Œä¸ä¹‹å‰ä»»åŠ¡ä¸­çš„éªŒè¯/æµ‹è¯•å¾ªç¯ä¸€æ ·ï¼Œåœ¨ torch.no_grad() ä¼šè¯ä¸‹ï¼Œä½¿ç”¨æ¨¡å‹å¯¹æ‰€æœ‰åˆ†å—åçš„æ–°æ ·æœ¬è¿›è¡Œé¢„æµ‹ï¼Œå¹¶ä¸”æ±‡æ€»é¢„æµ‹å‡ºçš„èµ·å§‹/ç»“æŸ logits å€¼ï¼š"},{"cell_type":"code","execution_count":49,"metadata":{"id":"F6F96F0629504EC9A4F090AC64C93E97","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":"start_logits = []\nend_logits = []\n\ntrained_model.eval()\nfor batch_data in eval_set:\n    del batch_data['offset_mapping']\n    del batch_data['example_id']\n    batch_data = {k: torch.tensor(batch_data[k]).to(device) for k in batch_data.keys()}\n    with torch.no_grad():\n        outputs = trained_model(**batch_data)\n    start_logits.append(outputs.start_logits.cpu().numpy())\n    end_logits.append(outputs.end_logits.cpu().numpy())\n\nimport numpy as np\nstart_logits = np.concatenate(start_logits)\nend_logits = np.concatenate(end_logits)"},{"cell_type":"code","execution_count":57,"metadata":{"id":"A9F34EEDE9C343ED9FA394CDE95D424D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["(20, 384)"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":"start_logits.shape # æ¯ä¸€ä¸ªä½ç½®æœ‰ä¸€ä¸ªå¼€å§‹ä½ç½®é¢„æµ‹åˆ†æ•°"},{"cell_type":"code","execution_count":56,"metadata":{"id":"05348580A48245A49126CF57ACDA98E6","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[-0.32454446, -6.3131785 , -6.3455443 , ..., -6.296451  ,\n","        -5.6250753 , -0.32487208],\n","       [ 4.793381  , -6.331345  , -6.8320727 , ..., -6.8217463 ,\n","        -6.8422074 , -6.840258  ],\n","       [-0.38632843, -6.789579  , -6.5350556 , ..., -6.345919  ,\n","        -5.9616427 , -0.38640732],\n","       ...,\n","       [ 4.8648605 , -7.1324077 , -6.5852427 , ..., -6.6514907 ,\n","        -6.8463683 , -6.8796086 ],\n","       [ 1.9186516 , -6.7040086 , -6.0588236 , ..., -6.1933575 ,\n","        -5.732796  ,  1.918763  ],\n","       [-0.6912477 , -6.3243914 , -6.18748   , ..., -6.591582  ,\n","        -6.6785283 , -6.6339097 ]], dtype=float32)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":"end_logits# ç­”æ¡ˆç»“æŸä½ç½®é¢„æµ‹åˆ†æ•°"},{"cell_type":"code","execution_count":58,"metadata":{"id":"8DD2A95125854E8990BE2C8AE1DBE596","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["defaultdict(<class 'list'>, {'DEV_0_QUERY_0': [0, 1], 'DEV_0_QUERY_1': [2, 3], 'DEV_0_QUERY_2': [4, 5], 'DEV_1_QUERY_0': [6, 7], 'DEV_1_QUERY_1': [8, 9], 'DEV_1_QUERY_2': [10, 11], 'DEV_1_QUERY_3': [12, 13], 'DEV_2_QUERY_0': [14, 15], 'DEV_2_QUERY_1': [16, 17], 'DEV_2_QUERY_2': [18, 19]})\n"]}],"source":"all_example_ids = []\nall_offset_mapping = []\nfor batch_data in eval_set:\n    all_example_ids += batch_data['example_id']\n    all_offset_mapping += batch_data['offset_mapping']\n\nimport collections\nexample_to_features = collections.defaultdict(list)\nfor idx, feature_id in enumerate(all_example_ids):\n    example_to_features[feature_id].append(idx)\n\nprint(example_to_features)"},{"cell_type":"code","execution_count":60,"metadata":{"id":"1D87FBCCF49B40DFAA1E4F58C210BE06","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["['DEV_0_QUERY_0',\n"," 'DEV_0_QUERY_0',\n"," 'DEV_0_QUERY_1',\n"," 'DEV_0_QUERY_1',\n"," 'DEV_0_QUERY_2',\n"," 'DEV_0_QUERY_2',\n"," 'DEV_1_QUERY_0',\n"," 'DEV_1_QUERY_0',\n"," 'DEV_1_QUERY_1',\n"," 'DEV_1_QUERY_1',\n"," 'DEV_1_QUERY_2',\n"," 'DEV_1_QUERY_2',\n"," 'DEV_1_QUERY_3',\n"," 'DEV_1_QUERY_3',\n"," 'DEV_2_QUERY_0',\n"," 'DEV_2_QUERY_0',\n"," 'DEV_2_QUERY_1',\n"," 'DEV_2_QUERY_1',\n"," 'DEV_2_QUERY_2',\n"," 'DEV_2_QUERY_2']"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":"all_example_ids"},{"cell_type":"code","execution_count":27,"metadata":{"id":"82D8CFB8D9C3444690E6F7769DC58048","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":"n_best = 20\nmax_answer_length = 30\ntheoretical_answers = [\n    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in small_eval_set\n]\npredicted_answers = []\n\nfor example in small_eval_set:# æ¯ä¸€ä¸ªé—®é¢˜æ ·æœ¬ æœ‰å¤šä¸ªæ»‘çª—\n    example_id = example[\"id\"]\n    context = example[\"context\"] # ä¸Šä¸‹æ–‡\n    answers = []\n\n    for feature_index in example_to_features[example_id]:# æ¯ä¸ªæ»‘çª—\n        start_logit = start_logits[feature_index]# ç­”æ¡ˆå¼€å§‹ä½ç½®åˆ†æ•°\n        end_logit = end_logits[feature_index]# ç­”æ¡ˆç»“æŸä½ç½®åˆ†æ•°\n        offsets = all_offset_mapping[feature_index]\n\n        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()# å¼€å§‹ä½ç½®æ’åºå‰n_bestçš„å¼€å§‹ä½ç½®\n        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist() # ç»“æŸä½ç½®æ’åºå‰n_bestçš„å¼€å§‹ä½ç½®\n        for start_index in start_indexes:# ç»„åˆå¼€å§‹ä½ç½®ä¸ç»“æŸä½ç½®\n            for end_index in end_indexes:\n                if offsets[start_index] is None or offsets[end_index] is None:# å¦‚æœå¼€å§‹ä½ç½®ä¸ºNone è·³è¿‡\n                    continue\n                # å¦‚æœç»“æŸä½ç½®å°äºå¼€å§‹ä½ç½®æˆ–è€…ç»“æŸä½ç½®å‡å»ç»“æŸä½ç½®å¤§äºæœ€å¤§ç­”æ¡ˆé•¿åº¦ è·³è¿‡\n                if (end_index < start_index or end_index - start_index + 1 > max_answer_length):\n                    continue \n                answers.append(\n                    {\n                        \"start\": offsets[start_index][0],# ç­”æ¡ˆå¼€å§‹ä½ç½®\n                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],# ç­”æ¡ˆå…·ä½“å†…å®¹\n                        \"logit_score\": start_logit[start_index] + end_logit[end_index], # å¼€å§‹ä¸ç»“æŸåˆ†æ•°ç›¸åŠ ä¹‹å’Œ\n                    }\n                )\n    if len(answers) > 0:\n        best_answer = max(answers, key=lambda x: x[\"logit_score\"])# é€‰å–å¼€å§‹ä½ç½®åˆ†æ•°+ç»“æŸä½ç½®åˆ†æ•°æœ€å¤§çš„å¼€å§‹-ç»“æŸç»„åˆ\n        predicted_answers.append({\n            \"id\": example_id, \n            \"prediction_text\": best_answer[\"text\"], \n            \"answer_start\": best_answer[\"start\"]\n        })\n    else:\n        # å¦‚æœå€™é€‰ç­”æ¡ˆä¸ºç©ºï¼Œè¿”å›ç©ºç­”æ¡ˆ\n        predicted_answers.append({\n            \"id\": example_id, \n            \"prediction_text\": \"\", \n            \"answer_start\": 0\n        })"},{"cell_type":"code","execution_count":28,"metadata":{"id":"F64201FCB2EE452FA24B6D14EF087B8C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DEV_0_QUERY_0\n","pred: å…‰è£å’ŒÏ‰-force\n","label: ['å…‰è£å’ŒÏ‰-force', 'å…‰è£å’ŒÏ‰-force', 'å…‰è£å’ŒÏ‰-force']\n","DEV_0_QUERY_1\n","pred: ä»»å¤©å ‚æ¸¸æˆè°œä¹‹æ‘é›¨åŸ\n","label: ['æ‘é›¨åŸ', 'æ‘é›¨åŸ', 'ä»»å¤©å ‚æ¸¸æˆè°œä¹‹æ‘é›¨åŸ']\n","DEV_0_QUERY_2\n","pred: ã€Œæˆ˜å²æ¼”æ­¦ã€&ã€Œäº‰éœ¸æ¼”æ­¦ã€\n","label: ['ã€Œæˆ˜å²æ¼”æ­¦ã€&ã€Œäº‰éœ¸æ¼”æ­¦ã€', 'ã€Œæˆ˜å²æ¼”æ­¦ã€&ã€Œäº‰éœ¸æ¼”æ­¦ã€', 'ã€Œæˆ˜å²æ¼”æ­¦ã€&ã€Œäº‰éœ¸æ¼”æ­¦ã€']\n","DEV_1_QUERY_0\n","pred: é”£é¼“ç»æ˜¯å¤§é™†ä¼ ç»Ÿå™¨ä¹åŠæˆæ›²é‡Œé¢å¸¸ç”¨çš„æ‰“å‡»ä¹è®°è°±æ–¹æ³•\n","label: ['å¤§é™†ä¼ ç»Ÿå™¨ä¹åŠæˆæ›²é‡Œé¢å¸¸ç”¨çš„æ‰“å‡»ä¹è®°è°±æ–¹æ³•', 'å¤§é™†ä¼ ç»Ÿå™¨ä¹åŠæˆæ›²é‡Œé¢å¸¸ç”¨çš„æ‰“å‡»ä¹è®°è°±æ–¹æ³•', 'å¤§é™†ä¼ ç»Ÿå™¨ä¹åŠæˆæ›²é‡Œé¢å¸¸ç”¨çš„æ‰“å‡»ä¹è®°è°±æ–¹æ³•']\n","DEV_1_QUERY_1\n","pred: ã€Œé”£é¼“ç‚¹ã€\n","label: ['é”£é¼“ç‚¹', 'é”£é¼“ç‚¹', 'é”£é¼“ç‚¹']\n","DEV_1_QUERY_2\n","pred: ä¾ç…§è§’è‰²è¡Œå½“çš„èº«ä»½ã€æ€§æ ¼ã€æƒ…ç»ªä»¥åŠç¯å¢ƒï¼Œé…åˆç›¸åº”çš„é”£é¼“ç‚¹ã€‚\n","label: ['ä¾ç…§è§’è‰²è¡Œå½“çš„èº«ä»½ã€æ€§æ ¼ã€æƒ…ç»ªä»¥åŠç¯å¢ƒï¼Œé…åˆç›¸åº”çš„é”£é¼“ç‚¹ã€‚', 'ä¾ç…§è§’è‰²è¡Œå½“çš„èº«ä»½ã€æ€§æ ¼ã€æƒ…ç»ªä»¥åŠç¯å¢ƒï¼Œé…åˆç›¸åº”çš„é”£é¼“ç‚¹ã€‚', 'ä¾ç…§è§’è‰²è¡Œå½“çš„èº«ä»½ã€æ€§æ ¼ã€æƒ…ç»ªä»¥åŠç¯å¢ƒï¼Œé…åˆç›¸åº”çš„é”£é¼“ç‚¹']\n","DEV_1_QUERY_3\n","pred: æˆæ›²é”£é¼“æ‰€è¿ç”¨çš„æ•²å‡»ä¹å™¨ä¸»è¦åˆ†ä¸ºé¼“ã€é”£ã€é’¹å’Œæ¿å››ç±»å‹\n","label: ['é¼“ã€é”£ã€é’¹å’Œæ¿', 'é¼“ã€é”£ã€é’¹å’Œæ¿', 'é¼“ã€é”£ã€é’¹å’Œæ¿']\n","DEV_2_QUERY_0\n","pred: å…¨é•¿364.6å…¬é‡Œ\n","label: ['364.6å…¬é‡Œ', '364.6å…¬é‡Œ', '364.6å…¬é‡Œ']\n","DEV_2_QUERY_1\n","pred: ä¸‰èŒ‚é“è·¯è‚¡ä»½æœ‰é™å…¬å¸\n","label: ['ä¸‰èŒ‚é“è·¯è‚¡ä»½æœ‰é™å…¬å¸', 'ä¸‰èŒ‚é“è·¯è‚¡ä»½æœ‰é™å…¬å¸', 'ä¸‰èŒ‚é“è·¯è‚¡ä»½æœ‰é™å…¬å¸']\n","DEV_2_QUERY_2\n","pred: 1903å¹´\n","label: ['1903å¹´', '1903å¹´', '1903å¹´']\n"]}],"source":"for pred, label in zip(predicted_answers, theoretical_answers):\n    print(pred['id'])\n    print('pred:', pred['prediction_text'])\n    print('label:', label['answers']['text'])"},{"cell_type":"markdown","metadata":{"id":"B9C250D2D6734CC6A74F69461E66AA67","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"å¯ä»¥çœ‹åˆ°ï¼Œç”±äºæˆ‘ä»¬é€‰æ‹©çš„ Chinese RoBERTa-Base Model for QA æ¨¡å‹æœ¬èº«çš„é¢„è®­ç»ƒæ•°æ®å°±åŒ…å«äº† CMRC 2018ï¼Œå› æ­¤æ¨¡å‹çš„é¢„æµ‹ç»“æœè¿˜æ˜¯ä¸é”™çš„ã€‚\n\nåœ¨æˆåŠŸè·å–åˆ°é¢„æµ‹çš„ç­”æ¡ˆç‰‡æ®µä¹‹åï¼Œå°±å¯ä»¥å¯¹æ¨¡å‹çš„æ€§èƒ½è¿›è¡Œè¯„ä¼°äº†ã€‚è¿™é‡Œæˆ‘ä»¬å¯¹ CMRC 2018 è‡ªå¸¦çš„è¯„ä¼°è„šæœ¬è¿›è¡Œä¿®æ”¹ï¼Œä½¿å…¶æ”¯æŒæœ¬æ–‡æ¨¡å‹çš„è¾“å‡ºæ ¼å¼ï¼š"},{"cell_type":"code","execution_count":36,"metadata":{"id":"D650353232844EDC97691C3B8E0DE5ED","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":"import re\nimport sys\nfrom transformers import AutoTokenizer\n\n# model_checkpoint = \"bert-base-cased\"\n# model_checkpoint = '../pretrained_models/chinese-roberta-wwm-ext'\ntrained_checkpoint = \"uer/roberta-base-chinese-extractive-qa\"\ntokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n\ntokenize = lambda x: tokenizer(x).tokens()[1:-1]\n\n# import nltk\n# tokenize = lambda x: nltk.word_tokenize(x)\n\n# split Chinese with English\ndef mixed_segmentation(in_str, rm_punc=False):\n    in_str = str(in_str).lower().strip()\n    segs_out = []\n    temp_str = \"\"\n    sp_char = ['-',':','_','*','^','/','\\\\','~','`','+','=',\n               'ï¼Œ','ã€‚','ï¼š','ï¼Ÿ','ï¼','â€œ','â€','ï¼›','â€™','ã€Š','ã€‹','â€¦â€¦','Â·','ã€',\n               'ã€Œ','ã€','ï¼ˆ','ï¼‰','ï¼','ï½','ã€','ã€']\n    for char in in_str:\n        if rm_punc and char in sp_char:\n            continue\n        if re.search(r'[\\u4e00-\\u9fa5]', char) or char in sp_char:\n            if temp_str != \"\":\n                # ss = nltk.word_tokenize(temp_str)\n                ss = tokenize(temp_str)\n                segs_out.extend(ss)\n                temp_str = \"\"\n            segs_out.append(char)\n        else:\n            temp_str += char\n\n    #handling last part\n    if temp_str != \"\":\n        # ss = nltk.word_tokenize(temp_str)\n        ss = tokenize(temp_str)\n        segs_out.extend(ss)\n\n    return segs_out\n\n# remove punctuation\ndef remove_punctuation(in_str):\n    in_str = str(in_str).lower().strip()\n    sp_char = ['-',':','_','*','^','/','\\\\','~','`','+','=',\n               'ï¼Œ','ã€‚','ï¼š','ï¼Ÿ','ï¼','â€œ','â€','ï¼›','â€™','ã€Š','ã€‹','â€¦â€¦','Â·','ã€',\n               'ã€Œ','ã€','ï¼ˆ','ï¼‰','ï¼','ï½','ã€','ã€']\n    out_segs = []\n    for char in in_str:\n        if char in sp_char:\n            continue\n        else:\n            out_segs.append(char)\n    return ''.join(out_segs)\n\n# find longest common string\ndef find_lcs(s1, s2):\n    m = [[0 for i in range(len(s2)+1)] for j in range(len(s1)+1)]\n    mmax = 0\n    p = 0\n    for i in range(len(s1)):\n        for j in range(len(s2)):\n            if s1[i] == s2[j]:\n                m[i+1][j+1] = m[i][j]+1\n                if m[i+1][j+1] > mmax:\n                    mmax=m[i+1][j+1]\n                    p=i+1\n    return s1[p-mmax:p], mmax\n\ndef calc_f1_score(answers, prediction):\n    f1_scores = []\n    for ans in answers:\n        ans_segs = mixed_segmentation(ans, rm_punc=True)\n        prediction_segs = mixed_segmentation(prediction, rm_punc=True)\n        lcs, lcs_len = find_lcs(ans_segs, prediction_segs)\n        if lcs_len == 0:\n            f1_scores.append(0)\n            continue\n        precision     = 1.0*lcs_len/len(prediction_segs)\n        recall         = 1.0*lcs_len/len(ans_segs)\n        f1             = (2*precision*recall)/(precision+recall)\n        f1_scores.append(f1)\n    return max(f1_scores)\n\ndef calc_em_score(answers, prediction):\n    em = 0\n    for ans in answers:\n        ans_ = remove_punctuation(ans)\n        prediction_ = remove_punctuation(prediction)\n        if ans_ == prediction_:\n            em = 1\n            break\n    return em\n\ndef evaluate(predictions, references):\n    f1 = 0\n    em = 0\n    total_count = 0\n    skip_count = 0\n    pred = dict([(data['id'], data['prediction_text']) for data in predictions])\n    ref = dict([(data['id'], data['answers']['text']) for data in references])\n    for query_id, answers in ref.items():\n        total_count += 1\n        if query_id not in pred:\n            sys.stderr.write('Unanswered question: {}\\n'.format(query_id))\n            skip_count += 1\n            continue\n        prediction = pred[query_id]\n        f1 += calc_f1_score(answers, prediction)\n        em += calc_em_score(answers, prediction)\n    f1_score = 100.0 * f1 / total_count\n    em_score = 100.0 * em / total_count\n    return {\n        'avg': (em_score + f1_score) * 0.5, \n        'f1': f1_score, \n        'em': em_score, \n        'total': total_count, \n        'skip': skip_count\n    }"},{"cell_type":"code","execution_count":37,"metadata":{"id":"D4F24F95922C4A4183F2C49795F4439A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["F1: 90.91 EM: 70.00 AVG: 80.46\n","\n"]}],"source":"result = evaluate(predicted_answers, theoretical_answers)\nprint(f\"F1: {result['f1']:>0.2f} EM: {result['em']:>0.2f} AVG: {result['avg']:>0.2f}\\n\")"},{"cell_type":"markdown","metadata":{"id":"D8E4040B60B447DA9726F68A4BA54B3C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"### æµ‹è¯•å‚æ•°\nç†Ÿæ‚‰äº†åå¤„ç†æ“ä½œä¹‹åï¼Œç¼–å†™éªŒè¯/æµ‹è¯•å¾ªç¯å°±å¾ˆç®€å•äº†ï¼Œåªéœ€å¯¹ä¸Šé¢çš„è¿™äº›æ­¥éª¤ç¨ä½œæ•´åˆå³å¯ã€‚è¿™é‡Œç”±äºæˆ‘ä»¬è¿˜éœ€è¦ä½¿ç”¨åˆ°æ ·æœ¬çš„åŸå§‹æ–‡æœ¬ï¼Œå› æ­¤å°†æ•°æ®é›†ä¹Ÿä½œä¸ºå‚æ•°ä¼ å…¥ï¼š"},{"cell_type":"code","execution_count":44,"metadata":{"id":"79FDE323B16F43D697002A356AD037EA","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":"import collections\n\nn_best = 20\nmax_answer_length = 30\n\ndef test_loop(dataloader, dataset, model, mode='Test'):\n    assert mode in ['Valid', 'Test']\n\n    all_example_ids = []\n    all_offset_mapping = []\n    for batch_data in dataloader:\n        all_example_ids += batch_data['example_id']\n        all_offset_mapping += batch_data['offset_mapping']\n\n    model.eval()\n    start_logits = []\n    end_logits = []\n    for batch_data in tqdm(dataloader):\n        del batch_data['offset_mapping']\n        del batch_data['example_id']\n        batch_data = {k: torch.tensor(batch_data[k]).to(device) for k in batch_data.keys()}\n        with torch.no_grad():\n            outputs = model(**batch_data)\n        start_logits.append(outputs.start_logits.cpu().numpy())\n        end_logits.append(outputs.end_logits.cpu().numpy())\n    start_logits = np.concatenate(start_logits)\n    end_logits = np.concatenate(end_logits)\n    \n    example_to_features = collections.defaultdict(list)\n    for idx, feature_id in enumerate(all_example_ids):\n        example_to_features[feature_id].append(idx)\n    \n    theoretical_answers = [\n        {\"id\": dataset[idx][\"id\"], \"answers\": dataset[idx][\"answers\"]} for idx in range(len(dataset))\n    ]\n    predicted_answers = []\n    for idx in tqdm(range(len(dataset))):\n        example_id = dataset[idx][\"id\"]\n        context = dataset[idx][\"context\"]\n        answers = []\n\n        # Loop through all features associated with that example\n        for feature_index in example_to_features[example_id]:\n            start_logit = start_logits[feature_index]\n            end_logit = end_logits[feature_index]\n            offsets = all_offset_mapping[feature_index]\n\n            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    if offsets[start_index] is None or offsets[end_index] is None:\n                        continue\n                    if (end_index < start_index or end_index-start_index+1 > max_answer_length):\n                        continue\n                    answers.append({\n                        \"start\": offsets[start_index][0], \n                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]], \n                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n                    })\n        # Select the answer with the best score\n        if len(answers) > 0:\n            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n            predicted_answers.append({\n                \"id\": example_id, \n                \"prediction_text\": best_answer[\"text\"], \n                \"answer_start\": best_answer[\"start\"]\n            })\n        else:\n            predicted_answers.append({\n                \"id\": example_id, \n                \"prediction_text\": \"\", \n                \"answer_start\": 0\n            })\n    result = evaluate(predicted_answers, theoretical_answers)\n    print(f\"{mode} F1: {result['f1']:>0.2f} EM: {result['em']:>0.2f} AVG: {result['avg']:>0.2f}\\n\")\n    return result,predicted_answers"},{"cell_type":"markdown","metadata":{"id":"DE50D4D8D22847D7BD87CD4521528DC8","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"### ä¿å­˜å’ŒåŠ è½½æ¨¡å‹\nä¸ä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬ä¼šæ ¹æ®æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½æ¥è°ƒæ•´è¶…å‚æ•°ä»¥åŠé€‰å‡ºæœ€å¥½çš„æ¨¡å‹ï¼Œç„¶åå°†é€‰å‡ºçš„æ¨¡å‹åº”ç”¨äºæµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ã€‚è¿™é‡Œç»§ç»­ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨ï¼Œå¹¶ä¸”é€šè¿‡ get_scheduler() å‡½æ•°å®šä¹‰å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼š\n\n"},{"cell_type":"markdown","metadata":{"id":"175D9FC297AB46F1880EBF4FE5F98209","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"åŸç”Ÿè®­ç»ƒï¼šhfl/chinese-bert-wwm-ext"},{"cell_type":"code","execution_count":32,"metadata":{"id":"15D3E3A6AB3E4EC89D436B1CC0F19A29","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","-------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["F:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ec39dcee94142ffb8ff863adc3ef4a6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2536 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d86279a24e5b4e6ba338ddfd5ce0ff1f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/403 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cf4138c51fb426e9bdeb62bad90434b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Valid F1: 84.86 EM: 65.80 AVG: 75.33\n","\n","saving new weights...\n","\n","Epoch 2/3\n","-------------------------------\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d45f47802d0f4bfd8eb0f5089a838e72","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2536 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b35d3d8e980a44f7bc9c2aa6c17e5e11","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/403 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64ade976a437431aa2633bb353aa6e1d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Valid F1: 86.91 EM: 68.65 AVG: 77.78\n","\n","saving new weights...\n","\n","Epoch 3/3\n","-------------------------------\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9301112e88dc45f69601917b9f5a4859","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2536 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f54b8eebf1cf4a00a2249f8976d8873a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/403 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"233c8acdceef4324917b0fcc4916add3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3219 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Valid F1: 85.65 EM: 66.29 AVG: 75.97\n","\n","Done!\n"]}],"source":"from transformers import AdamW, get_scheduler\n\nlearning_rate = 2e-5\nepoch_num = 3\n\noptimizer = AdamW(model.parameters(), lr=learning_rate)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=epoch_num*len(train_dataloader),\n)\n\ntotal_loss = 0.\nbest_avg_score = 0.\nfor t in range(epoch_num):\n    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n    total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1, total_loss)\n    valid_scores = test_loop(valid_dataloader, valid_data, model, mode='Valid')\n    avg_score = valid_scores['avg']\n    if avg_score > best_avg_score:\n        best_avg_score = avg_score\n        print('saving new weights...\\n')\n        torch.save(model.state_dict(), f'epoch_{t+1}_valid_avg_{avg_score:0.4f}_model_weights.bin')\nprint(\"Done!\")"},{"cell_type":"code","execution_count":35,"metadata":{"id":"D72D57B79611477B878DBDD376F6B19E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["{'avg': 75.97387284638347,\n"," 'f1': 85.65386560578341,\n"," 'em': 66.29388008698353,\n"," 'total': 3219,\n"," 'skip': 0}"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":"valid_scores"},{"cell_type":"code","execution_count":45,"metadata":{"id":"55FCEB083E3C4474915E0B045F4D04B0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43a13b41c8564daf9c52fa6da8d57670","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/126 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a14f37928d94668a8601f1b20a38f9b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1002 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test F1: 69.34 EM: 33.73 AVG: 51.54\n","\n"]}],"source":"test_data = CMRCDataset('data/10/cmrc2018_trial.json')\ntest_dataloader = DataLoader(test_data, batch_size=8, shuffle=False, collate_fn=test_collote_fn)\n\nmodel.load_state_dict(torch.load('epoch_2_valid_avg_77.7824_model_weights.bin'))\nscores,predicted_answers=test_loop(test_dataloader, test_data, model, mode='Test')"},{"cell_type":"code","execution_count":46,"metadata":{"id":"5EBB3812AD4B49DA84D707F79F5B3317","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["{'avg': 51.53681296175643,\n"," 'f1': 69.34109099337314,\n"," 'em': 33.73253493013972,\n"," 'total': 1002,\n"," 'skip': 0}"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":"scores"},{"cell_type":"markdown","metadata":{"id":"C61CE15316AF4D6B92BF6A5263B18409","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"predicted_answersä¸ºæµ‹è¯•é›†é¢„æµ‹ç»“æœåˆ—è¡¨ï¼Œé‡Œé¢åŒ…å«äº†ä¸€ä¸ªé—®é¢˜çš„å¯¹åº”idï¼Œé¢„æµ‹ç­”æ¡ˆæ–‡æœ¬å†…å®¹ã€ä»¥åŠç­”æ¡ˆçš„å¼€å§‹ä½ç½®"},{"cell_type":"code","execution_count":48,"metadata":{"id":"079BD72B0C624CD799E0677DC648CC6B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'id': 'TRIAL_800_QUERY_0', 'prediction_text': 'è¸¢çˆ†', 'answer_start': 182},\n"," {'id': 'TRIAL_800_QUERY_1',\n","  'prediction_text': '4åˆ†é’Ÿå†…ä¸å¾—è¿›è¡Œé…å¯¹(æ¯æ¬¡ä¸­ç¦»+4åˆ†é’Ÿ)',\n","  'answer_start': 301},\n"," {'id': 'TRIAL_800_QUERY_2',\n","  'prediction_text': 'æ°´æªã€å°æªã€é”¤å­æˆ–æ˜¯æ°´ç‚¸å¼¹',\n","  'answer_start': 88},\n"," {'id': 'TRIAL_800_QUERY_3',\n","  'prediction_text': 'ç»å…¸ã€çƒ­è¡€ã€ç‹™å‡»ç­‰æ¨¡å¼è¿›è¡Œæ¸¸æˆã€‚',\n","  'answer_start': 278},\n"," {'id': 'TRIAL_154_QUERY_0',\n","  'prediction_text': 'æ¾³æ´²å—éƒ¨å²›å±¿åŠè¥¿å²¸åœ°åŒº',\n","  'answer_start': 59},\n"," {'id': 'TRIAL_154_QUERY_1',\n","  'prediction_text': 'ç”±äºç‰ ä»¬æ¯å­£åœ¨è¢‹é¼ å²›éƒ½å¤§é‡ç¹æ®–ï¼Œç ´åäº†é’ˆé¼¹å²›ä¸Šçš„ç”Ÿæ´»ç¯å¢ƒ',\n","  'answer_start': 71},\n"," {'id': 'TRIAL_154_QUERY_2',\n","  'prediction_text': '1628å¹´èˆ¹éš¾çš„ç”Ÿè¿˜è€…åœ¨è¥¿æ¾³å‘ç°çš„',\n","  'answer_start': 115},\n"," {'id': 'TRIAL_154_QUERY_3', 'prediction_text': '8å…¬æ–¤é‡', 'answer_start': 186},\n"," {'id': 'TRIAL_154_QUERY_4',\n","  'prediction_text': 'æœ‰å¯èƒ½æ˜¯ä¸€ç§ç¥å¥‡è¯åŠé’éœ‰ç´ çš„æ”¹è‰¯ã€‚',\n","  'answer_start': 217},\n"," {'id': 'TRIAL_598_QUERY_0',\n","  'prediction_text': 'æ—¥æœ¬æˆ˜å›½æ—¶ä»£è‡³å®‰åœŸæ¡ƒå±±æ—¶ä»£',\n","  'answer_start': 23},\n"," {'id': 'TRIAL_598_QUERY_1',\n","  'prediction_text': 'åœ¨æ°¸ç¦„5å¹´ ï¼ˆ1562å¹´ï¼‰å…ƒæœ',\n","  'answer_start': 223},\n"," {'id': 'TRIAL_598_QUERY_2',\n","  'prediction_text': 'å¤©æ­£16å¹´ï¼ˆ1588å¹´ï¼‰',\n","  'answer_start': 326},\n"," {'id': 'TRIAL_598_QUERY_3',\n","  'prediction_text': 'åœ¨å¤©æ­£16å¹´ï¼ˆ1588å¹´ï¼‰æŠŠå®¶ç£è®©äºˆå«¡å­åº·ç›´å¹¶åœ¨äº¬éƒ½éšå±…',\n","  'answer_start': 540},\n"," {'id': 'TRIAL_598_QUERY_4',\n","  'prediction_text': 'æ”¶å®¶åº·çš„ä¸ƒç”·æ¾åƒä»£ä¸ºåº·ç›´çš„å…»å­å¹¶ä»¤å…¶ç»§æ‰¿æ·±è°·è—©1ä¸‡çŸ³ã€‚',\n","  'answer_start': 612},\n"," {'id': 'TRIAL_662_QUERY_0',\n","  'prediction_text': 'æ³°å›½çš„é¦–éƒ½æ›¼è°·çš„ä¹éƒ½èŠ‚å¿',\n","  'answer_start': 9},\n"," {'id': 'TRIAL_662_QUERY_1', 'prediction_text': 'æ³°å›½å›½å®¶é“è·¯å±€', 'answer_start': 58},\n"," {'id': 'TRIAL_662_QUERY_2',\n","  'prediction_text': 'å®ƒçš„é¢ç§¯çº¦ä¸º0.304å¹³æ–¹å…¬é‡Œ',\n","  'answer_start': 107},\n"," {'id': 'TRIAL_662_QUERY_3',\n","  'prediction_text': 'å±•ç¤ºæ³°å›½çš„æœºè½¦åŠè½¦å¢ã€‚',\n","  'answer_start': 245},\n"," {'id': 'TRIAL_863_QUERY_0', 'prediction_text': 'æ³•å›½', 'answer_start': 47},\n"," {'id': 'TRIAL_863_QUERY_1',\n","  'prediction_text': 'è‡ª1983å¹´è‡³ä»Šï¼Œä¸€ç›´å…¼ä»»åŸƒçº³çœåœ°åŒºé¦–åºœéŸ¦å°”ä¸‡ï¼ˆVervinsï¼‰å¸‚å¸‚é•¿',\n","  'answer_start': 170}]"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":"predicted_answers[:20]"},{"cell_type":"markdown","metadata":{"id":"2FA153EF20194BCF9D2BEC2A05C407D0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"## å‚è€ƒèµ„æ–™"},{"cell_type":"markdown","metadata":{"id":"371AFFAF2F7A4ED890207BA1FC87F015","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"- [Hugging Face çš„ Transformers åº“å¿«é€Ÿå…¥é—¨ï¼ˆä¹ï¼‰ï¼šæŠ½å–å¼é—®ç­”](https://xiaosheng.run/2022/04/02/transformers-note-9.html)\n- [è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸä¸­çš„è‡ªåŠ¨é—®ç­”ç ”ç©¶è¿›å±•](http://www.xml-data.org/whdy/html/19bfe585-f918-4b28-bbcf-3431d84a570b.htm)"},{"cell_type":"code","execution_count":null,"metadata":{"id":"41686F92B8114D0A895FA1DA614B5F81","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":4}