{"cells":[{"cell_type":"markdown","metadata":{"id":"rEJBSTyZIrIb","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"# 基于Bert在多项选择任务上微调模型"},{"cell_type":"markdown","metadata":{"id":"205B1600F9A84C649225378748841E3E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"source":"### SWAG 数据集简介\n\n鉴于部分描述，例如“她打开汽车的引擎盖”，人类可以推断出这种情况并预测接下来会发生什么（“然后，她检查了发动机”）。在本文中，我们介绍了基础常识推理的任务，统一自然语言推理和常识推理。\n\n\n该数据集由 113k 个关于接地情况的多项选择题组成。每个问题都是来自 LSMDC 或 ActivityNet Captions 的视频字幕，有四个关于场景中接下来可能发生的事情的答案选项。正确答案是视频中下一个事件的（真实）视频字幕；三个不正确的答案是对抗性生成和人工验证的，以欺骗机器而不是人类。作者的目标是让 SWAG 成为评估基础常识 NLI 和学习表示的基准。"},{"metadata":{"id":"9793785D003644F9A71967DF8DD8D064","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\nRequirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.17.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.6/site-packages (2.0.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from datasets) (1.19.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from datasets) (0.4.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from datasets) (0.70.12.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets) (0.24.2)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from datasets) (0.8)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.6/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from datasets) (0.3.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.6/site-packages (from datasets) (0.10.6)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from datasets) (2022.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.6/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from datasets) (1.7.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.6/site-packages (from datasets) (2.26.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.6/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from datasets) (21.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.6/site-packages (from datasets) (4.64.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.0.12)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->datasets) (2.1.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (1.26.6)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (3.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from responses<0.19->datasets) (1.15.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.6/site-packages (from tqdm>=4.62.1->datasets) (5.4.0)\nRequirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.12.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2019.6.8)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.49)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.6/site-packages (from aiohttp->datasets) (5.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: idna-ssl>=1.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->datasets) (1.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.6/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.6/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.6/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->datasets) (19.3.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->datasets) (3.1.0)\nRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets) (2.8.1)\nRequirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->datasets) (2019.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (0.13.2)\n\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}],"source":"# !pip install transformers datasets -i https://pypi.tuna.tsinghua.edu.cn/simple # 清华镜像\n!pip install -i https://mirrors.cloud.tencent.com/pypi/simple transformers datasets # 腾讯镜像\n# https://mirrors.cloud.tencent.com/help/pypi.html","execution_count":44},{"cell_type":"markdown","metadata":{"id":"kTCFado4IrIc","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"数据集：[SWAG](https://www.aclweb.org/anthology/D18-1009/)\nSWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference\n\n模型简介：https://paperswithcode.com/dataset/swag\n\nhuggingface dataset：https://huggingface.co/datasets/swag"},{"cell_type":"code","execution_count":45,"metadata":{"id":"zVvslsfMIrIh","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"model_checkpoint = \"bert-base-uncased\" # 使用的预训练模型\nbatch_size = 16"},{"cell_type":"markdown","metadata":{"id":"whPRbBNbIrIl","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"### 加载数据集"},{"cell_type":"code","execution_count":47,"metadata":{"id":"IreSlFmlIrIm","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"from datasets import load_dataset, load_metric"},{"cell_type":"markdown","metadata":{"id":"CKx2zKs5IrIq","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"`load_dataset` 将缓存数据集，下次运行此单元格时不再下载。"},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270,"referenced_widgets":["69caab03d6264fef9fc5649bffff5e20","3f74532faa86412293d90d3952f38c4a","50615aa59c7247c4804ca5cbc7945bd7","fe962391292a413ca55dc932c4279fa7","299f4b4c07654e53a25f8192bd1d7bbd","ad04ed1038154081bbb0c1444784dcc2","7c667ad22b5740d5a6319f1b1e3a8097","46c2b043c0f84806978784a45a4e203b","80e2943be35f46eeb24c8ab13faa6578","de5956b5008d4fdba807bae57509c393","931db1f7a42f4b46b7ff8c2e1262b994","6c1db72efff5476e842c1386fadbbdba","ccd2f37647c547abb4c719b75a26f2de","d30a66df5c0145e79693e09789d96b81","5fa26fc336274073abbd1d550542ee33","2b34de08115d49d285def9269a53f484","d426be871b424affb455aeb7db5e822e","160bf88485f44f5cb6eaeecba5e0901f","745c0d47d672477b9bb0dae77b926364","d22ab78269cd4ccfbcf70c707057c31b","d298eb19eeff453cba51c2804629d3f4","a7204ade36314c86907c562e0a2158b8","e35d42b2d352498ca3fc8530393786b2","75103f83538d44abada79b51a1cec09e","f6253931d90543e9b5fd0bb2d615f73a","051aa783ff9e47e28d1f9584043815f5","0984b2a14115454bbb009df71c1cf36f","8ab9dfce29854049912178941ef1b289","c9de740e007141958545e269372780a4","cbea68b25d6d4ba09b2ce0f27b1726d5","5781fc45cf8d486cb06ed68853b2c644","d2a92143a08a4951b55bab9bc0a6d0d3","a14c3e40e5254d61ba146f6ec88eae25","c4ffe6f624ce4e978a0d9b864544941a","1aca01c1d8c940dfadd3e7144bb35718","9fbbaae50e6743f2aa19342152398186","fea27ca6c9504fc896181bc1ff5730e5","940d00556cb849b3a689d56e274041c2","5cdf9ed939fb42d4bf77301c80b8afca","94b39ccfef0b4b08bf2fb61bb0a657c1","9a55087c85b74ea08b3e952ac1d73cbe","2361ab124daf47cc885ff61f2899b2af","1a65887eb37747ddb75dc4a40f7285f2","3c946e2260704e6c98593136bd32d921","50d325cdb9844f62a9ecc98e768cb5af","aa781f0cfe454e9da5b53b93e9baabd8","6bb68d3887ef43809eb23feb467f9723","7e29a8b952cf4f4ea42833c8bf55342f","dd5997d01d8947e4b1c211433969b89b","2ace4dc78e2f4f1492a181bcd63304e7","bbee008c2791443d8610371d1f16b62b","31b1c8a2e3334b72b45b083688c1a20c","7fb7c36adc624f7dbbcb4a831c1e4f63","0b7c8f1939074794b3d9221244b1344d","a71908883b064e1fbdddb547a8c41743","2f5223f26c8541fc87e91d2205c39995"]},"id":"s_AY1ATSIrIq","jupyter":{},"outputId":"fd0578d1-8895-443d-b56f-5908de9f1b6b","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"# datasets = load_dataset(\"swag\", \"regular\")"},{"metadata":{"id":"FA51AFB7600349E5A7C2CEC876DD329F","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Using custom data configuration task063578-a70cb52678a611ac\nReusing dataset csv (./cache/csv/task063578-a70cb52678a611ac/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n","name":"stderr"},{"output_type":"display_data","metadata":{},"data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a87bcd0534604042bd1db4e420313eb8"}},"transient":{}}],"source":"import os\n\ndata_path = '/home/mw/input/task063578' #数据路径/home/mw/input/task063578\ncache_dir = './cache'\ndata_files = {\n    'train': os.path.join(data_path, 'train.csv'),# 数据集名称 训练集\n    'validation': os.path.join(data_path, 'validation.csv'), # 验证集\n    'test': os.path.join(data_path, 'test.csv') # 测试集\n }\ndatasets = load_dataset(data_path, 'regular', data_files=data_files, cache_dir=cache_dir)","execution_count":49},{"cell_type":"markdown","metadata":{"id":"RzfPtOMoIrIu","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"dataset对象本身是DatasetDict，它包含用于训练、验证和测试集的键值对(mnli是一个特殊的例子，其中包含用于不匹配的验证和测试集的键值对)。"},{"cell_type":"code","execution_count":50,"metadata":{"id":"GWiVUF0jIrIv","jupyter":{},"outputId":"35e3ea43-f397-4a54-c90c-f2cf8d36873e","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n        num_rows: 73546\n    })\n    validation: Dataset({\n        features: ['Unnamed: 0', 'video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n        num_rows: 20006\n    })\n    test: Dataset({\n        features: ['Unnamed: 0', 'video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n        num_rows: 20005\n    })\n})"},"transient":{}}],"source":"datasets"},{"cell_type":"markdown","metadata":{"id":"u3EtYfeHIrIz","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"假如我们要访问其中的元素，我们可以像下面一样读取train的第一个样本：\n- 给定数据集名称：train\n- 指定数据集的索引：0"},{"cell_type":"code","execution_count":51,"metadata":{"id":"X6HrpprwIrIz","jupyter":{},"outputId":"d7670bc0-42e4-4c09-8a6a-5c018ded7d95","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"{'Unnamed: 0': 0,\n 'video-id': 'anetv_jkn6uvmqwh4',\n 'fold-ind': 3416,\n 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n 'sent2': 'A drum line',\n 'gold-source': 'gold',\n 'ending0': 'passes by walking down the street playing their instruments.',\n 'ending1': 'has heard approaching them.',\n 'ending2': \"arrives and they're outside dancing and asleep.\",\n 'ending3': 'turns the lead singer watches the performance.',\n 'label': 0}"},"transient":{}}],"source":"datasets[\"train\"][0]"},{"metadata":{"id":"8E839EC379B04C5A8EDC9939FF78658E","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"{'Unnamed: 0': 1,\n 'video-id': 'anetv_jkn6uvmqwh4',\n 'fold-ind': 3417,\n 'startphrase': 'A drum line passes by walking down the street playing their instruments. Members of the procession',\n 'sent1': 'A drum line passes by walking down the street playing their instruments.',\n 'sent2': 'Members of the procession',\n 'gold-source': 'gen',\n 'ending0': 'are playing ping pong and celebrating one left each in quick.',\n 'ending1': 'wait slowly towards the cadets.',\n 'ending2': 'continues to play as well along the crowd along with the band being interviewed.',\n 'ending3': 'continue to play marching, interspersed.',\n 'label': 3}"},"transient":{}}],"source":"datasets[\"train\"][1]","execution_count":52},{"cell_type":"code","execution_count":10,"metadata":{"id":"9801580653F14AC08806281A9CFD3055","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"# datasets[\"train\"].to_pandas().to_csv('data/06/train.csv')\n# datasets[\"validation\"].to_pandas().to_csv('data/06/validation.csv')\n# datasets[\"test\"].to_pandas().to_csv('data/06/test.csv')"},{"cell_type":"markdown","metadata":{"id":"WHUmphG3IrI3","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"为了了解数据的具体内容，我们使用以下函数将显示数据集中随机选取的一些示例。"},{"cell_type":"code","execution_count":53,"metadata":{"id":"i3j8APAoIrI3","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"from datasets import ClassLabel\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    \"\"\"\n    随机选取10个样本进行展示\n    \"\"\"\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n    \n    df = pd.DataFrame(dataset[picks])\n    for column, typ in dataset.features.items():\n        if isinstance(typ, ClassLabel):\n            df[column] = df[column].transform(lambda i: typ.names[i])\n    display(HTML(df.to_html()))"},{"cell_type":"code","execution_count":54,"metadata":{"id":"SZy5tRB_IrI7","jupyter":{},"outputId":"ba8f2124-e485-488f-8c0c-254f34f24f13","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>video-id</th>\n      <th>fold-ind</th>\n      <th>startphrase</th>\n      <th>sent1</th>\n      <th>sent2</th>\n      <th>gold-source</th>\n      <th>ending0</th>\n      <th>ending1</th>\n      <th>ending2</th>\n      <th>ending3</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11514</td>\n      <td>anetv_TjDlEonao3s</td>\n      <td>545</td>\n      <td>She continues the process till the entire head...</td>\n      <td>She continues the process till the entire head...</td>\n      <td>The model then</td>\n      <td>gold</td>\n      <td>loose a hair around the mattress.</td>\n      <td>uses a different rag and rendition the use of ...</td>\n      <td>ties a thick part on her head.</td>\n      <td>smiles and takes a selfie while looking in the...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33024</td>\n      <td>lsmdc1023_Horrible_Bosses-81983</td>\n      <td>16102</td>\n      <td>They see someone pounding someone's chest. Som...</td>\n      <td>They see someone pounding someone's chest.</td>\n      <td>Someone</td>\n      <td>gold</td>\n      <td>unwittingly drops someone's mobile as they hur...</td>\n      <td>can not hear what he is saying to himself in t...</td>\n      <td>nears someone's ring.</td>\n      <td>glares at the panel.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>51949</td>\n      <td>anetv_Nx4rK_jvvR4</td>\n      <td>11044</td>\n      <td>A ballet is fun graphic appears across the scr...</td>\n      <td>A ballet is fun graphic appears across the scr...</td>\n      <td>A man in a black leotard and a woman in a blac...</td>\n      <td>gold</td>\n      <td>is doing balance and dancing with the high gir...</td>\n      <td>is demonstrating how to throw her hula hoop.</td>\n      <td>is shown standing up even ballet and dressed i...</td>\n      <td>begin to dance in a well lit dance studio.</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>65127</td>\n      <td>anetv_zgdT41KjjrE</td>\n      <td>7921</td>\n      <td>A person leads a horse. The guy</td>\n      <td>A person leads a horse.</td>\n      <td>The guy</td>\n      <td>gold</td>\n      <td>tries one at a time.</td>\n      <td>leads the horse and runs towards that.</td>\n      <td>shifts the rocking horse in the horse balance ...</td>\n      <td>gets on top of the horse.</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>63691</td>\n      <td>lsmdc3064_SPARKLE_2012-4368</td>\n      <td>13738</td>\n      <td>Someone waves, then rests her head on the wind...</td>\n      <td>Someone waves, then rests her head on the wind...</td>\n      <td>Now in prison, someone</td>\n      <td>gold</td>\n      <td>looks at someone through a pane of glass.</td>\n      <td>arrives at the house, then peers toward a ceil...</td>\n      <td>walks toward the house and starts across the s...</td>\n      <td>heads through a courtyard.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10376</td>\n      <td>lsmdc3018_CINDERELLA_MAN-7734</td>\n      <td>16245</td>\n      <td>Someone and someone watch her exit quickly. In...</td>\n      <td>Someone and someone watch her exit quickly.</td>\n      <td>In her sweater and scarf, someone</td>\n      <td>gold</td>\n      <td>crosses the snow to an alcove between buildings.</td>\n      <td>looks back to herself.</td>\n      <td>sits by her mother's building, sitting in a di...</td>\n      <td>sits on the porch.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>64835</td>\n      <td>anetv_Fu46pdVz4qY</td>\n      <td>17053</td>\n      <td>We see a lady in a pink shirt talking to the c...</td>\n      <td>We see a lady in a pink shirt talking to the c...</td>\n      <td>We</td>\n      <td>gold</td>\n      <td>see this store house.</td>\n      <td>credits appears on the screen.</td>\n      <td>cheer on the lady then an image appears in a s...</td>\n      <td>see the lady pick up a basket of laundry and p...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>14159</td>\n      <td>lsmdc3016_CHASING_MAVERICKS-6937</td>\n      <td>14167</td>\n      <td>Someone comes out of the barrel near the bone ...</td>\n      <td>Someone comes out of the barrel near the bone ...</td>\n      <td>Someone</td>\n      <td>gold</td>\n      <td>gives someone the letter and leaves.</td>\n      <td>sleeps in a lifeboat with his arms crossed, so...</td>\n      <td>nibbles across a puddle of hayseeds.</td>\n      <td>slides on top of the large pinata.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14863</td>\n      <td>lsmdc0021_Rear_Window-58244</td>\n      <td>9562</td>\n      <td>She is quite flat - chested, and the dress han...</td>\n      <td>She is quite flat - chested, and the dress han...</td>\n      <td>As if she</td>\n      <td>gold</td>\n      <td>were protesting, she holds in silence.</td>\n      <td>is just meeting 'new coach.</td>\n      <td>is preparing to meet someone.</td>\n      <td>knows she must go.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>65566</td>\n      <td>anetv_wj0D-wiqEb0</td>\n      <td>3771</td>\n      <td>When he is done, he lowers his instrument and ...</td>\n      <td>When he is done, he lowers his instrument and ...</td>\n      <td>They</td>\n      <td>gold</td>\n      <td>appear to be riding inside a train.</td>\n      <td>peer coolly at them.</td>\n      <td>are playing with a drum roll.</td>\n      <td>play the harmonica, and throw the ice in the a...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>"},"transient":{}}],"source":"show_random_elements(datasets[\"train\"])"},{"cell_type":"markdown","metadata":{"id":"5idsc_XCU3bt","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"数据集中的每个示例都有一个上下文，\n- 该上下文由第一个句子（在“sent1”字段中）\n- 第二个句子的介绍（在“sent2”字段中）组成。 \n- 然后给出四个可能的结尾或者后续（在字段 `ending0`、`ending1`、`ending2` 和 `ending3`）\n- 并且模型必须选择正确的一个（在字段 `label` 中指示）。 \n\n下面的函数让我们更好地可视化一个给定的例子："},{"metadata":{"id":"2474A14DAAB84C61AB545C5DD3BE1002","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"datasets[\"train\"][0] 为：\n```\n\n{'video-id': 'anetv_jkn6uvmqwh4',\n 'fold-ind': '3416',\n 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n 'sent2': 'A drum line',\n 'gold-source': 'gold',\n 'ending0': 'passes by walking down the street playing their instruments.',\n 'ending1': 'has heard approaching them.',\n 'ending2': \"arrives and they're outside dancing and asleep.\",\n 'ending3': 'turns the lead singer watches the performance.',\n 'label': 0}\n\n```\n\n英文翻译为中文：\n```\n{'video-id': 'anetv_jkn6uvmqwh4',\n  'fold-ind'：'3416'，\n  'startphrase'：'游行的成员拿着小号角铜管乐器走在街上。 鼓线'，\n  'sent1': '游行的成员拿着小号角铜管乐器走在街上。',\n  'sent2': '鼓线',\n  'gold-source'：'gold'，\n  'ending0': '路过演奏他们的乐器的街道。',\n  'ending1': '听说正在接近他们。',\n  'ending2': \"到了，他们在外面跳舞睡着了。\",\n  'ending3': '轮流主唱观看演出。',\n  'label'：0}\n```"},{"cell_type":"code","execution_count":55,"metadata":{"id":"RsFPKZ2mU3bu","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"def show_one(example):\n    print(f\"Context: {example['sent1']}\")\n    print(f\"  A - {example['sent2']} {example['ending0']}\")\n    print(f\"  B - {example['sent2']} {example['ending1']}\")\n    print(f\"  C - {example['sent2']} {example['ending2']}\")\n    print(f\"  D - {example['sent2']} {example['ending3']}\")\n    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D'][example['label']]}\")"},{"cell_type":"code","execution_count":9,"metadata":{"id":"LbeptCqEU3bu","jupyter":{},"outputId":"7486a481-6e39-4597-c669-810eafab7670","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Context: Members of the procession walk down the street holding small horn brass instruments.\n","  A - A drum line passes by walking down the street playing their instruments.\n","  B - A drum line has heard approaching them.\n","  C - A drum line arrives and they're outside dancing and asleep.\n","  D - A drum line turns the lead singer watches the performance.\n","\n","Ground truth: option A\n"]}],"source":"show_one(datasets[\"train\"][0])"},{"cell_type":"code","execution_count":57,"metadata":{"id":"kjQfUKkgU3bu","jupyter":{},"outputId":"3aef87f4-8e67-4e8d-b7ef-692e59822c02","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Context: Someone looks up at her hero and sees someone closing in again.\n  A - Someone offers his wand to find the entirely under world most obvious.\n  B - Someone leans back to her surroundings, his eyes rimmed with tears.\n  C - Someone gathers her belongings in a suitcase and walks out into the next room.\n  D - Someone lights his walking stick as he aims his pistol at someone's wand.\n\nGround truth: option B\n","name":"stdout"}],"source":"show_one(datasets[\"train\"][17])"},{"cell_type":"markdown","metadata":{"id":"n9qywopnIrJH","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"### 数据处理"},{"cell_type":"markdown","metadata":{"id":"YVx71GdAIrJH","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"在将这些文本输入模型之前，我们需要对它们进行预处理。 这是由 🤗 Transformers `Tokenizer` 完成的，它将（如名称所示）对输入进行标记（包括将标记转换为它们在预训练词汇表中的相应 ID）并将其放入模型期望的格式中，并生成 模型需要的其他输入。\n\n为此，我们使用 AutoTokenizer.from_pretrained 方法实例化我们的标记器，这将确保：\n\n- 完成分词\n- 处理成AutoModelForMultipleChoice格式。\n- AutoModelForMultipleChoice 比如 BertForMultipleChoice，XlnetForMultipleChoice\n\n该词汇表将被缓存，因此下次我们运行单元时不会再次下载它。"},{"metadata":{"id":"01370E39CD64449D9E029E4D862E0149","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"\n![Image Name](https://cdn.kesci.com/upload/image/r9x57uzad7.png?imageView2/0/w/960/h/960)\n"},{"cell_type":"code","execution_count":19,"metadata":{"id":"eXNLu_-nIrJI","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"610e29310158413daec0a4449befb985"}},"transient":{}},{"output_type":"display_data","metadata":{},"data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bee23c82cf3f434aa63798863dd329d1"}},"transient":{}},{"output_type":"display_data","metadata":{},"data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f50c2573690c428cbf7930fb0d5bef5a"}},"transient":{}},{"output_type":"display_data","metadata":{},"data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"385b0b647908411a9e453604494cd114"}},"transient":{}}],"source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"},{"cell_type":"markdown","metadata":{"id":"Vl6IidfdIrJK","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"我们将 `use_fast=True` 传递给上面的调用，以使用 🤗 Tokenizers 库中的一种快速分词器（由 Rust 支持）。 这些快速标记器可用于几乎所有模型，但如果您在之前的调用中遇到错误，请删除该参数。"},{"cell_type":"markdown","metadata":{"id":"rowT4iCLIrJK","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"您可以直接在一个句子或一对句子上调用此标记器："},{"cell_type":"code","execution_count":20,"metadata":{"id":"a5hBlsrHIrJL","jupyter":{},"outputId":"acdaa98a-a8cd-4a20-89b8-cc26437bbe90","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"{'input_ids': [101, 7592, 1010, 2023, 2028, 6251, 999, 102, 1998, 2023, 6251, 3632, 2007, 2009, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"transient":{}}],"source":"tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\")"},{"cell_type":"markdown","metadata":{"id":"qo_0B1M2IrJM","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"确定模型输入是什么？"},{"metadata":{"id":"291F462590204FCB8C628508A04B3E7C","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"MultipleChoice任务输入就是将问题和备选项分别进行组合，相当于一个样本为输入备选项个数相同的句子对列表，如下所示：\n\n```\n[(\"Members of the procession walk down the street holding small horn brass instruments.\",\"A drum line passes by walking down the street playing their instruments.\"),\n(\"Members of the procession walk down the street holding small horn brass instruments.\",\"A drum line has heard approaching them.\"),\n(\"Members of the procession walk down the street holding small horn brass instruments.\",\"A drum line arrives and they're outside dancing and asleep.\"),\n(\"Members of the procession walk down the street holding small horn brass instruments.\",\"A drum line turns the lead singer watches the performance.\")]\n```\n"},{"metadata":{"id":"94452658425645F2A64A1EC70D2EBAEC","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false,"mdEditEnable":false},"cell_type":"markdown","source":"语文阅读理解：\n```\n[{\"ID\": 1,    \n    \"Content\": \"奉和袭美抱疾杜门见寄次韵  陆龟蒙虽失春城醉上期，下帷裁遍未裁诗。因吟郢岸百亩蕙，欲采商崖三秀芝。栖野鹤笼宽使织，施山僧饭别教炊。但医沈约重瞳健，不怕江花不满枝。\",   \n    \"Questions\": [{\"Question\": \"下列对这首诗的理解和赏析，不正确的一项是\",        \n    \"Choices\": [\"A．作者写作此诗之时，皮日休正患病居家，闭门谢客，与外界不通音讯。\",\n                \"B．由于友人患病，原有的约会被暂时搁置，作者游春的诗篇也未能写出。\", \n                \"C．作者虽然身在书斋从事教学，但心中盼望能走进自然，领略美好春光。\",\n                \"D．尾联使用了关于沈约的典故，可以由此推测皮日休所患的疾病是目疾。\"],\n    \"Answer\": \"A\",\n    \"Q_id\": \"000101\"\n}]}\n```"},{"cell_type":"code","execution_count":58,"metadata":{"id":"vc0BSBLIIrJQ","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n\ndef preprocess_function(examples):\n    # 预处理输入tokenizer的输入\n    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n    # 复制四次句子sent1，个数与选项个数相同\n    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]#构造和备选项个数相同的问题句，也是tokenizer的第一个句子[sent1,sent1,sent1,sent1]\n    # Grab all second sentences possible for each context.\n    question_headers = examples[\"sent2\"] #tokenizer的第二个句子的上半句[sent2|ending0,sent2|ending1,sent2|ending2,sent2|ending3,]\n    second_sentences = [[f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)]#构造上半句拼接下半句作为tokenizer的第二个句子（也就是备选项）\n    # \n    \n    # Flatten everything\n    first_sentences = sum(first_sentences, []) #合并成一个列表方便tokenizer一次性处理：[[e1_sen1,e1_sen1,e1_sen1,e1_sen1],[e2_sen1,e2_sen1,e2_sen1,e2_sen1],[e3_sen1,e3_sen1,e3_sen1,e3_sen1]]->\n    # [e1_sen1,e1_sen1,e1_sen1,e1_sen1,e2_sen1,e2_sen1,e2_sen1,e2_sen1,e3_sen1,e3_sen1,e3_sen1,e3_sen1]\n    second_sentences = sum(second_sentences, [])#合并成一个列表方便tokenizer一次性处理\n    \n    # Tokenize\n    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n    # Un-flatten\n    # 转化成每个样本（一个样本中包括了四个k=[问题1,问题1,问题1,问题1],v=[备选项1,备选项2,备选项3,备选项4]）\n    # [e1_tokens1,e1_tokens1,e1_tokens1,e1_tokens1,e2_tokens1,e2_tokens1,e2_tokens1,e2_tokens1,e3_tokens1,e3_tokens1,e3_tokens1,e3_tokens1]->\n    # [[e1_tokens1,e1_tokens1,e1_tokens1,e1_tokens1],[e2_tokens1,e2_tokens1,e2_tokens1,e2_tokens1],[e3_tokens1,e3_tokens1,e3_tokens1]]\n    return {k: [v[i:i+4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"},{"cell_type":"markdown","metadata":{"id":"0lm8ozrJIrJR","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"此功能适用于一个或多个示例。 在多个示例的情况下，标记器将返回每个键的列表列表：所有示例的列表（此处为 5），然后是所有选择的列表（4）和输入 ID 列表（此处的长度不同 因为我们没有应用任何填充）："},{"cell_type":"code","execution_count":59,"metadata":{"id":"p6kpDpgtU3bz","jupyter":{},"outputId":"bea25138-f601-4222-b39a-1d1caf4b2756","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"5 4 [30, 25, 30, 28]\n","name":"stdout"}],"source":"examples = datasets[\"train\"][:5] # 训练集中的五条样本\nfeatures = preprocess_function(examples) # 构造五条样本的分词输入\nprint(\n    len(features[\"input_ids\"]), # \n    len(features[\"input_ids\"][0]), # 第一个样本四个句子对的token ids\n    # [[sent1,sent2|option1],\n    # [sent1,sent2|option2],\n    # [sent1,sent2|option3],\n    # [sent1,sent2|option4]]\n    [len(x) for x in features[\"input_ids\"][0]] # 每个句子对toeken ids个数\n)"},{"metadata":{"id":"FB85D45ECD2C495C8901406912544124","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"},"transient":{}}],"source":"features.keys()","execution_count":62},{"cell_type":"code","execution_count":60,"metadata":{"id":"BB7FB9F1561A42319C6DA337A7F80884","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"{'Unnamed: 0': [0, 1, 2, 3, 4],\n 'video-id': ['anetv_jkn6uvmqwh4',\n  'anetv_jkn6uvmqwh4',\n  'anetv_jkn6uvmqwh4',\n  'anetv_jkn6uvmqwh4',\n  'anetv_Bri_myFFu4A'],\n 'fold-ind': [3416, 3417, 3415, 3417, 2408],\n 'startphrase': ['Members of the procession walk down the street holding small horn brass instruments. A drum line',\n  'A drum line passes by walking down the street playing their instruments. Members of the procession',\n  'A group of members in green uniforms walks waving flags. Members of the procession',\n  'A drum line passes by walking down the street playing their instruments. Members of the procession',\n  'The person plays a song on the violin. The man'],\n 'sent1': ['Members of the procession walk down the street holding small horn brass instruments.',\n  'A drum line passes by walking down the street playing their instruments.',\n  'A group of members in green uniforms walks waving flags.',\n  'A drum line passes by walking down the street playing their instruments.',\n  'The person plays a song on the violin.'],\n 'sent2': ['A drum line',\n  'Members of the procession',\n  'Members of the procession',\n  'Members of the procession',\n  'The man'],\n 'gold-source': ['gold', 'gen', 'gold', 'gen', 'gold'],\n 'ending0': ['passes by walking down the street playing their instruments.',\n  'are playing ping pong and celebrating one left each in quick.',\n  'pay the other coaches to cheer as people this chatter dips in lawn sheets.',\n  'are playing ping pong and celebrating one left each in quick.',\n  'finishes the song and lowers the instrument.'],\n 'ending1': ['has heard approaching them.',\n  'wait slowly towards the cadets.',\n  'walk down the street holding small horn brass instruments.',\n  'wait slowly towards the cadets.',\n  'hits the saxophone and demonstrates how to properly use the racquet.'],\n 'ending2': [\"arrives and they're outside dancing and asleep.\",\n  'continues to play as well along the crowd along with the band being interviewed.',\n  'is seen in the background.',\n  'makes a square call and ends by jumping down into snowy streets where fans begin to take their positions.',\n  'finishes massage the instrument again and continues.'],\n 'ending3': ['turns the lead singer watches the performance.',\n  'continue to play marching, interspersed.',\n  'are talking a couple of people playing a game of tug of war.',\n  'play and go back and forth hitting the drums while the audience claps for them.',\n  'continues dancing while the man gore the music outside while drums.'],\n 'label': [0, 3, 1, 3, 0]}"},"transient":{}}],"source":"examples"},{"cell_type":"markdown","metadata":{"id":"5z9pG6RIU3bz","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"为了检查是否准确，我们可以打印下第四条样本"},{"cell_type":"code","execution_count":15,"metadata":{"id":"3O2i277XU3bz","jupyter":{},"outputId":"54141acd-5b93-4a92-cd34-4d6197460fe8","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["['[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession are playing ping pong and celebrating one left each in quick. [SEP]',\n"," '[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession wait slowly towards the cadets. [SEP]',\n"," '[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession makes a square call and ends by jumping down into snowy streets where fans begin to take their positions. [SEP]',\n"," '[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession play and go back and forth hitting the drums while the audience claps for them. [SEP]']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":"idx = 3\n[tokenizer.decode(features[\"input_ids\"][idx][i]) for i in range(4)]"},{"cell_type":"markdown","metadata":{"id":"VOQqPuYyU3bz","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"与真实内容相比较"},{"cell_type":"code","execution_count":63,"metadata":{"id":"-6HHsDJ9U3b0","jupyter":{},"outputId":"63442036-3824-4bbe-da20-6ef997afa52e","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Context: A drum line passes by walking down the street playing their instruments.\n  A - Members of the procession are playing ping pong and celebrating one left each in quick.\n  B - Members of the procession wait slowly towards the cadets.\n  C - Members of the procession makes a square call and ends by jumping down into snowy streets where fans begin to take their positions.\n  D - Members of the procession play and go back and forth hitting the drums while the audience claps for them.\n\nGround truth: option D\n","name":"stdout"}],"source":"show_one(datasets[\"train\"][3])"},{"cell_type":"markdown","metadata":{"id":"zS-6iXTkIrJT","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"这似乎没问题，所以我们可以将这个函数应用于我们数据集中的所有示例，我们只需使用我们之前创建的 `dataset` 对象的 `map` 方法。 这会将函数应用于“数据集”中所有拆分的所有元素，因此我们的训练、验证和测试数据将在一个命令中进行预处理。"},{"cell_type":"code","execution_count":64,"metadata":{"id":"DDtsaJeVIrJT","jupyter":{},"outputId":"aa4734bf-4ef5-4437-9948-2c16363da719","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Loading cached processed dataset at ./cache/csv/task063578-a70cb52678a611ac/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-c2ec216ab18d6a01.arrow\nLoading cached processed dataset at ./cache/csv/task063578-a70cb52678a611ac/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-4a0d824c5f087eb0.arrow\nLoading cached processed dataset at ./cache/csv/task063578-a70cb52678a611ac/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-4620c53b2807eee1.arrow\n","name":"stderr"}],"source":"encoded_datasets = datasets.map(preprocess_function, batched=True)"},{"metadata":{"id":"62483B10F40A4FC5AF2A90850796135F","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 73546\n    })\n    validation: Dataset({\n        features: ['Unnamed: 0', 'video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 20006\n    })\n    test: Dataset({\n        features: ['Unnamed: 0', 'video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 20005\n    })\n})"},"transient":{}}],"source":"encoded_datasets","execution_count":65},{"metadata":{"id":"B7E9987A3A88410C856F03EE6D801364","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"{'Unnamed: 0': 0,\n 'video-id': 'anetv_jkn6uvmqwh4',\n 'fold-ind': 3416,\n 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n 'sent2': 'A drum line',\n 'gold-source': 'gold',\n 'ending0': 'passes by walking down the street playing their instruments.',\n 'ending1': 'has heard approaching them.',\n 'ending2': \"arrives and they're outside dancing and asleep.\",\n 'ending3': 'turns the lead singer watches the performance.',\n 'label': 0,\n 'input_ids': [[101,\n   2372,\n   1997,\n   1996,\n   14385,\n   3328,\n   2091,\n   1996,\n   2395,\n   3173,\n   2235,\n   7109,\n   8782,\n   5693,\n   1012,\n   102,\n   1037,\n   6943,\n   2240,\n   5235,\n   2011,\n   3788,\n   2091,\n   1996,\n   2395,\n   2652,\n   2037,\n   5693,\n   1012,\n   102],\n  [101,\n   2372,\n   1997,\n   1996,\n   14385,\n   3328,\n   2091,\n   1996,\n   2395,\n   3173,\n   2235,\n   7109,\n   8782,\n   5693,\n   1012,\n   102,\n   1037,\n   6943,\n   2240,\n   2038,\n   2657,\n   8455,\n   2068,\n   1012,\n   102],\n  [101,\n   2372,\n   1997,\n   1996,\n   14385,\n   3328,\n   2091,\n   1996,\n   2395,\n   3173,\n   2235,\n   7109,\n   8782,\n   5693,\n   1012,\n   102,\n   1037,\n   6943,\n   2240,\n   8480,\n   1998,\n   2027,\n   1005,\n   2128,\n   2648,\n   5613,\n   1998,\n   6680,\n   1012,\n   102],\n  [101,\n   2372,\n   1997,\n   1996,\n   14385,\n   3328,\n   2091,\n   1996,\n   2395,\n   3173,\n   2235,\n   7109,\n   8782,\n   5693,\n   1012,\n   102,\n   1037,\n   6943,\n   2240,\n   4332,\n   1996,\n   2599,\n   3220,\n   12197,\n   1996,\n   2836,\n   1012,\n   102]],\n 'token_type_ids': [[0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n  [0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1],\n  [0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1]],\n 'attention_mask': [[1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1],\n  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n  [1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1],\n  [1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1]]}"},"transient":{}}],"source":"encoded_datasets['train'][0]","execution_count":66},{"cell_type":"markdown","metadata":{"id":"voWiw8C7IrJV","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"更好的是，🤗 Datasets 库会自动缓存结果，以避免在下次运行 notebook 时在这一步上花费时间。 🤗 Datasets 库通常足够智能，可以检测您传递给 map 的函数何时发生更改（因此需要不使用缓存数据）。 例如，它会正确检测您是否更改了第一个单元格中的任务并重新运行笔记本。 🤗 Datasets 在使用缓存文件时会发出警告，您可以在对 `map` 的调用中传递 `load_from_cache_file=False` 以不使用缓存文件并强制再次应用预处理。\n\n请注意，我们传递了 `batched=True` 来对文本进行批量编码。 这是为了充分利用我们之前加载的快速分词器的全部优势，它将使用多线程同时处理批处理中的文本。"},{"cell_type":"markdown","metadata":{"id":"545PP3o8IrJV","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"### 微调模型"},{"cell_type":"markdown","metadata":{"id":"FBiW8UpKIrJW","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"现在我们的数据已经准备好了，我们可以下载预训练模型并对其进行微调。 由于我们所有的任务都是关于多项选择的，因此我们使用了 AutoModelForMultipleChoice 类。 与分词器一样，`from_pretrained` 方法将为我们下载并缓存模型。"},{"cell_type":"code","execution_count":32,"metadata":{"id":"TlqNaB8jIrJW","jupyter":{},"outputId":"84916cf3-6e6c-47f3-d081-032ec30a4132","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n\nmodel = AutoModelForMultipleChoice.from_pretrained(model_checkpoint) # 加载预训练模型 bert base"},{"cell_type":"markdown","metadata":{"id":"CczA5lJlIrJX","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"警告告诉我们我们正在丢弃一些权重（`vocab_transform` 和 `vocab_layer_norm` 层）并随机初始化其他一些权重（`pre_classifier` 和 `classifier` 层）。 在这种情况下，这是绝对正常的，因为我们正在移除用于在掩码语言建模目标上预训练模型的头部，并将其替换为我们没有预训练权重的新头部，因此库警告我们应该没问题 - 在使用它进行推理之前调整这个模型，这正是我们要做的。"},{"cell_type":"markdown","metadata":{"id":"_N8urzhyIrJY","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"要实例化一个“Trainer”，我们需要再定义三件事。 最重要的是 [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments)，这是一个包含自定义训练的所有属性的类。 它需要一个文件夹名称，用于保存模型的检查点，所有其他参数都是可选的："},{"cell_type":"code","execution_count":19,"metadata":{"id":"Bliy8zgjIrJY","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"model_name = model_checkpoint.split(\"/\")[-1]\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-swag\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    push_to_hub=True,\n)"},{"cell_type":"markdown","metadata":{"id":"km3pGVdTIrJc","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"在这里，我们将评估设置为在每个 epoch 结束时进行，调整学习率，使用 notebook 顶部定义的 `batch_size` 并自定义训练的 epoch 数量以及权重衰减。\n\n设置一切的最后一个参数，以便我们可以在训练期间定期将模型推送到 [Hub](https://huggingface.co/models)。如果您没有按照笔记本顶部的安装步骤将其删除。如果您想以不同于将要推送的存储库名称的名称在本地保存模型，或者如果您想将模型推送到组织而不是名称空间下，请使用 `hub_model_id` 参数设置repo 名称（它必须是全名，包括您的命名空间：例如“sgugger/bert-finetuned-swag”或“huggingface/bert-finetuned-swag”）。\n\n然后我们需要告诉我们的“Trainer”如何从预处理的输入中形成批次。我们还没有做任何填充，因为我们会将每个批次填充到批次内的最大长度（而不是使用整个数据集的最大长度这样做）。这将是 *data collat​​or* 的工作。数据整理器获取示例列表并将它们转换为批处理（在我们的示例中，通过应用填充）。由于库中没有适用于我们特定问题的数据整理器，我们将编写一个，改编自“DataCollat​​orWithPadding”："},{"cell_type":"code","execution_count":67,"metadata":{"id":"XrHr1Vj_U3b2","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"from dataclasses import dataclass\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom typing import Optional, Union\nimport torch\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    \"\"\"\n    Data collator that will dynamically pad the inputs for multiple choice received.\n    \"\"\"\n\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n\n    def __call__(self, features):\n        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0][\"input_ids\"])\n        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n        \n        # Un-flatten\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        # Add back labels\n        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n        return batch"},{"cell_type":"markdown","metadata":{"id":"AbZBAnbxU3b2","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"当在示例列表上调用时，它将展平大列表中的所有输入/注意掩码等，并将其传递给 `tokenizer.pad` 方法。 这将返回一个带有大张量的字典（形状为 `(batch_size * 4) x seq_length`），然后我们将其展开。\n\n我们可以检查这个数据整理器是否适用于特征列表，我们只需要确保删除我们模型不接受的所有输入特征（之后“Trainer”会自动为我们做一些事情）："},{"cell_type":"code","execution_count":74,"metadata":{"id":"RYtsb6IYU3b2","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[],"source":"accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"] # 需要保留的输入\nfeatures = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]# \nbatch = DataCollatorForMultipleChoice(tokenizer)(features)"},{"metadata":{"id":"B0107518C0DA4CA6861FF007AC139E52","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"dict_keys(['input_ids', 'attention_mask', 'labels'])"},"transient":{}}],"source":"batch.keys()","execution_count":75},{"metadata":{"id":"092794D3349146EB89E81B667489CFBD","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"torch.Size([10, 4, 40])"},"transient":{}}],"source":"batch['input_ids'].shape","execution_count":76},{"cell_type":"markdown","metadata":{"id":"nc42V6rPU3b3","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"为了检查我们转换后的数据是否长句，我们可以和原始内容进行比较"},{"cell_type":"code","execution_count":71,"metadata":{"id":"UfzBwYSkU3b3","jupyter":{},"outputId":"cecbf62c-6963-4f88-dec2-731f85a7b5a6","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"['[CLS] someone walks over to the radio. [SEP] someone hands her another phone. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n '[CLS] someone walks over to the radio. [SEP] someone takes the drink, then holds it. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n '[CLS] someone walks over to the radio. [SEP] someone looks off then looks at someone. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n '[CLS] someone walks over to the radio. [SEP] someone stares blearily down at the floor. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"},"transient":{}}],"source":"[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(4)]"},{"cell_type":"code","execution_count":72,"metadata":{"id":"KQI0ixRqU3b3","jupyter":{},"outputId":"8f652215-c214-491f-9a86-72c1eb7c4560","slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Context: Someone walks over to the radio.\n  A - Someone hands her another phone.\n  B - Someone takes the drink, then holds it.\n  C - Someone looks off then looks at someone.\n  D - Someone stares blearily down at the floor.\n\nGround truth: option D\n","name":"stdout"}],"source":"show_one(datasets[\"train\"][8])"},{"cell_type":"markdown","metadata":{"id":"7sZOdRlRIrJd","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"看起来很好\n\n为我们的“Trainer”定义的最后一件事是如何根据预测计算指标。 我们需要为此定义一个函数，它将只使用我们之前加载的 `metric`，我们要做的唯一预处理是获取我们预测的 logits 的 argmax："},{"cell_type":"code","execution_count":24,"metadata":{"id":"UmvbnJ9JIrJd","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"import numpy as np\n\ndef compute_metrics(eval_predictions):\n    predictions, label_ids = eval_predictions\n    preds = np.argmax(predictions, axis=1)\n    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"},{"cell_type":"markdown","metadata":{"id":"rXuFTAzDIrJe","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"然后我们只需要将所有这些与我们的数据集一起传递给`Trainer`："},{"cell_type":"code","execution_count":25,"metadata":{"id":"imY1oC3SIrJf","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Cloning https://huggingface.co/quincyqiang/bert-base-uncased-finetuned-swag into local empty directory.\n"]}],"source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=encoded_datasets[\"train\"],\n    eval_dataset=encoded_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer),\n    compute_metrics=compute_metrics,\n)"},{"cell_type":"markdown","metadata":{"id":"CdzABDVcIrJg","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"我们现在可以通过调用 `train` 方法来微调我们的模型："},{"cell_type":"code","execution_count":26,"metadata":{"id":"jLtt-Hf3U3b4","outputId":"4a9c57f9-647a-4250-9a9b-16615b68da16","slideshow":{"slide_type":"slide"},"tags":[],"jupyter":{},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set  don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: sent1, video-id, ending3, gold-source, startphrase, ending0, ending1, sent2, fold-ind, ending2. If sent1, video-id, ending3, gold-source, startphrase, ending0, ending1, sent2, fold-ind, ending2 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n","F:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 73546\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 13791\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquincyqiang\u001b[0m (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/quincyqiang/huggingface/runs/31am8bfe\" target=\"_blank\">bert-base-uncased-finetuned-swag</a></strong> to <a href=\"https://wandb.ai/quincyqiang/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='13791' max='13791' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13791/13791 40:52, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.756000</td>\n","      <td>0.602119</td>\n","      <td>0.764571</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.397800</td>\n","      <td>0.661687</td>\n","      <td>0.778267</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.146800</td>\n","      <td>1.039732</td>\n","      <td>0.789213</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-1000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-1000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-1000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-1000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-1000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-1500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-1500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-1500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-1500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-1500\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-2000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-2000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-2000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-2000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-2000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-2500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-2500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-2500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-2500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-2500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-3000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-3000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-3000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-3000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-3000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-3500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-3500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-3500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-3500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-3500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-4000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-4000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-4000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-4000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-4000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-4500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-4500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-4500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-4500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-4500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: sent1, video-id, ending3, gold-source, startphrase, ending0, ending1, sent2, fold-ind, ending2. If sent1, video-id, ending3, gold-source, startphrase, ending0, ending1, sent2, fold-ind, ending2 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 20006\n","  Batch size = 16\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-5000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-5000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-5000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-5000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-5000\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-5500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-5500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-5500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-5500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-5500\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-6000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-6000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-6000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-6000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-6000\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-6500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-6500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-6500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-6500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-6500\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-7000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-7000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-7000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-7000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-7000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-7500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-7500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-7500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-7500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-7500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-8000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-8000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-8000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-8000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-8000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-8500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-8500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-8500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-8500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-8500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-9000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-9000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-9000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-9000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-9000\\special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: sent1, video-id, ending3, gold-source, startphrase, ending0, ending1, sent2, fold-ind, ending2. If sent1, video-id, ending3, gold-source, startphrase, ending0, ending1, sent2, fold-ind, ending2 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 20006\n","  Batch size = 16\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-9500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-9500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-9500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-9500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-9500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-10000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-10000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-10000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-10000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-10000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-10500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-10500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-10500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-10500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-10500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-11000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-11000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-11000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-11000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-11000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-11500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-11500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-11500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-11500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-11500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-12000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-12000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-12000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-12000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-12000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-12500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-12500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-12500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-12500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-12500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-13000\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-13000\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-13000\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-13000\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-13000\\special_tokens_map.json\n","Saving model checkpoint to bert-base-uncased-finetuned-swag\\checkpoint-13500\n","Configuration saved in bert-base-uncased-finetuned-swag\\checkpoint-13500\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\checkpoint-13500\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\checkpoint-13500\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\checkpoint-13500\\special_tokens_map.json\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: sent1, video-id, ending3, gold-source, startphrase, ending0, ending1, sent2, fold-ind, ending2. If sent1, video-id, ending3, gold-source, startphrase, ending0, ending1, sent2, fold-ind, ending2 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 20006\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=13791, training_loss=0.4617224831533055, metrics={'train_runtime': 2468.151, 'train_samples_per_second': 89.394, 'train_steps_per_second': 5.588, 'total_flos': 2.466167112293952e+16, 'train_loss': 0.4617224831533055, 'epoch': 3.0})"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":"trainer.train()"},{"cell_type":"markdown","metadata":{"id":"wY82caEX3l_i","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true,"mdEditEnable":false},"source":"上传模型到huggingface hub平台"},{"cell_type":"code","execution_count":27,"metadata":{"id":"P4uYoiRKU3b4","jupyter":{},"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to bert-base-uncased-finetuned-swag\n","Configuration saved in bert-base-uncased-finetuned-swag\\config.json\n","Model weights saved in bert-base-uncased-finetuned-swag\\pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-swag\\tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-swag\\special_tokens_map.json\n","Several commits (2) will be pushed upstream.\n","The progress bars may be unreliable.\n","Everything up-to-date\n","\n","Dropping the following result as it does not have all the necessary fields:\n","{'dataset': {'name': 'swag', 'type': 'swag', 'args': 'regular'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.789213240146637}]}\n","To https://huggingface.co/quincyqiang/bert-base-uncased-finetuned-swag\n","   22cea59..32a6065  main -> main\n","\n"]},{"data":{"text/plain":["'https://huggingface.co/quincyqiang/bert-base-uncased-finetuned-swag/commit/22cea5901e2cfee5212caa5d751a681d99796f7e'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":"trainer.push_to_hub()"},{"cell_type":"markdown","metadata":{"id":"7845D09F07E44F579FB59FDAECBFFC6B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false,"mdEditEnable":false},"source":"## 科大讯飞中文成语填空挑战赛\n\n比赛名称：中文成语填空挑战赛算法挑战大赛\n比赛链接：https://challenge.xfyun.cn/topic/info?type=chinese-idioms\n关注公众号“ChallengeHub”回复“成语填空”获取完整baseline"},{"metadata":{"id":"46AABEF8EDEB4B2783D157EE7AB71CA5","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 一、赛事背景\n中国文化博大精深源远流长，其中成语更是中国文化的精华。成语大多由四个字组成，一般都有典故或出处。有些成语从字面上不难理解，如“小题大做”、“后来居上”等。有些成语必须知道来源或典故才能懂得意思，如“朝三暮四”、“杯弓蛇影”等。\n\n成语学习是小学语文和初中重要的学习内容，如何在语句中选择合适的成语？本次赛题中希望选手构建模型能理解中文成语。\n\n### 二、赛事任务\n给定一个中文句子的情况下，需要选手在给定上下文的情况下从待选的成语中选择最为合适的成语。即给定句子的上下文，完成合适的成语填入对应位置。\n\n赛题训练集案例如下：\n![](https://ai-contest-static.xfyun.cn/2021/158.jpg)"},{"metadata":{"id":"1B8BBA0DC2A84F94B43BD70EBA3CCAFB","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"* 按照NLP中阅读理解题目处理比赛数据格式，具体内容可以参考swag格式\n* 构建描述文本text和选项‘choice’，以及候选答案：四个候选‘成语’\n* 输入‘AutoModelForMultipleChoice’模型进行训练和预测\n\n### 三、构建训练集和测试集"},{"metadata":{"id":"6F7D25F7C8EC4113903B0C2DD05BFF6A","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"import re\nimport pandas as pd\nfrom tqdm import tqdm\n\ntrain = pd.read_csv('data/train.csv', sep='\\t')\ntest = pd.read_csv('data/test.csv', sep='\\t')\n\nprint(train)\nprint(test)\n\n\ndef process_text(text):\n    return re.sub(' +', ' ', text).strip()\n\n\ndef get_question(text):\n    \"\"\"\n    根据[MASK][MASK][MASK][MASK]获取问题\n    :param text:\n    :return:\n    \"\"\"\n    sentences = re.split('(。|！|\\!|\\.|？|\\?)', text)  # 保留分割符\n    for sent in sentences:\n        if '[MASK][MASK][MASK][MASK]' in sent:\n            return sent\n    return text\n\n\ncols = [\n    \"Unnamed: 0\",\n    \"video-id\",\n    \"fold-ind\",  # q_id\n    \"startphrase\",\n    \"sent1\",  # content\n    \"sent2\",  # question\n    \"gold-source\",\n    \"ending0\", \"ending1\", \"ending2\", \"ending3\",  # choice\n    \"label\"]\n\n# ======================================================\n# 生成训练集\n# ======================================================\nres = []\n\nfor idx, row in tqdm(train.iterrows()):\n    q_id = f'train_{idx}'\n    content = row['text']\n    content = process_text(content)\n    question = get_question(content)\n    modified_choices = eval(row['candidate'])\n    label = modified_choices.index(row['label'])\n    ## Hard-code for swag format!\n    res.append((\"\",\n                \"\",\n                q_id,\n                \"\",\n                content,\n                question,\n                \"\",\n                modified_choices[0],\n                modified_choices[1],\n                modified_choices[2],\n                modified_choices[3],\n                label))\ndf = pd.DataFrame(res, columns=cols)","execution_count":null},{"metadata":{"id":"A90D3187EB5A497487296B49A8774DA6","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 四、模型训练"},{"metadata":{"id":"45816E05FDD74BFB89C3F03419763A0A","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"# Metric\n    def compute_metrics(eval_predictions):\n        predictions, label_ids = eval_predictions\n        preds = np.argmax(predictions, axis=1)\n        return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}\n\n    # Initialize our Trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_datasets[\"train\"] if training_args.do_train else None,\n        eval_dataset=tokenized_datasets[\"validation\"] if training_args.do_eval else None,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n\n    # Training\n    if training_args.do_train:\n        if last_checkpoint is not None:\n            checkpoint = last_checkpoint\n        elif os.path.isdir(model_args.model_name_or_path):\n            checkpoint = model_args.model_name_or_path\n        else:\n            checkpoint = None\n        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n        trainer.save_model()  # Saves the tokenizer too for easy upload\n\n        output_train_file = os.path.join(training_args.output_dir, \"train_results.txt\")\n        if trainer.is_world_process_zero():\n            with open(output_train_file, \"w\") as writer:\n                logger.info(\"***** Train results *****\")\n                for key, value in sorted(train_result.metrics.items()):\n                    logger.info(f\"  {key} = {value}\")\n                    writer.write(f\"{key} = {value}\\n\")\n\n            # Need to save the state, since Trainer.save_model saves only the tokenizer with the model\n            trainer.state.save_to_json(os.path.join(training_args.output_dir, \"trainer_state.json\"))","execution_count":null},{"metadata":{"id":"BA30D6929EC64BB38301B33ACA62FE4D","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"## 2021海华AI挑战赛·中文阅读理解\n\n### 赛题背景\n文字是人类用以记录和表达的最基本工具，也是信息传播的重要媒介。透过文字与符号，我们可以追寻人类文明的起源，可以传播知识与经验，读懂文字是认识与了解的第一步。对于人工智能而言，它的核心问题之一就是认知，而认知的核心则是语义理解。\n \n机器阅读理解(Machine Reading Comprehension)是自然语言处理和人工智能领域的前沿课题，对于使机器拥有认知能力、提升机器智能水平具有重要价值，拥有广阔的应用前景。机器的阅读理解是让机器阅读文本，然后回答与阅读内容相关的问题，体现的是人工智能对文本信息获取、理解和挖掘的能力，在对话、搜索、问答、同声传译等领域，机器阅读理解可以产生的现实价值正在日益凸显，长远的目标则是能够为各行各业提供解决方案。\n \n《2021海华AI挑战赛·中文阅读理解》大赛由中关村海华信息技术前沿研究院与清华大学交叉信息研究院联合主办，腾讯云计算协办。共设置题库16000条数据，总奖金池30万元，且腾讯云计算为中学组赛道提供独家算力资源支持。\n \n本次比赛的数据来自小学/中高考语文阅读理解题库（其中，技术组的数据主要为中高考语文试题，中学组的数据主要来自小学语文试题）。相较于英文，中文阅读理解有着更多的歧义性和多义性，然而璀璨的中华文明得以绵延数千年，离不开每一个时代里努力钻研、坚守传承的人，这也正是本次大赛的魅力与挑战，让机器读懂文字，让机器学习文明。秉承着人才培养的初心，我们继续保留针对中学组以及技术组的两条平行赛道，科技创新，时代有我，期待你们的回响。\n \n\n### 比赛任务\n本次比赛技术组的数据来自中高考语文阅读理解题库。每条数据都包括一篇文章，至少一个问题和多个候选选项。参赛选手需要搭建模型，从候选选项中选出正确的一个。\nhttps://www.biendata.xyz/competition/haihua_2021/"},{"metadata":{"id":"AAE8F825AFE147DC89DC32BF58B065AA","notebookId":"624d7c109ed218001727b436","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":4}